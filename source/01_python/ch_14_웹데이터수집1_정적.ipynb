{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c195eaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:90% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:19pt;}\n",
       "div.text_cell_render.rendered_html{font-size:16pt;}\n",
       "div.output {font-size:16pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:16pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:16pt;padding:5px;}\n",
       "table.dataframe{font-size:12px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:90% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:19pt;}\n",
    "div.text_cell_render.rendered_html{font-size:16pt;}\n",
    "div.output {font-size:16pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:16pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:16pt;padding:5px;}\n",
    "table.dataframe{font-size:12px;}\n",
    "</style>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c027eb7d",
   "metadata": {},
   "source": [
    "<b><font size=\"7\" color=\"red\">ch14. 웹데이터 수집</font></b>\n",
    "# 1절. BEAUTIFULSOUP과 parser\n",
    "'pip install bs4' 아나콘다를 설치하면 자동 설치되는 패키지 7500개에 포함\n",
    "\n",
    "- 공식 Documentation : https://beautiful-soup-4.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a4db062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내 Local PC의 파일을 url(http://~)처럼 접근\n",
    "import requests # http 요청 처리하는 Lib\n",
    "from requests_file import FileAdapter # file://프로토콜을 다루기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15219789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = requests.Session() # HTTP 요청처리하는 세션 객체\n",
    "s.mount(\"file://\", FileAdapter())\n",
    "# file://경로로 들어오면 이 요청은 c:(로컬파일)을 접근\n",
    "response = s.get('file:///ai/ch14_sample.html')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c2deb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잘 접근하였습니다.\n"
     ]
    }
   ],
   "source": [
    "if response:\n",
    "    print('잘 접근하였습니다.')\n",
    "else:\n",
    "    print('접근을 못했습니다')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6f40ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code\n",
    "    # 200 : 정상\n",
    "    # 404 : 없는페이지\n",
    "    # 406 : get, post 오류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab750735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n<head>\\r\\n  <meta charset=\"UTF-8\">\\r\\n</head>\\r\\n<body>\\r\\n  <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\\r\\n  <h1 class=\"css\">Hi, CSS</h1>\\r\\n  <div id=\"subject\">subject \\xec\\x84\\xa0\\xed\\x83\\x9d\\xec\\x9e\\x90 \\xec\\x95\\x88\\xec\\x9d\\x98 \\xeb\\x82\\xb4\\xec\\x9a\\xa9</div>\\r\\n  <p>CSS \\xec\\x84\\xa0\\xed\\x83\\x9d\\xec\\x9e\\x90\\xeb\\x8a\\x94 \\xeb\\x8b\\xa4\\xec\\x96\\x91\\xed\\x95\\x9c \\xea\\xb3\\xb3\\xec\\x97\\x90\\xec\\x84\\x9c \\xed\\x99\\x9c\\xec\\x9a\\xa9\\xeb\\x90\\xa9\\xeb\\x8b\\x88\\xeb\\x8b\\xa4</p>\\r\\n  <div class=\"contents\">\\r\\n    \\xec\\x84\\xa0\\xed\\x83\\x9d\\xec\\x9e\\x90\\xeb\\xa5\\xbc \\xec\\x96\\xb4\\xeb\\x96\\xbb\\xea\\xb2\\x8c \\xec\\x9e\\x91\\xec\\x84\\xb1\\xed\\x95\\x98\\xeb\\x8a\\x90\\xeb\\x83\\x90\\xec\\x97\\x90 \\xeb\\x94\\xb0\\xeb\\x9d\\xbc\\r\\n    <span>\\xeb\\x8b\\xa4\\xeb\\xa5\\xb8<b>\\xec\\x9a\\x94\\xec\\x86\\x8c\\xea\\xb0\\x80 \\xeb\\xb0\\x98\\xed\\x99\\x98</b></span>\\xeb\\x90\\xa9\\xeb\\x8b\\x88\\xeb\\x8b\\xa4\\r\\n  </div>\\r\\n  <div>CSS \\xec\\x84\\xa0\\xed\\x83\\x9d\\xec\\x9e\\x90\\xeb\\x8a\\x94 \\xeb\\x8b\\xa4\\xec\\x96\\x91\\xed\\x95\\x9c \\xea\\xb3\\xb3\\xec\\x97\\x90 <b>\\xed\\x99\\x9c\\xec\\x9a\\xa9</b>\\xeb\\x90\\xa9\\xeb\\x8b\\x88\\xeb\\x8b\\xa4</div>\\r\\n</body>\\r\\n</html>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content # 바이너리 형식의 html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f0bff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n<head>\\r\\n  <meta charset=\"UTF-8\">\\r\\n</head>\\r\\n<body>\\r\\n  <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\\r\\n  <h1 class=\"css\">Hi, CSS</h1>\\r\\n  <div id=\"subject\">subject 선택자 안의 내용</div>\\r\\n  <p>CSS 선택자는 다양한 곳에서 활용됩니다</p>\\r\\n  <div class=\"contents\">\\r\\n    선택자를 어떻게 작성하느냐에 따라\\r\\n    <span>다른<b>요소가 반환</b></span>됩니다\\r\\n  </div>\\r\\n  <div>CSS 선택자는 다양한 곳에 <b>활용</b>됩니다</div>\\r\\n</body>\\r\\n</html>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4566d95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n<head>\\r\\n  <meta charset=\"UTF-8\">\\r\\n</head>\\r\\n<body>\\r\\n  <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\\r\\n  <h1 class=\"css\">Hi, CSS</h1>\\r\\n  <div id=\"subject\">subject 선택자 안의 내용</div>\\r\\n  <p>CSS 선택자는 다양한 곳에서 활용됩니다</p>\\r\\n  <div class=\"contents\">\\r\\n    선택자를 어떻게 작성하느냐에 따라\\r\\n    <span>다른<b>요소가 반환</b></span>됩니다\\r\\n  </div>\\r\\n  <div>CSS 선택자는 다양한 곳에 <b>활용</b>됩니다</div>\\r\\n</body>\\r\\n</html>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text # HTML파일의 텍스트 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0543a35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html 파싱\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, #response.text\n",
    "                    \"html.parser\")\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a39d00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n",
      "el.text : Hello, CSS\n",
      "el.string : Hello, CSS\n",
      "el의 속성들 : {'class': ['greeting', 'css'], 'id': 'text'}\n",
      "el의 id속성 : text\n",
      "el의 id속성 : text\n",
      "el의 href속성 : None\n",
      "el의 태그이름 : h1\n"
     ]
    }
   ],
   "source": [
    "# soup.select_one('선택자') : 해당선택자 처음 하나만\n",
    "el = soup.select_one('h1') # 처음 나오는 h1태그 하나만\n",
    "print('el :', el)\n",
    "print('el.text :', el.text)\n",
    "print('el.string :', el.string)\n",
    "print('el의 속성들 :', el.attrs)\n",
    "print('el의 id속성 :', el.attrs['id']) # el.attrs은 딕셔너리\n",
    "print('el의 id속성 :', el.attrs.get('id'))\n",
    "print('el의 href속성 :', el.attrs.get('href'))\n",
    "print('el의 태그이름 :', el.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aca795f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "els : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>]\n",
      "els의 text들 : ['Hello, CSS', 'Hi, CSS']\n",
      "els의 string들 : ['Hello, CSS', 'Hi, CSS']\n",
      "els의 속성들 : [{'class': ['greeting', 'css'], 'id': 'text'}, {'class': ['css']}]\n",
      "els의 class 속성들 : [['greeting', 'css'], ['css']]\n"
     ]
    }
   ],
   "source": [
    "# soup.select('선택자') : 해당 선택자 모두\n",
    "els = soup.select('h1') # h1태그를 list\n",
    "print('els :', els)\n",
    "print('els의 text들 :', [el.text for el in els])\n",
    "print('els의 string들 :', [el.string for el in els])\n",
    "print('els의 속성들 :', [el.attrs for el in els])\n",
    "print('els의 class 속성들 :', [el.attrs.get('class') for el in els])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68a2dd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select_one : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n",
      "find : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n",
      "find : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n",
      "\n",
      "select_one : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n",
      "find : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n"
     ]
    }
   ],
   "source": [
    "# soup.find(태그, 속성) : soup.select_one('선택자')와 유사\n",
    "print('select_one :', soup.select_one('h1.css') )\n",
    "print('find :', soup.find('h1', {'class':'css'}) ) # soup.select_one('h1.css')\n",
    "print('find :', soup.find('h1', class_='css') )\n",
    "print()\n",
    "print('select_one :', soup.select_one('h1#text') )\n",
    "print('find :', soup.find('h1', {'id':'text'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "921596e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>]\n",
      "find_all : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>]\n",
      "find_all : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>]\n"
     ]
    }
   ],
   "source": [
    "# soup.find_all(태그, 속성) : soup.select('선택자')와 유사\n",
    "print('select :', soup.select('h1.css'))\n",
    "print('find_all :', soup.find_all('h1', class_='css'))\n",
    "print('find_all :', soup.find_all('h1', {'class':'css'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa49d49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>, <span>다른<b>요소가 반환</b></span>]\n",
      "find_all : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>]\n",
      "find_all : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>, <span>다른<b>요소가 반환</b></span>]\n"
     ]
    }
   ],
   "source": [
    "print('select :', soup.select('h1.css, span'))\n",
    "print('find_all :', soup.find_all(['h1', 'span'], {'class':'css'}))\n",
    "print('find_all :', soup.find_all('h1', class_='css') + \\\n",
    "                     soup.find_all('span'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "292f9a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select(빈 list) : []\n",
      "select_one(None) : None\n",
      "find_all(빈 list) : []\n",
      "find(None) : None\n"
     ]
    }
   ],
   "source": [
    "# 없는 엘리먼트 찾기\n",
    "print('select(빈 list) :', soup.select('a.css'))\n",
    "print('select_one(None) :', soup.select_one('a.css'))\n",
    "print('find_all(빈 list) :', soup.find_all('a', {'class','css'}))\n",
    "print('find(None) :', soup.find('a', {'class':'css'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e470491",
   "metadata": {},
   "source": [
    "# 2절. 정적 웹 데이터 수집(정적 웹크롤링)\n",
    "## 2.1 BeautifulSoup을 활용한 html 웹 데이터수집\n",
    "### 1) 환율정보 가져오기 (네이버증권 -> 시장지표_)\n",
    "-https://finance.naver.com/marketindex/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f34a788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 허용범위는 사이트마다 ~/robots.txt에서 확인\n",
    "    # Allow : / - 사이트의 모든 경로(/)애ㅔ 대한 크롤링 허용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "465cd4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://finance.naver.com/marketindex/'\n",
    "response = requests.get(url)\n",
    "#response.status_code\n",
    "# response.text / response.content.decode('cp949')\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89a4ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법2\n",
    "from urllib.request import urlopen\n",
    "url = 'https://finance.naver.com/marketindex/'\n",
    "response = urlopen(url)\n",
    "response.status\n",
    "# response.read() / responseread().decode('cp949')\n",
    "soup = BeautifulSoup(response, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3779520c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1464.0, 949.11, 1695.82, 205.57, 153.98, 1.16, 1.318, 99.31, 61.04, 1704.69, 4116.3, 194893.24]\n"
     ]
    }
   ],
   "source": [
    "# div.head_info > span.value (find함수)\n",
    "prices = []\n",
    "headinfos = soup.find_all('div', class_='head_info')\n",
    "for headinfo in headinfos:\n",
    "    price = headinfo.find('span', class_ = 'value')\n",
    "    #print(price.text.repalce(',', ''))\n",
    "    prices.append(float(''.join(price.text.split(','))))\n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d405bb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1464.0, 949.11, 1695.82, 205.57, 153.98, 1.16, 1.318, 99.31, 61.04, 1704.69, 4116.3, 194893.24]\n"
     ]
    }
   ],
   "source": [
    "# div.head_info > span.value (select함수)\n",
    "prices = soup.select('div.head_info > span.value')\n",
    "print([float(p.text.replace(',','')) for p in prices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87e71fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 USD\t일본 JPY(100엔)\t유럽연합 EUR\t중국 CNY\t달러/일본 엔\t유로/달러\t영국 파운드/달러\t달러인덱스\tWTI\t휘발유\t국제 금\t국내 금\t"
     ]
    }
   ],
   "source": [
    "titles = soup.select('h3.h_lst > span.blind')\n",
    "for t in titles:\n",
    "    print(t.text, end='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b3c034b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['원', '원', '원', '원', '엔', '달러', '달러', '', '달러', '원', '달러', '원']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "units = soup.select('div.head_info > span > span.blind')\n",
    "units = [unit.text for unit in units]\n",
    "units.insert(7, '') # 7번째에 '' 추가\n",
    "units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41ef3c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상승\t상승\t상승\t상승\t하락\t상승\t상승\t하락\t상승\t상승\t하락\t상승\t"
     ]
    }
   ],
   "source": [
    "statuses = soup.select('div.head_info > span.blind')\n",
    "for idx in range(len(statuses)):\n",
    "    print(statuses[idx].text, end='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a13f3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 12, 12)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles), len(prices), len(units), len(statuses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b11f42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 USD : 1,464.00원 - 상승\n",
      "일본 JPY(100엔) : 949.11원 - 상승\n",
      "유럽연합 EUR : 1,695.82원 - 상승\n",
      "중국 CNY : 205.57원 - 상승\n",
      "달러/일본 엔 : 153.9800엔 - 하락\n",
      "유로/달러 : 1.1600달러 - 상승\n",
      "영국 파운드/달러 : 1.3180달러 - 상승\n",
      "달러인덱스 : 99.3100 - 하락\n",
      "WTI : 61.04달러 - 상승\n",
      "휘발유 : 1704.69원 - 상승\n",
      "국제 금 : 4116.3달러 - 하락\n",
      "국내 금 : 194893.24원 - 상승\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(titles)):\n",
    "    print(\"{} : {}{} - {}\".format(titles[idx].text,\n",
    "                                 prices[idx].text,\n",
    "                                 units[idx],\n",
    "                                 statuses[idx].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffac0032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 USD : 1,464.00원 -상승\n",
      "일본 JPY(100엔) : 949.11원 -상승\n",
      "유럽연합 EUR : 1,695.82원 -상승\n",
      "중국 CNY : 205.57원 -상승\n",
      "달러/일본 엔 : 153.9800엔 -하락\n",
      "유로/달러 : 1.1600달러 -상승\n",
      "영국 파운드/달러 : 1.3180달러 -상승\n",
      "달러인덱스 : 99.3100 -하락\n",
      "WTI : 61.04달러 -상승\n",
      "휘발유 : 1704.69원 -상승\n",
      "국제 금 : 4116.3달러 -하락\n",
      "국내 금 : 194893.24원 -상승\n"
     ]
    }
   ],
   "source": [
    "for title, price, unit, status in zip(titles, prices, units, statuses):\n",
    "    print(\"{} : {}{} -{}\".format(title.text,\n",
    "                                price.text,\n",
    "                                unit,\n",
    "                                status.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd92ac25",
   "metadata": {},
   "source": [
    "### 2) 이번주 로또 번호 출력\n",
    "- https://dhlottery.co.kr/gameResult.do?method=byWin (google에 로또번호 당첨번호 검색)\n",
    "````\n",
    "11997회(2025년 11월 08일 추첨)\n",
    "당첨번호 [1,5,7,26,28,43]\n",
    "보너스 30\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6ad0205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://dhlottery.co.kr/gameResult.do?method=byWin'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d26cb72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법2\n",
    "from urllib.request import urlopen\n",
    "url = 'https://dhlottery.co.kr/gameResult.do?method=byWin'\n",
    "response = urlopen(url)\n",
    "response.status\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2859bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = soup.select_one('div.win_result strong').text\n",
    "date  = soup.select_one('div.win_result > p.desc').text\n",
    "# date = soup.find('p', class_='desc').text\n",
    "lotto_number_el = soup.select('div.num.win  span')\n",
    "lotto_number = [int(el.text) for el in lotto_number_el]\n",
    "bonus_number = int(soup.select_one('div.num.bonus > p > span').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47f09eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197회 (2025년 11월 08일 추첨)\n",
      "당첨번호  [1, 5, 7, 26, 28, 43]\n",
      "보 너 스  30\n"
     ]
    }
   ],
   "source": [
    "print(times, date)\n",
    "print('당첨번호 ',lotto_number)\n",
    "print('보 너 스 ', bonus_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd45b30",
   "metadata": {},
   "source": [
    "### 3) 다음 검색 리스트\n",
    "```\n",
    "no title   href\n",
    "0 \"한풀 꺾인 비트코인 https://daum.net/v/202511110094711892\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b7a043c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q=비트코인\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>가상자산 일제히 급락… 비트코인 10만달러 위태</td>\n",
       "      <td>http://v.daum.net/v/20251112080939100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>큰손들은 털고 나간다…비트코인 10만 달러 붕괴 조짐</td>\n",
       "      <td>http://v.daum.net/v/20251112082149370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>‘비트코인 9.6조 압수’ 中 사기범, 영국서 징역 11년 8개월형</td>\n",
       "      <td>http://v.daum.net/v/20251112093346011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>영국서 초호화생활 중국인 여성 중형, 왜?…다단계 사기로 ‘비트코인 10조’ 세탁</td>\n",
       "      <td>http://v.daum.net/v/20251112093904308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>압수 비트코인만 9조원···사기친 돈 세탁한 중국인 영국서 징역 11년</td>\n",
       "      <td>http://v.daum.net/v/20251112094247439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"비트코인 9조 최대 압수\"...'중국 가상화폐 여왕' 영국서 징역 11년</td>\n",
       "      <td>http://v.daum.net/v/20251112064009731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>비트코인 9조 4천억 압수...자금세탁 중국인 징역11년8개월</td>\n",
       "      <td>http://v.daum.net/v/20251112073602477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>“새로운 기부라고 생각” 서울대병원에 1비트코인 기부한 70대…가격 보니</td>\n",
       "      <td>http://v.daum.net/v/20251112064050739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>꿈틀대던 비트코인, 다시 10.5만달러대…'고래 매도' 조정 신호?</td>\n",
       "      <td>http://v.daum.net/v/20251111161648648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>70대 개인투자자, 서울대병원에 '1비트코인' 기부…\"새로운 형태 나눔 문화 확산...</td>\n",
       "      <td>http://v.daum.net/v/20251112090849904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                              title  \\\n",
       "0   0                        가상자산 일제히 급락… 비트코인 10만달러 위태    \n",
       "1   1                     큰손들은 털고 나간다…비트코인 10만 달러 붕괴 조짐    \n",
       "2   2             ‘비트코인 9.6조 압수’ 中 사기범, 영국서 징역 11년 8개월형    \n",
       "3   3     영국서 초호화생활 중국인 여성 중형, 왜?…다단계 사기로 ‘비트코인 10조’ 세탁    \n",
       "4   4           압수 비트코인만 9조원···사기친 돈 세탁한 중국인 영국서 징역 11년    \n",
       "5   5         \"비트코인 9조 최대 압수\"...'중국 가상화폐 여왕' 영국서 징역 11년    \n",
       "6   6                비트코인 9조 4천억 압수...자금세탁 중국인 징역11년8개월    \n",
       "7   7          “새로운 기부라고 생각” 서울대병원에 1비트코인 기부한 70대…가격 보니    \n",
       "8   8             꿈틀대던 비트코인, 다시 10.5만달러대…'고래 매도' 조정 신호?    \n",
       "9   9   70대 개인투자자, 서울대병원에 '1비트코인' 기부…\"새로운 형태 나눔 문화 확산...   \n",
       "\n",
       "                                    link  \n",
       "0  http://v.daum.net/v/20251112080939100  \n",
       "1  http://v.daum.net/v/20251112082149370  \n",
       "2  http://v.daum.net/v/20251112093346011  \n",
       "3  http://v.daum.net/v/20251112093904308  \n",
       "4  http://v.daum.net/v/20251112094247439  \n",
       "5  http://v.daum.net/v/20251112064009731  \n",
       "6  http://v.daum.net/v/20251112073602477  \n",
       "7  http://v.daum.net/v/20251112064050739  \n",
       "8  http://v.daum.net/v/20251111161648648  \n",
       "9  http://v.daum.net/v/20251112090849904  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "word = '비트코인'\n",
    "url = 'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q='+word\n",
    "print(url)\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "items_find_list = [] #검색한 결과를 담을 리스트\n",
    "items_el = soup.select('div.item-title > strong.tit-g > a')\n",
    "for idx, item in enumerate(items_el):\n",
    "    #print(idx, item.text, item.attrs.get('href'))\n",
    "    items_find_list.append({'no':idx,\n",
    "                           'title':item.text,\n",
    "                           'link':item.attrs.get('href')})\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(items_find_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ba10669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q=%EB%B9%84%ED%8A%B8%EC%BD%94%EC%9D%B8\n"
     ]
    }
   ],
   "source": [
    "# 방법2 : 불가\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote\n",
    "word = quote('비트코인') # url에 한글이 포함된 경우 한글을 quote()로 변환\n",
    "url = 'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q='+word\n",
    "print(url)\n",
    "response = urlopen(url)\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df7d3de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>번호</th>\n",
       "      <th>제목</th>\n",
       "      <th>링크</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>가상자산 일제히 급락… 비트코인 10만달러 위태</td>\n",
       "      <td>http://v.daum.net/v/20251112080939100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>큰손들은 털고 나간다…비트코인 10만 달러 붕괴 조짐</td>\n",
       "      <td>http://v.daum.net/v/20251112082149370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>‘비트코인 9.6조 압수’ 中 사기범, 영국서 징역 11년 8개월형</td>\n",
       "      <td>http://v.daum.net/v/20251112093346011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>영국서 초호화생활 중국인 여성 중형, 왜?…다단계 사기로 ‘비트코인 10조’ 세탁</td>\n",
       "      <td>http://v.daum.net/v/20251112093904308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>압수 비트코인만 9조원···사기친 돈 세탁한 중국인 영국서 징역 11년</td>\n",
       "      <td>http://v.daum.net/v/20251112094247439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"비트코인 9조 최대 압수\"...'중국 가상화폐 여왕' 영국서 징역 11년</td>\n",
       "      <td>http://v.daum.net/v/20251112064009731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>비트코인 9조 4천억 압수...자금세탁 중국인 징역11년8개월</td>\n",
       "      <td>http://v.daum.net/v/20251112073602477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>“새로운 기부라고 생각” 서울대병원에 1비트코인 기부한 70대…가격 보니</td>\n",
       "      <td>http://v.daum.net/v/20251112064050739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>꿈틀대던 비트코인, 다시 10.5만달러대…'고래 매도' 조정 신호?</td>\n",
       "      <td>http://v.daum.net/v/20251111161648648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>70대 개인투자자, 서울대병원에 '1비트코인' 기부…\"새로운 형태 나눔 문화 확산...</td>\n",
       "      <td>http://v.daum.net/v/20251112090849904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   번호                                                 제목  \\\n",
       "0   0                        가상자산 일제히 급락… 비트코인 10만달러 위태    \n",
       "1   1                     큰손들은 털고 나간다…비트코인 10만 달러 붕괴 조짐    \n",
       "2   2             ‘비트코인 9.6조 압수’ 中 사기범, 영국서 징역 11년 8개월형    \n",
       "3   3     영국서 초호화생활 중국인 여성 중형, 왜?…다단계 사기로 ‘비트코인 10조’ 세탁    \n",
       "4   4           압수 비트코인만 9조원···사기친 돈 세탁한 중국인 영국서 징역 11년    \n",
       "5   5         \"비트코인 9조 최대 압수\"...'중국 가상화폐 여왕' 영국서 징역 11년    \n",
       "6   6                비트코인 9조 4천억 압수...자금세탁 중국인 징역11년8개월    \n",
       "7   7          “새로운 기부라고 생각” 서울대병원에 1비트코인 기부한 70대…가격 보니    \n",
       "8   8             꿈틀대던 비트코인, 다시 10.5만달러대…'고래 매도' 조정 신호?    \n",
       "9   9   70대 개인투자자, 서울대병원에 '1비트코인' 기부…\"새로운 형태 나눔 문화 확산...   \n",
       "\n",
       "                                      링크  \n",
       "0  http://v.daum.net/v/20251112080939100  \n",
       "1  http://v.daum.net/v/20251112082149370  \n",
       "2  http://v.daum.net/v/20251112093346011  \n",
       "3  http://v.daum.net/v/20251112093904308  \n",
       "4  http://v.daum.net/v/20251112094247439  \n",
       "5  http://v.daum.net/v/20251112064009731  \n",
       "6  http://v.daum.net/v/20251112073602477  \n",
       "7  http://v.daum.net/v/20251112064050739  \n",
       "8  http://v.daum.net/v/20251111161648648  \n",
       "9  http://v.daum.net/v/20251112090849904  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_find_list = [] #검색한 결과를 담을 리스트\n",
    "items_el = soup.select('div.item-title > strong.tit-g > a')\n",
    "for idx, item in enumerate(items_el):\n",
    "    items_find_list.append([idx, item.text, item.attrs['href']])\n",
    "pd.DataFrame(items_find_list, columns=['번호','제목','링크'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "473ee51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>가상자산 일제히 급락… 비트코인 10만달러 위태</td>\n",
       "      <td>http://v.daum.net/v/20251112080939100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>큰손들은 털고 나간다…비트코인 10만 달러 붕괴 조짐</td>\n",
       "      <td>http://v.daum.net/v/20251112082149370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>‘비트코인 9.6조 압수’ 中 사기범, 영국서 징역 11년 8개월형</td>\n",
       "      <td>http://v.daum.net/v/20251112093346011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>영국서 초호화생활 중국인 여성 중형, 왜?…다단계 사기로 ‘비트코인 10조’ 세탁</td>\n",
       "      <td>http://v.daum.net/v/20251112093904308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>압수 비트코인만 9조원···사기친 돈 세탁한 중국인 영국서 징역 11년</td>\n",
       "      <td>http://v.daum.net/v/20251112094247439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"비트코인 9조 최대 압수\"...'중국 가상화폐 여왕' 영국서 징역 11년</td>\n",
       "      <td>http://v.daum.net/v/20251112064009731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>비트코인 9조 4천억 압수...자금세탁 중국인 징역11년8개월</td>\n",
       "      <td>http://v.daum.net/v/20251112073602477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>“새로운 기부라고 생각” 서울대병원에 1비트코인 기부한 70대…가격 보니</td>\n",
       "      <td>http://v.daum.net/v/20251112064050739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>꿈틀대던 비트코인, 다시 10.5만달러대…'고래 매도' 조정 신호?</td>\n",
       "      <td>http://v.daum.net/v/20251111161648648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>70대 개인투자자, 서울대병원에 '1비트코인' 기부…\"새로운 형태 나눔 문화 확산...</td>\n",
       "      <td>http://v.daum.net/v/20251112090849904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                              title  \\\n",
       "0   0                        가상자산 일제히 급락… 비트코인 10만달러 위태    \n",
       "1   1                     큰손들은 털고 나간다…비트코인 10만 달러 붕괴 조짐    \n",
       "2   2             ‘비트코인 9.6조 압수’ 中 사기범, 영국서 징역 11년 8개월형    \n",
       "3   3     영국서 초호화생활 중국인 여성 중형, 왜?…다단계 사기로 ‘비트코인 10조’ 세탁    \n",
       "4   4           압수 비트코인만 9조원···사기친 돈 세탁한 중국인 영국서 징역 11년    \n",
       "5   5         \"비트코인 9조 최대 압수\"...'중국 가상화폐 여왕' 영국서 징역 11년    \n",
       "6   6                비트코인 9조 4천억 압수...자금세탁 중국인 징역11년8개월    \n",
       "7   7          “새로운 기부라고 생각” 서울대병원에 1비트코인 기부한 70대…가격 보니    \n",
       "8   8             꿈틀대던 비트코인, 다시 10.5만달러대…'고래 매도' 조정 신호?    \n",
       "9   9   70대 개인투자자, 서울대병원에 '1비트코인' 기부…\"새로운 형태 나눔 문화 확산...   \n",
       "\n",
       "                                    link  \n",
       "0  http://v.daum.net/v/20251112080939100  \n",
       "1  http://v.daum.net/v/20251112082149370  \n",
       "2  http://v.daum.net/v/20251112093346011  \n",
       "3  http://v.daum.net/v/20251112093904308  \n",
       "4  http://v.daum.net/v/20251112094247439  \n",
       "5  http://v.daum.net/v/20251112064009731  \n",
       "6  http://v.daum.net/v/20251112073602477  \n",
       "7  http://v.daum.net/v/20251112064050739  \n",
       "8  http://v.daum.net/v/20251111161648648  \n",
       "9  http://v.daum.net/v/20251112090849904  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "items_find_list = [] # 검색한 결과를 담을 리스트\n",
    "# div.item-title > strong.tit-g > a\n",
    "item_titles = soup.find_all('div', class_='item-title')\n",
    "for idx, item in enumerate(item_titles):\n",
    "    a = item.find('a')\n",
    "    #print(idx, a.text, a.attrs['href'])\n",
    "    #items_find_list.append([idx, a.text, a.attrs['href']])\n",
    "    items_find_list.append({\n",
    "        'no':idx,\n",
    "        'title':a.text,\n",
    "        'link':a.attrs['href'],\n",
    "    })\n",
    "pd.DataFrame(items_find_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb761386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 뉴스 검색(원하는 키워드를 원하는 페이지를 가져오기)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "def collect_news_list(keyword, page):\n",
    "    'keyword로 page에 다음 뉴스검색한 결과를 출력->list를 return'\n",
    "    #url = f'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q={keyword}&p={page}'\n",
    "    # response = requests.get(url)\n",
    "    url = f'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8'\n",
    "    params = {'q':keyword, 'p':page}\n",
    "    response = requests.get(url, params=params)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    items_find_list = [] # 검색한 결과를 담는 리스트\n",
    "    item_titles = soup.select('div.item-title > strong.tit-g > a')\n",
    "    print(keyword)\n",
    "    for idx, item in enumerate(item_titles):\n",
    "        items_find_list.append([(page-1)*10+idx, item.text, item.attrs['href']])\n",
    "    return items_find_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43b4a7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비트코인\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[20,\n",
       "  ' 파생상품 대거 청산, 암호화폐 일제 하락…리플 5%↓(상보) ',\n",
       "  'http://v.daum.net/v/20251112073111389'],\n",
       " [21,\n",
       "  ' 투자 사기 후 영국으로 도주한 중국인… 법원 \"비트코인 9조원 압수\" ',\n",
       "  'http://v.daum.net/v/20251112083740757'],\n",
       " [22,\n",
       "  ' 코스피 4097.44에 하락 출발…환율 1461원 ',\n",
       "  'http://v.daum.net/v/20251112090609808'],\n",
       " [23,\n",
       "  ' 비트코인, 美 정부 셧다운 해제 관망에 10만6000달러선 [크립토브리핑] ',\n",
       "  'http://v.daum.net/v/20251111103648808'],\n",
       " [24,\n",
       "  ' 개미 투자자 ‘데이터 무장’ 돕는다…업비트, 데이터랩 ‘인사이트’ 기능 강화 ',\n",
       "  'http://v.daum.net/v/20251112090600801'],\n",
       " [25,\n",
       "  \" 9조 비트코인 들고 런던으로 튄 '中 폰지의 여왕', 징역 11년8개월 \",\n",
       "  'http://v.daum.net/v/20251112062715613'],\n",
       " [26,\n",
       "  ' 美 ‘셧다운 해제 기대감’에 가상자산 오름세… 비트코인 10만6200달러 ',\n",
       "  'http://v.daum.net/v/20251111083345066'],\n",
       " [27,\n",
       "  ' 12만명 속여 ‘비트코인 9조’ 40대 중국여성…도망간 英서 징역 11년8개월 ',\n",
       "  'http://v.daum.net/v/20251112064227765'],\n",
       " [28,\n",
       "  ' \"내년에도 비트코인·K-방산\"…\\'지정학적 위기\\' 뜨는 자산 ',\n",
       "  'http://v.daum.net/v/20251110095715363'],\n",
       " [29,\n",
       "  ' 서울대병원, 첫 비트코인 기부 받았다…1억5700만원 병원발전기금으로 ',\n",
       "  'http://v.daum.net/v/20251111170538874']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_news_list('비트코인', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9e459d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===1번쨰 검색어 청바지 검색 결과 수집 중입니다===\n",
      "청바지\n",
      "청바지\n",
      "청바지\n",
      "===2번쨰 검색어 동대문 검색 결과 수집 중입니다===\n",
      "동대문\n",
      "동대문\n",
      "동대문\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "keywords = ['청바지','동대문']\n",
    "result0 = [] # 청바지 1~3페이지까지 검색한 결과를 담을 list\n",
    "result1 = [] # 동대문 1~3페이지까지 검색한 결괄르 담을 list\n",
    "pages = 3\n",
    "for i, keyword in enumerate(keywords):\n",
    "    print(f'==={i+1}번쨰 검색어 {keyword} 검색 결과 수집 중입니다===')\n",
    "    for page in range(1, pages+1):\n",
    "        if i==0:\n",
    "            result0.extend(collect_news_list(keyword,page))\n",
    "        elif i == 1:\n",
    "            result1.extend(collect_news_list(keyword,page))\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51e10924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>“돈 벌어가세요” 동대문 일요시장, 겨울옷 ‘핫플’ 됐다</td>\n",
       "      <td>http://v.daum.net/v/20251111111251709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>동대문구, 사회복지시설 종사자 독감 예방접종 비용 지원</td>\n",
       "      <td>http://v.daum.net/v/20251112081345203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>동대문구, ‘2025 아이돌봄서비스 평가’ A등급(우수) 선정</td>\n",
       "      <td>http://v.daum.net/v/20251111172914828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>노보텔 앰배서더 동대문, 연말 맞아 '페스티브 파티’ 패키지 출시</td>\n",
       "      <td>http://v.daum.net/v/20251111155426418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>동대문구, 11월 학부모·학생 맞춤형 교육 특강</td>\n",
       "      <td>http://v.daum.net/v/20251111151146411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                   title  \\\n",
       "0   0        “돈 벌어가세요” 동대문 일요시장, 겨울옷 ‘핫플’ 됐다    \n",
       "1   1         동대문구, 사회복지시설 종사자 독감 예방접종 비용 지원    \n",
       "2   2     동대문구, ‘2025 아이돌봄서비스 평가’ A등급(우수) 선정    \n",
       "3   3   노보텔 앰배서더 동대문, 연말 맞아 '페스티브 파티’ 패키지 출시    \n",
       "4   4             동대문구, 11월 학부모·학생 맞춤형 교육 특강    \n",
       "\n",
       "                                    link  \n",
       "0  http://v.daum.net/v/20251111111251709  \n",
       "1  http://v.daum.net/v/20251112081345203  \n",
       "2  http://v.daum.net/v/20251111172914828  \n",
       "3  http://v.daum.net/v/20251111155426418  \n",
       "4  http://v.daum.net/v/20251111151146411  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0_df = pd.DataFrame(result0, columns=['no','title','link'])\n",
    "result1_df = pd.DataFrame(result1, columns=['no','title','link'])\n",
    "result1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2b682e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result0_df.to_csv('data/ch14_{keywords{0}}.csv',index=False, encoding='cp949')\n",
    "result1_df.to_csv('data/ch14_{keywords{1}}.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0178fc27",
   "metadata": {},
   "source": [
    "### 4) User-Agent를 추가하여 크롤링\n",
    "- 자동으로 브라어저를 통해 요청하는 것 처럼 보이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f116d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q=%EB%B9%84%ED%8A%B8%EC%BD%94%EC%9D%B8\n"
     ]
    }
   ],
   "source": [
    "# 방법2 :\n",
    "from urllib.request import urlopen, Request\n",
    "from urllib.parse import quote\n",
    "word = quote('비트코인') # 한글을 encoding 처리\n",
    "url = 'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q='+word\n",
    "print(url)\n",
    "# headers = {'User-Agent':\n",
    "#           'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'}\n",
    "# request = Request(url, headers = headers)\n",
    "request = Request(url)\n",
    "request.add_header('User-Agent',\n",
    "                  'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36')\n",
    "response = urlopen(request)\n",
    "soup = BeautifulSoup(response, 'html.parser')\n",
    "# soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad2445b",
   "metadata": {},
   "source": [
    "###4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab3bb70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법 1\n",
    "import requests\n",
    "url = 'https://www.melon.com/chart/hot100/index.htm'\n",
    "melonpage = requests.get(url)\n",
    "melonpage\n",
    "soup = BeautifulSoup(melonpage.text, 'html.parser')\n",
    "soup\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2753485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법2\n",
    "from urllib.request import urlopen, Request\n",
    "url = 'https://www.melon.com/chart/hot100/index.htm'\n",
    "# melonpage = urlopen(url) # 에러남\n",
    "headers = {'user-agent':\n",
    "          'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'}\n",
    "request = Request(url, headers=headers)\n",
    "melonpage = urlopen(request)\n",
    "soup = BeautifulSoup(melonpage, 'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d808ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1위 | Blue Valentine - NMIXX\n",
      "2위 | 타임캡슐 - 다비치\n",
      "3위 | 달리 표현할 수 없어요 - 로이킴\n",
      "4위 | SPAGHETTI (feat. j-hope of BTS) - LE SSERAFIM (르세라핌), \n",
      "5위 | Good Goodbye - 화사 (HWASA)\n",
      "6위 | IRIS OUT - Kenshi Yonezu\n",
      "7위 | 시작의 아이 ❍ - 박다혜, 마크툽 (MAKTUB)\n",
      "8위 | Hollywood Action - BOYNEXTDOOR\n",
      "9위 | XOXZ - IVE (아이브)\n",
      "10위 | 한번 더 이별 - 이창섭\n",
      "11위 | Rich Man - aespa\n",
      "12위 | body - 다영 (DAYOUNG)\n",
      "13위 | FOCUS - Hearts2Hearts (하츠투하츠\n",
      "14위 | BBUU! - PLAVE\n",
      "15위 | 순간을 영원처럼 - 임영웅\n",
      "16위 | 봉숭아 - PLAVE\n",
      "17위 | OVERDRIVE - TWS (투어스)\n",
      "18위 | 들꽃이 될게요 - 임영웅\n",
      "19위 | JANE DOE - Kenshi Yonezu, Hikar\n",
      "20위 | 그댈 위한 멜로디 - 임영웅\n",
      "21위 | 숨바꼭질 (Hide and Seek) - PLAVE\n",
      "22위 | 비가 와서 - 임영웅\n",
      "23위 | 가만히 눈을 감고 - DK(디셈버)\n",
      "24위 | 답장을 보낸지 - 임영웅\n",
      "25위 | 나였으면 - 나윤권, 도경수(D.O.)\n",
      "26위 | 알겠어요 미안해요 - 임영웅\n",
      "27위 | ULSSIGU - 임영웅\n",
      "28위 | 바이, 썸머 - 아이유\n",
      "29위 | Wonderful Life - 임영웅\n",
      "30위 | 꿈의 버스 - DAY6 (데이식스)\n",
      "31위 | 숨바꼭질 (Hide and Seek) - PLAVE\n",
      "32위 | 돌아보지 마세요 - 임영웅\n",
      "33위 | 나는야 HERO - 임영웅\n",
      "34위 | 우리에게 안녕 - 임영웅\n",
      "35위 | 당신을 위하여 - 이보람 (씨야)\n",
      "36위 | 있잖아 - BOYNEXTDOOR\n",
      "37위 | Be My Light - 이세계아이돌\n",
      "38위 | 0+0 - 한로로\n",
      "39위 | Nameless - 이세계아이돌\n",
      "40위 | WE GO UP - BABYMONSTER\n",
      "41위 | BURNING UP - MEOVV (미야오)\n",
      "42위 | 바래다 주는 길 - 윤민수(바이브), 이예준\n",
      "43위 | GO! - CORTIS (코르티스)\n",
      "44위 | INSIDE OUT - DAY6 (데이식스)\n",
      "45위 | 어떻게 사랑이 그래요 - 최은빈\n",
      "46위 | 주르르 - 이창섭\n",
      "47위 | Stargazers - 이세계아이돌\n",
      "48위 | ELEVATE - 이세계아이돌\n",
      "49위 | Mamma Mia - izna (이즈나)\n",
      "50위 | MEMORY - 이세계아이돌\n",
      "51위 | 사랑만 해두자 - 경서\n",
      "52위 | Live In Paris - BOYNEXTDOOR\n",
      "53위 | To Me From Me (Prod. TABLO) - KiiiKiii (키키)\n",
      "54위 | 딱 1년만 (Feat. 10CM) - BIG Naughty (서동현)\n",
      "55위 | 그대가 분다 - HYNN (박혜원)\n",
      "56위 | 끝사랑 - 권진아\n",
      "57위 | Stay - 어반자카파\n",
      "58위 | Pretty Please - Hearts2Hearts (하츠투하츠\n",
      "59위 | Bathroom - BOYNEXTDOOR\n",
      "60위 | Talk to You - 연준\n",
      "61위 | I'll Never Love Again - WOODZ\n",
      "62위 | 밤하늘의 별을(더 리슨 5) - 허각, 켄(KEN), 권진아, ASH\n",
      "63위 | JAM! - BOYNEXTDOOR\n",
      "64위 | CYNICAL - 선미\n",
      "65위 | SPINNIN′ ON IT - NMIXX\n",
      "66위 | TUNNEL VISION - ITZY (있지)\n",
      "67위 | FaSHioN - CORTIS (코르티스)\n",
      "68위 | 비라도 내렸으면 좋겠어 - 폴킴\n",
      "69위 | Surf - NCT WISH\n",
      "70위 | blue - yung kai\n",
      "71위 | 지나왔던 추억이 사랑이 되고 - 이무진\n",
      "72위 | Ruin My Life - BOYNEXTDOOR\n",
      "73위 | number one rockstar - 다영 (DAYOUNG)\n",
      "74위 | Let Me Tell You (feat. Daniela of KATSEYE) - 연준, Daniela\n",
      "75위 | 내게 남은 사랑을 드릴께요 - 최유리\n",
      "76위 | 왜 그래 - 임지성\n",
      "77위 | Coma - 연준\n",
      "78위 | 탈진 - 하동균\n",
      "79위 | 오늘은 왠지 - 이찬원\n",
      "80위 | 첫사랑은 안녕히- - 잔나비\n",
      "81위 | 바이 바이 (Feat. 이무진) - BIG Naughty (서동현)\n",
      "82위 | Forever - 연준\n",
      "83위 | Falling (Feat. Young K (DAY6)) - WOODZ\n",
      "84위 | 사랑한 마음엔 죄가 없다 - 소란 (SORAN)\n",
      "85위 | Tiger - 더보이즈 (THE BOYZ)\n",
      "86위 | 처음 불러보는 노래 - KickFlip(킥플립)\n",
      "87위 | 가위바위보 - FIFTY FIFTY\n",
      "88위 | 시간을 넘어 너에게로 - 도영 (DOYOUNG)\n",
      "89위 | Do It - 연준\n",
      "90위 | Nothin’ ’Bout Me - 연준\n",
      "91위 | 사랑은 어쩌고 - LUCY\n",
      "92위 | 나의 오랜 여행 - 이찬원\n",
      "93위 | 우리들의 순간 - 브라운 아이드 소울\n",
      "94위 | DANCING ALONE - KiiiKiii (키키)\n",
      "95위 | 있어줘요 - 허각\n",
      "96위 | 시월의 시 - 이찬원\n",
      "97위 | 하루 - 수지 (Suzy)\n",
      "98위 | 1월부터 6월까지 - 김윤이\n",
      "99위 | SAY CHEESE! - BOYNEXTDOOR\n",
      "100위 | 해야 뜨지 말아 줘 - DAY6 (데이식스)\n"
     ]
    }
   ],
   "source": [
    "# 방법1 : User-Agent 추가\n",
    "url = 'https://www.melon.com/chart/hot100/index.htm'\n",
    "\n",
    "headers = {'user-agent':\n",
    "          'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'}\n",
    "\n",
    "melonpage  = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(melonpage.text, # melponpage.content\n",
    "                    'html.parser')\n",
    "ranks = soup.select('td div.wrap.t_center > span.rank')\n",
    "\n",
    "titles = soup.select('div.ellipsis.rank01 > span')\n",
    "\n",
    "singers = soup.select('div.ellipsis.rank02 > span')\n",
    "\n",
    "#[singer.text.strip()[:20] for singer in singers]\n",
    "\n",
    "for rank, title, singer in zip(ranks, titles, singers):\n",
    "    print(f'{rank.text}위 | {title.text.strip()} - {singer.text.strip()[:20]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea1cc8b",
   "metadata": {},
   "source": [
    "### 5) 네이버 지식인으로 검색(open API 사용X)\n",
    "- 특정 keyword를 특정페이지 수만큼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a723b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 방법1\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "keyword = '쳇지피티'\n",
    "# url = 'https://kin.naver.com/search/list.naver'\n",
    "# params = {'query' : keyword}\n",
    "# response = get(url, params=params)\n",
    "url = f'https://kin.naver.com/search/list.naver?query={keyword}'\n",
    "response = get(url)\n",
    "print(response.status_code)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5a3c89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://kin.naver.com/search/list.naver?query=%EC%B3%87%EC%A7%80%ED%94%BC%ED%8B%B0\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# 방법2\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote\n",
    "keyword = quote('쳇지피티')\n",
    "url = f'https://kin.naver.com/search/list.naver?query={keyword}'\n",
    "print(url)\n",
    "response = urlopen(url)\n",
    "print(response.status)\n",
    "soup = BeautifulSoup(response, 'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42064d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 2)\n",
      "https://kin.naver.com/qna/detail.naver?d1id=1&dirId=10303&docId=484943564&qb=7LOH7KeA7ZS87Yuw&enc=utf8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>쳇지피티 사주 정확성</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=3&amp;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title                                               link\n",
       "0  쳇지피티 사주 정확성  https://kin.naver.com/qna/detail.naver?d1id=3&..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 페이징 포함\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "keyword = quote('쳇지피티')\n",
    "pages = 3\n",
    "items_list = [] # 크롤링한 데이터를 담을 list(title, link)\n",
    "for page in range(1, pages+1):\n",
    "    url = f'https://kin.naver.com/search/list.naver?query={keyword}&page={page}'\n",
    "    response = urlopen(url)\n",
    "    # print(response.status)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    items = soup.select('dt > a')\n",
    "    for item in items:\n",
    "        title = item.text\n",
    "        link  = item.attrs.get('href')\n",
    "        items_list.append({\n",
    "            'title': title,\n",
    "            'link' : link\n",
    "        })\n",
    "df = pd.DataFrame(items_list)\n",
    "print(df.shape)\n",
    "print(df.loc[29, 'link'])\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cde557",
   "metadata": {},
   "source": [
    "## 2.2 openAPI사용 : json 웹데이터 수집\n",
    "### 1) 네이버 지식인으로 검색(open API 사용 O)\n",
    "- 네이버 개발자센터에서 애플리케이션 등록(이름/검색/WEB설정http://localhost)\n",
    "- .env파일에 CLIEnt_ID/CLIENT_SECRET 환경변수 저장\n",
    "- 환경변수를 읽기 위해서 `pip install dotenv`\n",
    "- 특정 keyword를 지식검색(데이터수 30개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a00dec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\admin\\anaconda3\\lib\\site-packages (from dotenv) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dba3f1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경변수 읽어오기\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\n",
    "    #dotenv_path='.env'\n",
    "           )# 현 소스와 같은 폴더내의 .env를 메모리에 Load\n",
    "\n",
    "#print(os.getenv('CLIENT_ID'))\n",
    "#print(os.getenv('CLIENT_SECRET'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec56c498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "{\n",
      "\t\"lastBuildDate\":\"Wed, 12 Nov 2025 09:44:00 +090\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>쳇지피티 사주 정확성</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=3&amp;...</td>\n",
       "      <td>쳇지피티 사주 정확성 몇프로 정도 될까요? 큰틀은 얼추 맞는거 같기도하고 모르겠네요...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>쳇지피티 질문</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=1&amp;...</td>\n",
       "      <td>제가 쳇지피티 한테 물어볼게 있어서 지피티야 이러면서 운을 뗐는데 애가 갑자기 제 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>쳇지피티 관해서</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=1&amp;...</td>\n",
       "      <td>쳇지피티한테 질문 제대로 하려면 어떻게 해야 하냐요?... 쳇지피티 한테 하는질문도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>사주에서 뭐가 부족한지 봐주세요(쳇지피티 답변 금지)</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=3&amp;...</td>\n",
       "      <td>사주에서 뭐가 부족한지 봐주세요(쳇지피티 답변 금지) 남매입니다 남자 1986년 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>쳇지피티 유료로 전환시</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=1&amp;...</td>\n",
       "      <td>쳇지피티 무료버전으로 카톡대화창 전송해서 상대의심리에 관한 분석요청을 많이했는데 첨...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  \\\n",
       "0                    쳇지피티 사주 정확성   \n",
       "1                        쳇지피티 질문   \n",
       "2                       쳇지피티 관해서   \n",
       "3  사주에서 뭐가 부족한지 봐주세요(쳇지피티 답변 금지)   \n",
       "4                   쳇지피티 유료로 전환시   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://kin.naver.com/qna/detail.naver?d1id=3&...   \n",
       "1  https://kin.naver.com/qna/detail.naver?d1id=1&...   \n",
       "2  https://kin.naver.com/qna/detail.naver?d1id=1&...   \n",
       "3  https://kin.naver.com/qna/detail.naver?d1id=3&...   \n",
       "4  https://kin.naver.com/qna/detail.naver?d1id=1&...   \n",
       "\n",
       "                                         description  \n",
       "0  쳇지피티 사주 정확성 몇프로 정도 될까요? 큰틀은 얼추 맞는거 같기도하고 모르겠네요...  \n",
       "1  제가 쳇지피티 한테 물어볼게 있어서 지피티야 이러면서 운을 뗐는데 애가 갑자기 제 ...  \n",
       "2  쳇지피티한테 질문 제대로 하려면 어떻게 해야 하냐요?... 쳇지피티 한테 하는질문도...  \n",
       "3  사주에서 뭐가 부족한지 봐주세요(쳇지피티 답변 금지) 남매입니다 남자 1986년 9...  \n",
       "4  쳇지피티 무료버전으로 카톡대화창 전송해서 상대의심리에 관한 분석요청을 많이했는데 첨...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#방법2\n",
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "client_id = os.getenv('CLIENT_ID')\n",
    "client_secret = os.getenv('CLIENT_SECRET')\n",
    "encText = urllib.parse.quote(\"쳇지피티\")\n",
    "url = \"https://openapi.naver.com/v1/search/kin?query=\" + encText # JSON 결과\n",
    "# request = urllib.request.Request(url)\n",
    "# request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "# request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "headers = {\n",
    "    'X-Naver-Client-Id':client_id,\n",
    "    'X-Naver-Client-Secret':client_secret\n",
    "}\n",
    "request = urllib.request.Request(url, headers=headers)\n",
    "response = urllib.request.urlopen(request)\n",
    "rescode = response.status\n",
    "if(rescode==200):\n",
    "    response_body = response.read()\n",
    "    print(type(response_body.decode('utf-8')))\n",
    "    print(response_body.decode('utf-8')[:50])\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)\n",
    "items = json.loads(response_body.decode('utf-8'))['items']\n",
    "items_list = []\n",
    "for item in items:\n",
    "    title = item['title'].replace('<b>','').replace('</b>','')\n",
    "    link  = item.get('link')\n",
    "    description = item.get('description').replace('<b>','').replace('</b>','')\n",
    "    items_list.append([title, link, description])\n",
    "pd.DataFrame(items_list, columns=['title', 'link', 'description']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc0a3f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>쳇지피티 사주 정확성</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=3&amp;...</td>\n",
       "      <td>쳇지피티 사주 정확성 몇프로 정도 될까요? 큰틀은 얼추 맞는거 같기도하고 모르겠네요...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>쳇지피티 질문</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=1&amp;...</td>\n",
       "      <td>제가 쳇지피티 한테 물어볼게 있어서 지피티야 이러면서 운을 뗐는데 애가 갑자기 제 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>쳇지피티 관해서</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=1&amp;...</td>\n",
       "      <td>쳇지피티한테 질문 제대로 하려면 어떻게 해야 하냐요?... 쳇지피티 한테 하는질문도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>사주에서 뭐가 부족한지 봐주세요(쳇지피티 답변 금지)</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=3&amp;...</td>\n",
       "      <td>사주에서 뭐가 부족한지 봐주세요(쳇지피티 답변 금지) 남매입니다 남자 1986년 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>쳇지피티 유료로 전환시</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=1&amp;...</td>\n",
       "      <td>쳇지피티 무료버전으로 카톡대화창 전송해서 상대의심리에 관한 분석요청을 많이했는데 첨...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  \\\n",
       "0                    쳇지피티 사주 정확성   \n",
       "1                        쳇지피티 질문   \n",
       "2                       쳇지피티 관해서   \n",
       "3  사주에서 뭐가 부족한지 봐주세요(쳇지피티 답변 금지)   \n",
       "4                   쳇지피티 유료로 전환시   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://kin.naver.com/qna/detail.naver?d1id=3&...   \n",
       "1  https://kin.naver.com/qna/detail.naver?d1id=1&...   \n",
       "2  https://kin.naver.com/qna/detail.naver?d1id=1&...   \n",
       "3  https://kin.naver.com/qna/detail.naver?d1id=3&...   \n",
       "4  https://kin.naver.com/qna/detail.naver?d1id=1&...   \n",
       "\n",
       "                                         description  \n",
       "0  쳇지피티 사주 정확성 몇프로 정도 될까요? 큰틀은 얼추 맞는거 같기도하고 모르겠네요...  \n",
       "1  제가 쳇지피티 한테 물어볼게 있어서 지피티야 이러면서 운을 뗐는데 애가 갑자기 제 ...  \n",
       "2  쳇지피티한테 질문 제대로 하려면 어떻게 해야 하냐요?... 쳇지피티 한테 하는질문도...  \n",
       "3  사주에서 뭐가 부족한지 봐주세요(쳇지피티 답변 금지) 남매입니다 남자 1986년 9...  \n",
       "4  쳇지피티 무료버전으로 카톡대화창 전송해서 상대의심리에 관한 분석요청을 많이했는데 첨...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법1\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json # response텍스트를 json스타일의 딕셔너리로\n",
    "client_id = os.getenv('CLIENT_ID')\n",
    "client_secret = os.getenv('CLIENT_SECRET')\n",
    "query = '쳇지피티'\n",
    "headers = {\n",
    "    'X-Naver-Client-Id':client_id,\n",
    "    'X-Naver-Client-Secret':client_secret\n",
    "}\n",
    "# url = f'https://openapi.naver.com/v1/search/kin?query={query}&display=30'\n",
    "# response = requests.get(url, headers=headers)\n",
    "url = 'https://openapi.naver.com/v1/search/kin'\n",
    "params = {'query':query, 'display':30}\n",
    "response = requests.get(url, params=params, headers=headers)\n",
    "# print(response.text[:500])\n",
    "# items = json.loads(response.text)['items']\n",
    "items = response.json()['items']\n",
    "items_list = []\n",
    "for item in items:\n",
    "    title = item['title'].replace('<b>','').replace('</b>','')\n",
    "    link  = item.get('link')\n",
    "    description = item.get('description').replace('<b>','').replace('</b>','')\n",
    "    items_list.append([title, link, description])\n",
    "pd.DataFrame(items_list, columns=['title', 'link', 'description']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c91d70",
   "metadata": {},
   "source": [
    "### quiz) 네이버 open API를 이용해서 청바지 이미지 100건의 데이터를 ch14_청바지.csv출력\n",
    "```\n",
    "    제목,링크,썸네일,sizeheight,sizewidth\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2596bb3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3440439115.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[51], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    ef get_image_list(query):\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ef get_image_list(query):\n",
    "    'query로 검색한 이미지 정보(정보,링크,썸네일,크기) 100건 데이터 프레임을 return(방법2)'\n",
    "    from urllib.request import urlopen, Request\n",
    "    from urllib.parse import quote\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    load_dotenv()\n",
    "    client_id = os.getenv('CLIENT_ID')\n",
    "    client_secret = os.getenv('CLIENT_SECRET')\n",
    "    encText = quote(query)\n",
    "    url = f'https://openapi.naver.com/v1/search/image?query={encText}&display=100'\n",
    "    headers = {\n",
    "        'X-Naver-Client-Id':client_id,\n",
    "        'X-Naver-Client-Secret':client_secret\n",
    "    }\n",
    "    request = Request(url, headers=headers)\n",
    "    response = urlopen(request)\n",
    "    # print(response.read().decode('utf-8'))\n",
    "    items = json.loads(response.read().decode('utf-8'))['items']\n",
    "    items_list = [] # 정보가 담길 리스트\n",
    "    for item in enumerate(items):\n",
    "        #print(item)\n",
    "        link = item.get('link')\n",
    "        thumbnail = item.get('thumbnail')\n",
    "        items_list.append({\n",
    "            '제목':item.get('title'),\n",
    "            '링크':link,\n",
    "            '썸네일': thumbnail,\n",
    "            'sizeheight': int(item.get('sizeheight')),\n",
    "            'sizewidth':  int(item.get('sizewidth')),\n",
    "        })\n",
    "        # 이미지 파일 저장\n",
    "        save_image('메일', idx, link, query)\n",
    "        save_image('썸네일', idx, thumbnail, query)\n",
    "        if (idx%20 == 0) & (idx!=0):\n",
    "            print(f'= = = {idx}% 진행완료 = = =')\n",
    "    return pd.DataFrame(items_list)\n",
    "df = get_image_list_save_image(\"청바지\")\n",
    "df.to_csv('image/ch14_청바지.csv')\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2961a4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_image_list(query):\n",
    "    'query로 검색한 이미지 정보(정보,링크,썸네일,크기) 100건 데이터 프레임을 return(방법1)'\n",
    "    import requests\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    load_dotenv()\n",
    "    client_id = os.getenv('CLIENT_ID')\n",
    "    client_secret = os.getenv('CLIENT_SECRET')\n",
    "    url = 'https://openapi.naver.com/v1/search/image'\n",
    "    params = {'query':query, 'display':100 }\n",
    "    headers = {\n",
    "        'X-Naver-Client-Id':client_id,\n",
    "        'X-Naver-Client-Secret':client_secret\n",
    "    }\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    #items = response.json()['items']\n",
    "    items = json.loads(response.text)['items']\n",
    "    items_list = []\n",
    "    for item in items:\n",
    "        #print(item)\n",
    "        link = item.get('link')\n",
    "        thumbnail = item.get('thumbnail')\n",
    "        items_list.append({\n",
    "            '제목':item.get('title'),\n",
    "            '링크':link,\n",
    "            '썸네일': thumbnail,\n",
    "            'sizeheight': int(item.get('sizeheight')),\n",
    "            'sizewidth':  int(item.get('sizewidth')),\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(items_list)\n",
    "df = get_image_list(\"청바지\")\n",
    "df.to_csv('data/ch14_청바지.csv')\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e39ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[99, '링크'])\n",
    "print(df.loc[99, '썸네일'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a5124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_image(attr, idx, link, query):\n",
    "    'link의 이미지를 image/attr_idx_query.확장자로 local에 저장'\n",
    "    import requests\n",
    "    file_extension = link.split('.')[-1] # 확장자\n",
    "    quote_index = file_extension.find('?') # 확장자뒤에 ?가 있는 위치 .jpg?w=780\n",
    "    if quote_index != -1:\n",
    "        file_extension = file_extension[:quote_index]\n",
    "    img = requests.get(link).content # 바이너리\n",
    "    with open(f'image/{attr}_{idx+1:02}_{query}.{file_extension}', 'wb') as f:\n",
    "        f.write(img)\n",
    "save_image('메인', 0, df.loc[25, '링크'], '청바지')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6783bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_list_save_image(query):\n",
    "    'query로 검색한 이미지 정보(정보,링크,썸네일,크기) 100건 데이터 프레임을 return(방법1)'\n",
    "    import requests\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    load_dotenv()\n",
    "    client_id = os.getenv('CLIENT_ID')\n",
    "    client_secret = os.getenv('CLIENT_SECRET')\n",
    "    url = 'https://openapi.naver.com/v1/search/image'\n",
    "    params = {'query':query, 'display':100 }\n",
    "    headers = {\n",
    "        'X-Naver-Client-Id':client_id,\n",
    "        'X-Naver-Client-Secret':client_secret\n",
    "    }\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    #items = response.json()['items']\n",
    "    items = json.loads(response.text)['items']\n",
    "    items_list = [] # 정보가 담길 리스트\n",
    "    for idx, item in enumerate(items):\n",
    "        link = item.get('link')\n",
    "        thumbnail = item.get('thumbnail')\n",
    "        items_list.append({\n",
    "            '제목':item.get('title'),\n",
    "            '링크':link,\n",
    "            '썸네일': thumbnail,\n",
    "            'sizeheight': int(item.get('sizeheight')),\n",
    "            'sizewidth':  int(item.get('sizewidth')),\n",
    "        })\n",
    "        # 이미지 파일 저장\n",
    "        save_image('메인', idx, link, query)\n",
    "        save_image('썸네일', idx, thumbnail, query)\n",
    "        if (idx%20 == 0) & (idx!=0):\n",
    "            print(f'= = = {idx}% 진행중 = = =')\n",
    "    print('= = = 완료 = = =')\n",
    "    return pd.DataFrame(items_list)\n",
    "df = get_image_list_save_image(\"청바지\")\n",
    "df.to_csv('image/ch14_청바지.csv')\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a3b012",
   "metadata": {},
   "source": [
    "## 2.3 XML 웹데이터 수집\n",
    "- RSS /open API 을 통한 XML 웹데이터 수집\n",
    "\n",
    "### 1) 전국 날씨 RSS를 BeautifulSoup을 이용한 크롤링\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e4724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "items_list = []\n",
    "url = 'https://www.kma.go.kr/repositary/xml/fct/mon/img/fct_mon1rss_108_20251106.xml'\n",
    "# 방법1\n",
    "# target = requests.get(url)\n",
    "# soup = BeautifulSoup(target.text, \"xml\") # pip install lxml 필요없음\n",
    "# 방법2\n",
    "target = urlopen(url)\n",
    "soup = BeautifulSoup(target, \"xml\")\n",
    "local_tas = soup.select('local_ta')\n",
    "for local_ta in local_tas:\n",
    "    local_name = local_ta.select_one('local_ta_name').text\n",
    "    week1_normalYear = local_ta.select_one('week1_local_ta_normalYear').text\n",
    "    week1_similarRange = local_ta.select_one('week1_local_ta_similarRange').text\n",
    "    week1_minVal = local_ta.select_one('week1_local_ta_minVal').text\n",
    "    week1_similarVal = local_ta.select_one('week1_local_ta_similarVal').text\n",
    "    week1_maxVal = local_ta.select_one('week1_local_ta_maxVal').text\n",
    "    items_list.append({\n",
    "        '지역':local_name,\n",
    "        '1주평년기온':week1_normalYear,\n",
    "        '1주기온범위':week1_similarRange,\n",
    "        '1주낮을확률':week1_minVal,\n",
    "        '1주비슷할확률':week1_similarVal,\n",
    "        '1주높을확률':week1_maxVal\n",
    "    })\n",
    "df = pd.DataFrame(items_list)\n",
    "df['1주평년기온'] = df['1주평년기온'].astype(np.float64)\n",
    "df['1주낮을확률'] = df['1주낮을확률'].astype(np.int16)\n",
    "df['1주비슷할확률'] = df['1주비슷할확률'].astype(np.int16)\n",
    "df['1주높을확률'] = df['1주높을확률'].astype(np.int16)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1796006",
   "metadata": {},
   "source": [
    "### 2) XML응답하는 open API 활용\n",
    "- data.go.kr에서\n",
    "    - 서울특별시_노선정보조회 서비스(버스ID, 정류장목록과정류장ID)\n",
    "    - 서울특별시_버스위치정보조회 서비스(실시간 버스 위치 목록)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea5edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1 버스번호의 버스 id받아오기\n",
    "# 서울특별시_노선정보조회 서비스 - 3번 기능(getBusRouteList) 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41baa082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "load_dotenv()\n",
    "# print(os.getenv('KEY1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "64e3a653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ws.bus.go.kr/api/rest/busRouteInfo/getBusRouteList?ServiceKey=ZS3iEVZ82iG9dvZc3urYq03YK9x0dwPWsaXcaNd1XACv8yWys1TONILRRSHiRNyrFo1qVk379RdHIUhAtRaL5w%3D%3D&strSrch=162\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# urlretrive(url, 저장경로) : url의 파일을 저장경로에 저장\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import quote\n",
    "#busNum = quote('종로07')\n",
    "busNum = '162'\n",
    "key = os.getenv('KEY1')\n",
    "url = f'http://ws.bus.go.kr/api/rest/busRouteInfo/getBusRouteList?ServiceKey={key}&strSrch={busNum}'\n",
    "print(url)\n",
    "savefilename1 = 'data/ch14_busInfo.xml'\n",
    "urlretrieve(url, savefilename1) #xml파일(url)을 savafilename으로 저장\n",
    "with open(savefilename1, encoding='utf-8') as f:\n",
    "    xml = f.read();\n",
    "soup = BeautifulSoup(xml, 'xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3577024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100100034\n",
      "busRouteId = 100100034\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from urllib.parse import quote\n",
    "busNum = '162'\n",
    "key = os.getenv('KEY1')\n",
    "url = f'http://ws.bus.go.kr/api/rest/busRouteInfo/getBusRouteList?ServiceKey={key}&strSrch={busNum}'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'xml')\n",
    "for item in soup.select('itemList'):\n",
    "    busRouteNm = item.select_one('busRouteNm').text\n",
    "    if busRouteNm == busNum:\n",
    "        busRouteId = item.select_one('busRouteId').text\n",
    "        print(busRouteId)\n",
    "        break;\n",
    "print('busRouteId =', busRouteId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2567f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stpe2. 버스id로 버스정류장목록받아오기(정류장명, 정류장id, 경도, 위도)\n",
    "# 서울특별시_노선정보조회 서비스 - 4번기능()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b8493ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162번 정류장 갯수 : 77\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>정류소명</th>\n",
       "      <th>id</th>\n",
       "      <th>경도</th>\n",
       "      <th>위도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>정릉산장아파트</td>\n",
       "      <td>107000071</td>\n",
       "      <td>127.003343</td>\n",
       "      <td>37.616712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>정릉4동주민센터.경국사</td>\n",
       "      <td>107000073</td>\n",
       "      <td>127.006345</td>\n",
       "      <td>37.613529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>북한산보국문역2번출구</td>\n",
       "      <td>107000518</td>\n",
       "      <td>127.0079858233</td>\n",
       "      <td>37.612293899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>성북청수도서관.정릉4동성당</td>\n",
       "      <td>107000075</td>\n",
       "      <td>127.0084193769</td>\n",
       "      <td>37.6115696748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>정릉시장입구</td>\n",
       "      <td>107000077</td>\n",
       "      <td>127.0098212542</td>\n",
       "      <td>37.6084653256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             정류소명         id              경도             위도\n",
       "0         정릉산장아파트  107000071      127.003343      37.616712\n",
       "1    정릉4동주민센터.경국사  107000073      127.006345      37.613529\n",
       "2     북한산보국문역2번출구  107000518  127.0079858233   37.612293899\n",
       "3  성북청수도서관.정릉4동성당  107000075  127.0084193769  37.6115696748\n",
       "4          정릉시장입구  107000077  127.0098212542  37.6084653256"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url2 = f'http://ws.bus.go.kr/api/rest/busRouteInfo/getStaionByRoute?ServiceKey={key}&busRouteId={busRouteId}'\n",
    "response = requests.get(url2)\n",
    "soup = BeautifulSoup(response.content,'xml')\n",
    "itemLists = soup.find_all('itemList')\n",
    "print(f'{busNum}번 정류장 갯수 : {len(itemLists)}')\n",
    "\n",
    "bus_station = []\n",
    "for itemList in itemLists:\n",
    "    stationNm = itemList.find('stationNm').text # 정류소 이름\n",
    "    station   = itemList.find('station').text # 정류소 id\n",
    "    gpsX      = itemList.find('gpsX').text # 경도\n",
    "    gpsY      = itemList.find('gpsY').text # 위도\n",
    "    bus_station.append([stationNm, station, gpsX, gpsY])\n",
    "df_station = pd.DataFrame(bus_station, columns=['정류소명','id','경도','위도'])\n",
    "df_station.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc8be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7155207e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b1fdc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3. 버스 id로 실시간위치정보를 받아오기(차량번호, 혼잡도, 최종정류장id,다음정류장id, 도착소요시간)\n",
    "# 서울특별시_버스위치정보조회 서비스 - 2번(getBusPosByRtidList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2887bbfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99960abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "운행중인 버스는 22대입니다\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>차량번호</th>\n",
       "      <th>혼잡도</th>\n",
       "      <th>경도</th>\n",
       "      <th>위도</th>\n",
       "      <th>최종정류소id</th>\n",
       "      <th>다음정류소id</th>\n",
       "      <th>도착소요시간</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>서울74사2244</td>\n",
       "      <td>여유</td>\n",
       "      <td>127.008532</td>\n",
       "      <td>37.611432</td>\n",
       "      <td>107000075</td>\n",
       "      <td>107000079</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>서울74사3381</td>\n",
       "      <td>여유</td>\n",
       "      <td>127.014223</td>\n",
       "      <td>37.598817</td>\n",
       "      <td>107000170</td>\n",
       "      <td>101000042</td>\n",
       "      <td>1858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        차량번호 혼잡도          경도         위도    최종정류소id    다음정류소id 도착소요시간\n",
       "0  서울74사2244  여유  127.008532  37.611432  107000075  107000079    232\n",
       "1  서울74사3381  여유  127.014223  37.598817  107000170  101000042   1858"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url3 = f'http://ws.bus.go.kr/api/rest/buspos/getBusPosByRtid?serviceKey={key}&busRouteId={busRouteId}'\n",
    "# print(url3)\n",
    "response = requests.get(url3)\n",
    "soup = BeautifulSoup(response.text, 'xml')\n",
    "itemLists = soup.select('itemList')\n",
    "print(f'운행중인 버스는 {len(itemLists)}대입니다')\n",
    "bus_position = []\n",
    "for itemList in itemLists:\n",
    "    plainNo = itemList.select_one('plainNo').text # 차량번호\n",
    "    congetion = itemList.select_one('congetion').text # 혼잡도(congetion)\n",
    "    # 0 : 없음, 3 : 여유, 4 : 보통, 5 : 혼잡, 6 : 매우혼잡\n",
    "    congetion = '없음' if congetion=='0' \\\n",
    "            else '여유' if congetion=='3' \\\n",
    "            else '보통' if congetion=='4' \\\n",
    "            else '혼잡' if congetion=='5' else '매우혼잡'\n",
    "    gpsX = itemList.select_one('gpsX').text # 경도\n",
    "    gpsY = itemList.select_one('gpsY').text # 위도\n",
    "    lastStnId = itemList.select_one('lastStnId').text # 최종정류소id\n",
    "    nextStId = itemList.select_one('nextStId').text # 다음정류소id\n",
    "    nextStTm = itemList.select_one('nextStTm').text # 다음정류소까지 소요시간\n",
    "    \n",
    "    bus_position.append({\n",
    "        '차량번호':plainNo,\n",
    "        '혼잡도':congetion,\n",
    "        '경도':gpsX,\n",
    "        '위도':gpsY,\n",
    "        '최종정류소id':lastStnId,\n",
    "        '다음정류소id':nextStId,\n",
    "        '도착소요시간':nextStTm\n",
    "    })\n",
    "df_position = pd.DataFrame(bus_position)\n",
    "df_position.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d0be78d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'북한산보국문역2번출구'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_station.loc[df_station['id'] == '107000518', '정류소명'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6827c6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'정릉우체국앞'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_station.loc[df_station['id']=='107000079','정류소명'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "22647d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_name(row):\n",
    "    row = row.copy()\n",
    "    'row의 최종정류소명과 다음정류소명을 추가하고, 도착소요시간을 분으로 바꿔 return'\n",
    "    row['이전정류소명'] = df_station.loc[df_station['id']==row['최종정류소id'],'정류소명'].iloc[0]\n",
    "    row['다음정류소명'] = df_station.loc[df_station['id']==row['다음정류소id'],'정류소명'].iloc[0]\n",
    "    minite = int(row['도착소요시간'])//60 # //몫연산자\n",
    "    sec    = int(row['도착소요시간']) % 60\n",
    "    row['도착소요시간'] = f'{minite}분{sec}초'\n",
    "    return row\n",
    "#station_name(df_position.loc[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e197fba4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '3분52초'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf_position\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m최종정류소id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m다음정류소id\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[102], line 6\u001b[0m, in \u001b[0;36mstation_name\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      4\u001b[0m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m이전정류소명\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_station\u001b[38;5;241m.\u001b[39mloc[df_station[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m최종정류소id\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m정류소명\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m다음정류소명\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_station\u001b[38;5;241m.\u001b[39mloc[df_station[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m다음정류소id\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m정류소명\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m minite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m도착소요시간\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m \u001b[38;5;66;03m# //몫연산자\u001b[39;00m\n\u001b[0;32m      7\u001b[0m sec    \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m도착소요시간\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m60\u001b[39m\n\u001b[0;32m      8\u001b[0m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m도착소요시간\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminite\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m분\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msec\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m초\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '3분52초'"
     ]
    }
   ],
   "source": [
    "\n",
    "df = df_position.apply(station_name, axis=1)\n",
    "df.drop(['최종정류소id','다음정류소id'], axis=1).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35972340",
   "metadata": {},
   "source": [
    "# 3절 연습문제(Quiz1)\n",
    "- yes24의 베스트셀러 정보를 제공하는 사이트에서 베스트셀러 정보를 수집해서 파일에 저장하세요.\n",
    "    * 베스트셀러 정보 수집 주소 : : http://www.yes24.com/24/category/bestseller (1페이지만 추출)\n",
    "    * https://www.yes24.com/product/category/bestseller?categoryNumber=001&pageNumber (여러 페이지 추출)\n",
    "    \n",
    "    ```\n",
    "    ch14_yes24.csv나 ch14_yes24.txt의 내용(구분문자를 ,나 \\t,....)\n",
    "        -순위\\t책이름\\t저자및출판사\\t가격\n",
    "        1\\ [도서]트렌드코리아2026\\t\"김난도,전미영,최지혜,권정윤,한다혜 | 미래의창\" \\t18.000원\n",
    "        24, [만화]그 비스트 어쩌구, 후쿠다신이치글그림/박연지역 | 소미미디어, 25, 200원\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0240046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://www.yes24.com/product/category/bestseller?categoryNumber=001&pageNumber=2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d1e5941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9169978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 도서의 저자가 많아 외 x명 뒤에도 길어 그 앞까지 짜름\n",
      "10 번째 도서의 저자가 많아 외 x명 뒤에도 길어 그 앞까지 짜름\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>순위</th>\n",
       "      <th>책이름</th>\n",
       "      <th>저자</th>\n",
       "      <th>출판사</th>\n",
       "      <th>가격</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>트렌드 코리아 2026</td>\n",
       "      <td>김난도, 전미영, 최지혜, 권정윤, 한다혜 저 외 7명</td>\n",
       "      <td>미래의창</td>\n",
       "      <td>18,000원</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   순위           책이름                              저자   출판사       가격\n",
       "0   1  트렌드 코리아 2026  김난도, 전미영, 최지혜, 권정윤, 한다혜 저 외 7명  미래의창  18,000원"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법1\n",
    "pages = 2\n",
    "bestseller_list = []\n",
    "with open('data/ch14_yes24.txt', 'w', encoding='utf-8') as f:\n",
    "    pass\n",
    "for page in range(1, pages+1):\n",
    "    url = f'https://www.yes24.com/product/category/bestseller?pageNumber={page}'\n",
    "    #print(url)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    ranks_els = soup.select('div.img_upper > em.ico.rank')\n",
    "    ranks =  [int(ranks_el.text) for ranks_el in ranks_els]\n",
    "    titles_els=soup.select(\"div.info_row > a.gd_name\")\n",
    "    titles = [titles_el.text for titles_el in titles_els]\n",
    "    authors_els = soup.select('span.authPub.info_auth')\n",
    "    authors = [authors_el.text.replace('\\r','').strip() for authors_el in authors_els]\n",
    "    for i, author in enumerate(authors):\n",
    "        match = re.search(r\"(.*)외 \\d+명\", author)\n",
    "        if(match):\n",
    "            authors[i] = match.group()\n",
    "            print(i, '번째 도서의 저자가 많아 외 x명 뒤에도 길어 그 앞까지 짜름')\n",
    "    publishers_els = soup.select('div.info_row.info_pubGrp > span.authPub.info_pub')\n",
    "    publishers = [publishers_el.text for publishers_el in publishers_els]\n",
    "    prices_els = soup.select(\"div.info_row > strong.txt_num\")\n",
    "    prices = [prices_el.text for prices_el in prices_els]\n",
    "    # print(len(ranks), len(titles), len(writers), len(publishers), len(prices))\n",
    "    with open('data/ch14_yes24.txt', 'a', encoding='utf-8') as f:\n",
    "        for rank, title, author, publisher, price in zip(ranks, titles, authors, publishers, prices):\n",
    "            # print(\"{:02},{},{} | {},{}\".format(rank, title, author, publisher, price))\n",
    "            f.write(f'{rank}, {title}, {author} | {publisher}, {price}\\n')\n",
    "            bestseller_list.append([rank, title, author, publisher, price])\n",
    "df = pd.DataFrame(bestseller_list, columns=['순위','책이름','저자','출판사','가격'])\n",
    "df.to_csv('data/ch14_yes24.csv', index=False)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c798943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법2\n",
    "pages = 2\n",
    "bestseller_list = []\n",
    "with open('data/ch14_yes24.txt', 'w', encoding='utf-8') as f:\n",
    "    pass\n",
    "for page in range(1, pages+1):\n",
    "    url = f'https://www.yes24.com/product/category/bestseller?pageNumber={page}'\n",
    "    #print(url)\n",
    "    response = urlopen(url)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    ranks_els = soup.select('div.img_upper > em.ico.rank')\n",
    "    ranks =  [int(ranks_el.text) for ranks_el in ranks_els]\n",
    "    titles_els=soup.select(\"div.info_row > a.gd_name\")\n",
    "    titles = [titles_el.text for titles_el in titles_els]\n",
    "    authors_els = soup.select('span.authPub.info_auth')\n",
    "    authors = [authors_el.text.split('정보 더 보기/감추기')[0].strip() \n",
    "                                   for authors_el in authors_els]\n",
    "#     for i, author in enumerate(authors):\n",
    "#         match = re.search(r\"(.*)외 \\d+명\", author)\n",
    "#         if(match):\n",
    "#             authors[i] = match.group()\n",
    "#             print(i, '번째 도서의 저자가 많아 외 x명 뒤에도 길어 그 앞까지 짜름')\n",
    "    publishers_els = soup.select('div.info_row.info_pubGrp > span.authPub.info_pub')\n",
    "    publishers = [publishers_el.text for publishers_el in publishers_els]\n",
    "    prices_els = soup.select(\"div.info_row > strong.txt_num\")\n",
    "    prices = [prices_el.text for prices_el in prices_els]\n",
    "    # print(len(ranks), len(titles), len(writers), len(publishers), len(prices))\n",
    "    with open('data/ch14_yes24.txt', 'a', encoding='utf-8') as f:\n",
    "        for rank, title, author, publisher, price in zip(ranks, titles, authors, publishers, prices):\n",
    "            # print(\"{:02},{},{} | {},{}\".format(rank, title, author, publisher, price))\n",
    "            f.write(f'{rank}, {title}, {author} | {publisher}, {price}\\n')\n",
    "            bestseller_list.append([rank, title, author, publisher, price])\n",
    "df = pd.DataFrame(bestseller_list, columns=['순위','책이름','저자','출판사','가격'])\n",
    "df.to_csv('data/ch14_yes24.csv', index=False)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7058ba5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.yes24.com/product/category/bestseller?pageNumber=2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>순위</th>\n",
       "      <th>책이름</th>\n",
       "      <th>저자</th>\n",
       "      <th>가격</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>35</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>37</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>38</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>39</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>41</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>42</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>43</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>45</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>46</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>47</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>48</td>\n",
       "      <td>너를 미워할 시간에 나를 사랑하기로 했다</td>\n",
       "      <td>윤서진 저</td>\n",
       "      <td>16,920원</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    순위                     책이름     저자       가격\n",
       "0   25  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "1   26  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "2   27  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "3   28  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "4   29  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "5   30  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "6   31  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "7   32  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "8   33  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "9   34  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "10  35  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "11  36  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "12  37  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "13  38  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "14  39  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "15  40  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "16  41  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "17  42  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "18  43  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "19  44  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "20  45  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "21  46  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "22  47  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원\n",
       "23  48  너를 미워할 시간에 나를 사랑하기로 했다  윤서진 저  16,920원"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page = 2\n",
    "url = f'https://www.yes24.com/product/category/bestseller?pageNumber={page}'\n",
    "print(url)\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "bestseller_list = [] #검색한 결과를 담을 리스트\n",
    "\n",
    "                       \n",
    "ranks_els = soup.select('div.img_upper > em.ico.rank')\n",
    "ranks =  [int(ranks_el.text) for ranks_el in ranks_els]\n",
    "titles_els=soup.select(\"div.info_row > a.gd_name\")\n",
    "titles = [titles_el.text for titles_el in titles_els]\n",
    "authors_els = soup.select('span.authPub.info_auth')\n",
    "authors = [authors_el.text.split('정보 더 보기/감추기')[0].strip() \n",
    "                               for authors_el in authors_els]\n",
    "publishers_els = soup.select('div.info_row.info_pubGrp > span.authPub.info_pub')\n",
    "publishers = [publishers_el.text for publishers_el in publishers_els]\n",
    "prices_els = soup.select(\"div.info_row > strong.txt_num\")\n",
    "prices = [prices_el.text for prices_el in prices_els]\n",
    "\n",
    "for idx, rank in enumerate(ranks):\n",
    "    bestseller_list.append({'순위':rank,'책이름':title,'저자':author,'가격':price})\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(bestseller_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec54349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b31b73c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94feb577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9032cc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9217bac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d49d264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315e3e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be688696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be65317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
