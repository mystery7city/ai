{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c40a3f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:80% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
       "div.text_cell_render.rendered_html{font-size:20pt;}\n",
       "div.text_cell_render ul li, div.text_cell_render ol li p, code{font-size:22pt; line-height:30px;}\n",
       "div.output {font-size:24pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:24pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
       "table.dataframe{font-size:24px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:80% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
    "div.text_cell_render.rendered_html{font-size:20pt;}\n",
    "div.text_cell_render ul li, div.text_cell_render ol li p, code{font-size:22pt; line-height:30px;}\n",
    "div.output {font-size:24pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:24pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
    "table.dataframe{font-size:24px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25162d8b",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">ch2.Ollama_LLM활용의 기본 개념(LangChain)</span>\n",
    "\n",
    "# 1. LLM을 활용하여 답변 생성하기\n",
    "\n",
    "## 1) Ollama를 이용한 로컬 LLM 이용\n",
    "\n",
    "- 성능은 GPT, Claude 같은 모델보다 떨어지나, 개념설명을 위해 open source 모델 사용\n",
    "- cmd창이나 powershell 창에 ollama run deepseek-r1:1.5b\n",
    "\n",
    "### ollama.com 다운로드 -> 설치 -> 모델 pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3797aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model = \"deepseek-r1:1.5b\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8226b229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is **Paris**.', additional_kwargs={}, response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-12-09T02:32:03.460939Z', 'done': True, 'done_reason': 'stop', 'total_duration': 14168482200, 'load_duration': 1221684300, 'prompt_eval_count': 10, 'prompt_eval_duration': 166348400, 'eval_count': 360, 'eval_duration': 12379568600, 'logprobs': None, 'model_name': 'deepseek-r1:1.5b', 'model_provider': 'ollama'}, id='lc_run--019b00f3-632b-7c13-abec-bfe6f49b0c03-0', usage_metadata={'input_tokens': 10, 'output_tokens': 360, 'total_tokens': 370})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm.invoke(\"What is the capital of France?\")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bffdf3d",
   "metadata": {},
   "source": [
    "### 모델 pull\n",
    "\n",
    "- cmd창이나 powershell창(window키+R에서 powershell)에서 ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6962598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "result = llm.invoke(\"What is the capital of Korea?\")\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "585342f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of South Korea is Seoul. The capital of North Korea is Pyongyang.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-12-09T02:40:36.3983674Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3494602300, 'load_duration': 1575519700, 'prompt_eval_count': 32, 'prompt_eval_duration': 925271400, 'eval_count': 17, 'eval_duration': 976154600, 'logprobs': None, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--019b00fb-6086-76a1-aa4b-dc2927e6aa72-0', usage_metadata={'input_tokens': 32, 'output_tokens': 17, 'total_tokens': 49})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff8995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac49f52b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5896347f",
   "metadata": {},
   "source": [
    "# 2) openai 활용\n",
    "- pip install langchain-openai\n",
    "- https://auth.openai.com/log-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d57b0ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경변수 가져오기\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "#os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af6575ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\",\n",
    "                #api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "                )\n",
    "result = llm.invoke(\"What is the capital of korea? Return the name of the city only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f886d66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Seoul', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 459, 'prompt_tokens': 21, 'total_tokens': 480, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 448, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CkkVoflC99riAmgvnAIwgDmpgtJGI', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b0192-2d15-7292-a08f-1f7b08d779de-0', usage_metadata={'input_tokens': 21, 'output_tokens': 459, 'total_tokens': 480, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 448}})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "009cdcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# claude 모델 \n",
    "# from langchain_openai import AzureOpenAI\n",
    "# llm = AzureOpenAI(model=\"gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee0f6e7",
   "metadata": {},
   "source": [
    "# 2. 렝체인 스타일로 프롬프트 작성\n",
    "\n",
    "- 프롬포트 : llm호출시 쓰는 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb05c4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of South Korea is Seoul. The capital of North Korea is Pyongyang.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-12-09T05:36:33.1169404Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5776321300, 'load_duration': 3668412300, 'prompt_eval_count': 32, 'prompt_eval_duration': 1050789700, 'eval_count': 17, 'eval_duration': 1039866400, 'logprobs': None, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--019b019c-6ccb-72f0-bad7-86380c3dd0a3-0', usage_metadata={'input_tokens': 32, 'output_tokens': 17, 'total_tokens': 49})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "result = llm.invoke(\"What is the capital of Korea?\")\n",
    "result\n",
    "\n",
    "# llm.invoke(0)\n",
    "# PromptValue, str, BaseMessages리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b84ce6c",
   "metadata": {},
   "source": [
    "## 1) 기본 프롬프트 템플릿 사용\n",
    "- PromptTemplate을 사용하여 변수가 포함된 템플릿을 작성하면 PromptValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9391f17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='What is the capital of Korea?'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='South Korea\\'s capital is Seoul, while North Korea\\'s capital is Pyongyang. However, some countries may refer to Seoul as the \"capital\" of Korea, which could be ambiguous. If you\\'re referring specifically to the country of Korea (both North and South), it\\'s more accurate to say that Seoul is the capital of South Korea and Pyongyang is the capital of North Korea.\\n\\nIf you want to avoid ambiguity, I can suggest a few alternatives:\\n\\n- For South Korea: Seoul\\n- For North Korea: Pyongyang\\n- For the Korean Peninsula as a whole (including both countries): There isn\\'t a single country with a unified government or recognized capital. However, some organizations and international bodies may refer to Seoul as the \"capital\" of Korea in the context of South Korea.\\n\\nIf you have any further clarification, I\\'d be happy to help!', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-12-09T05:53:45.7320182Z', 'done': True, 'done_reason': 'stop', 'total_duration': 14354158100, 'load_duration': 1869372400, 'prompt_eval_count': 32, 'prompt_eval_duration': 1059339000, 'eval_count': 170, 'eval_duration': 11244521200, 'logprobs': None, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--019b01ac-0cf0-7030-958d-e99cf3676519-0', usage_metadata={'input_tokens': 32, 'output_tokens': 170, 'total_tokens': 202})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"What is the capital of {country}?\", # {}안의 값을 새로운 값으로 대입 가능\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "# country = input('어느 나라의 수도를 알고 싶으신가요?')\n",
    "prompt = prompt_template.invoke({\"country\":\"Korea\"})\n",
    "print(prompt)\n",
    "llm.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f9d927",
   "metadata": {},
   "source": [
    "# 2) 메세지 기반 프롬프트 작성\n",
    "- BaseMessage 리스트\n",
    "- BaseMessage 상속받은 클래스 : AIMessage, HumanMessage, SystemMessage,ToolMessage\n",
    "- vscode에서 커널 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "beb53d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant!', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of Italy?', additional_kwargs={}, response_metadata={}), AIMessage(content='The capital of Italy is Rome.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={}), AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of {country}?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "message_list = [\n",
    "    SystemMessage(content=\"You are a helpful assistant!\"), # 페르소나 부여\n",
    "    HumanMessage(content=\"What is the capital of Italy?\"), # 모범질문\n",
    "    AIMessage(content=\"The capital of Italy is Rome.\"),    # 모범답안\n",
    "    HumanMessage(content=\"What is the capital of France?\"), # 모범질문\n",
    "    AIMessage(content=\"The capital of France is Paris.\"),    # 모범답안\n",
    "    HumanMessage(content=\"What is the capital of {country}?\")\n",
    "]\n",
    "print(message_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a899b27",
   "metadata": {},
   "source": [
    "## 3) ChatPromptTemplate 사용\n",
    "- BaseMessage리스트 ->  튜플리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "baa734ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라 수도가 궁금하세요영국\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"You're referring to England, I assume?\\n\\nThe capital of England (or the United Kingdom in general) is London.\\n\\nHowever, if you meant to ask about the entire UK, the capital is also Birmingham (partly), Cardiff (Wales), Edinburgh (Scotland), and Belfast (Northern Ireland).\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 위의 BaseMessage 리스트를 수정\n",
    "# PromptTemplate : 프롬프트에 변수포함, \n",
    "# ChatPromptTemplate : SystemPrompt설정(페르소나), few shot설정, 변수포함\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "chatPrompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpfull assistant!\"),\n",
    "    ('human', \"What is the capital of Italy?\"), # 모범질문\n",
    "    (\"ai\", \"The capital of Italy is Rome.\"),    # 모범답안\n",
    "    ('human', \"What is the capital of France?\"), # 모범질문\n",
    "    (\"ai\", \"The capital of France is Paris.\"),    # 모범답안\n",
    "    (\"human\", \"What is the capital of {country}?\")\n",
    "])\n",
    "country = input(\"어느 나라 수도가 궁금하세요\")\n",
    "prompt = chatPrompt_template.invoke({\"country\": country})\n",
    "#print(\"프롬프트 : \", prompt, type(prompt))\n",
    "\n",
    "result = llm.invoke(prompt)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43f32ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라 수도가 궁금하세요이스라엘\n",
      "messages=[SystemMessage(content='당신은 대한민국 정보 전문 도우미야.', additional_kwargs={}, response_metadata={}), HumanMessage(content='이스라엘의 수도가 어디예요!', additional_kwargs={}, response_metadata={})]\n",
      "아스달루트 (일스달루트, 영어: Jerusalem, 히브리어: ירושלים, 예루사렴[*])은 이스라엘의 수도이자 가장 큰 도시입니다. 예루사렴은 유대교, 기독교 및 이슬람 종교에 모두 중요한 성지입니다.\n",
      "\n",
      "이스라엘의 아산 (아산, 영어: Israel's Capital)이라고도 하는 이스라엘의 수도는 2019년 6월 2일, 이스라엘 의회에서 승인되어 2020년 3월 18日に 제정되었습니다.\n"
     ]
    }
   ],
   "source": [
    "chatPrompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 대한민국 정보 전문 도우미야.\"),\n",
    "    ('human', \"{country}의 수도가 어디예요!\")\n",
    "    \n",
    "])\n",
    "\n",
    "country = input(\"어느 나라 수도가 궁금하세요\")\n",
    "prompt  = chatPrompt_template.invoke({\"country\":country})\n",
    "print(prompt)\n",
    "result = llm.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce5195f",
   "metadata": {},
   "source": [
    "# 3. 답변 형식 컨트롤하기\n",
    "- llm.invoke()의 결과는 AIMessage() -> string이나 json, 객체 : OutputParser이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1240886f",
   "metadata": {},
   "source": [
    "## 1) 문자열 출력 파서 이용\n",
    "- StrOutputParser를 사용하여 LLM출력(AIMessage)을 단순 문자열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "971078c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# 명시적인 지시하상이 포함된 프롬프트\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}. Retrun the name of the city only.\",\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "# 프롬프트 템플릿에 값 주입\n",
    "prompt = prompt_template.invoke({\"country\": \"Korea\"})\n",
    "# print(prompt)\n",
    "ai_message = llm.invoke(prompt)\n",
    "#print(ai_message)\n",
    "# 문자열 출력 파서를 이용하여 llm응답(AIMessage객체)을 단순 문자열로 변환\n",
    "output_parser = StrOutputParser()\n",
    "result = output_parser.invoke(ai_message)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1164c98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "562cd552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That would be Seoul, for both North and South Korea (officially known as South Korea) but for North Korea, it's Pyongyang\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변수설정, system, few shot 지정\n",
    "chat_prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant with expertise in South Korea.\"),\n",
    "    ('human', \"What is the capital of Italy?\"),\n",
    "    (\"ai\", \"Rome.\"),\n",
    "    ('human', \"What is the capital of France?\"),\n",
    "    (\"ai\", \"Paris.\"),\n",
    "    ('human', \"What is the capital of {country}?\")\n",
    "])\n",
    "output_parser = StrOutputParser()\n",
    "output_parser.invoke(llm.invoke(chat_prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a641be",
   "metadata": {},
   "source": [
    "## 2)Json 출력 파서 이용\n",
    "- {'name' : '홍길동', 'age':22}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5c28fd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'capital': 'Seoul', 'population': 51321538, 'language': 'Korean', 'currency': 'Won'} <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "country_detail_prompt = PromptTemplate(\n",
    "    template =\"\"\" Give following information about {country}.\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    Return it is Json format and return the JSON dictionary only\"\"\",\n",
    "    \n",
    "    input_varaibles = [\"country\"]\n",
    ")\n",
    "prompt = country_detail_prompt.invoke({\"country\" : \"Korea\"})\n",
    "\n",
    "ai_message = llm.invoke(prompt)\n",
    "# print(ai_message.content)\n",
    "\n",
    "output_parser = JsonOutputParser()\n",
    "json_result = output_parser.invoke(ai_message)\n",
    "print(json_result, type(json_result))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ddaff92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': 'Seoul',\n",
       " 'population': 51100000,\n",
       " 'language': 'Korean',\n",
       " 'currency': 'Won'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205a1d8e",
   "metadata": {},
   "source": [
    "## 3) 구조화된 출력 사용\n",
    "- Pydantic 모델을 사용하여 LLM출력을 구조화된 형식으로 받기(JsonParser보다 훨씬 안정적)\n",
    "- Pydantic : 데이터유효성검사, 설정관리를 간편하게 해주는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "30832a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.User object at 0x0000022B58236770>\n"
     ]
    }
   ],
   "source": [
    "class User:\n",
    "    def __init__(self, id, name, is_active=True):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.is_active = is_active\n",
    "\n",
    "\n",
    "user = User(\"1\", \"홍길동\", False)        \n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3d3be083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=1 name='홍길동' is_active=True\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class User(BaseModel):\n",
    "    # gt=0:id>0 / ge=0:id>=0 / lt=0:id<0 / le=0:id<=0\n",
    "    id:int   = Field(gt=0,         description=\"id\")\n",
    "    name:str = Field(min_length=2, description=\"name\")\n",
    "    is_active:bool = Field(default=True, description=\"id활성화 여부\")\n",
    "user = User(id=\"1\", name=\"홍길동\")\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "25f70246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountryDetail(capital='Seoul', population=51000000, language='Korean', currency='Won (KRW)')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_detail_prompt = PromptTemplate(\n",
    "    template = \"\"\"Give following information about {country}.\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    Return in JSON format and return the JSON dictionary only\"\"\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "class CountryDetail(BaseModel): #description: 더 정확한 출력 유도\n",
    "    capital:str  = Field(description=\"the capital of the country\")\n",
    "    population:int = Field(description=\"the population of the country\")\n",
    "    language:str = Field(description=\"the language of the country\")\n",
    "    currency:str = Field(description=\"the currency of the country\")\n",
    "# 출력 형식 파서 + LLM\n",
    "structedllm = llm.with_structured_output(CountryDetail)\n",
    "# llm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"}))\n",
    "info = structedllm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"}))\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e086335b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.CountryDetail"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "94805336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Seoul', 51000000, 'Korean', 'Won (KRW)')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.capital, info.population, info.language, info.currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dc2dcebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info를 json 스타일로 : {\"capital\":\"Seoul\",\"population\":51000000,\"language\":\"Korean\",\"currency\":\"Won (KRW)\"}\n",
      "info를 dict로 : {'capital': 'Seoul', 'population': 51000000, 'language': 'Korean', 'currency': 'Won (KRW)'}\n",
      "info를 dict로 : {'capital': 'Seoul', 'population': 51000000, 'language': 'Korean', 'currency': 'Won (KRW)'}\n"
     ]
    }
   ],
   "source": [
    "print(\"info를 json 스타일로 :\", info.model_dump_json())\n",
    "print(\"info를 dict로 :\", info.model_dump())\n",
    "print(\"info를 dict로 :\", info.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b7d98034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "type(info.model_dump_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127c8603",
   "metadata": {},
   "source": [
    "# 4. LCEL을 활용한 렝체인 생성하기\n",
    "## 1) 문자열 출력 파서 사용\n",
    "- invoke : Runnable에 있는 함수\n",
    "- StrOutputParser, ChatOllama, PromptTemplate등은 모두 Runnable로부터 상속 받음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5bf0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "422c694d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\",\n",
    "                temperature=0) # 일관된 답변(보수적인 답변)\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}. Retrun the name of the city only.\",\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "output_parser = StrOutputParser() # AIMessage()를 Str변환\n",
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f910c0",
   "metadata": {},
   "source": [
    "## 2) LCEL을 사용한 간단한 체인 구성\n",
    "- 파이프연산자(|) 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4e8a6980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프롬프트 템플릿 -> llm -> 출력파서를 연결하는 체인 생성\n",
    "capital_chain = prompt_template | llm | output_parser\n",
    "# 생성된 체인 invoke\n",
    "capital_chain.invoke({\"country\":\"Korea\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c04c3ef",
   "metadata": {},
   "source": [
    "## 3) 복합체인 구성\n",
    "- 여러 단계의 추론이 필요한 경우(체인 연결)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "968ee85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'France'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라 설명 -> 나라이름\n",
    "country_prompt = PromptTemplate(\n",
    "    template =\"\"\"Guess the name of the country based on the following information:\n",
    "    {information}\n",
    "    Return the name of the country only\"\"\",\n",
    "    input_variables=[\"information\"]\n",
    ")\n",
    "\n",
    "output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\":\n",
    "                                                      \"This country is very famous for its wine\"})))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "da198555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'France'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라명 추출 체인 생성\n",
    "country_chain = country_prompt | llm | output_parser\n",
    "\n",
    "country_chain.invoke({\"information\" : \"This country is very famous for its wine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ef77b56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paris'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 복합체인 : 나라설명 -> 나라명(country_chain)\n",
    "#                     나라명 -> 수도(capital_chain)\n",
    "\n",
    "final_chain = country_chain | capital_chain\n",
    "\n",
    "final_chain.invoke({\"information\":\"THis country is very famous for its wine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260041e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복합체인 : information -> country_chain -> (나라명을 country) -> capital_chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "final_chain = {\"information\":RunnablePassthrough()}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5703186f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e7bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff446da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7458d870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "244.444px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
