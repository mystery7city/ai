{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4decb793",
   "metadata": {},
   "source": [
    "# RAGAS Evaluation Notebook (Clean)\n",
    "\n",
    "This notebook evaluates **baseline vs experiment** RAG pipelines using RAGAS and saves **summary/detail** outputs per run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5272651f",
   "metadata": {},
   "source": [
    "## ğŸ”§ ìˆ˜ì • í¬ì¸íŠ¸(ê°€ì¥ ìì£¼ ë°”ê¾¸ëŠ” ê³³)\n",
    "\n",
    "1) **SYSTEM_PROMPT_BASE / SYSTEM_PROMPT_EXP** (í”„ë¡¬í”„íŠ¸ ë¹„êµ)\n",
    "2) **base_cfg / exp_cfg** (íŒŒë¼ë¯¸í„° ë¹„êµ)\n",
    "\n",
    "ì´ ë‘ êµ°ë°ë§Œ ë°”ê¾¸ê³  ì•„ë˜ ì‹¤í–‰ ì…€ë“¤ì„ ëŒë¦¬ë©´, ê°™ì€ í…ŒìŠ¤íŠ¸ì…‹ìœ¼ë¡œ BASE vs EXPê°€ ìë™ ë¹„êµë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf76203-b1ff-4ee3-b17e-06004982adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdaa3541-ee50-497b-81cd-91c2274ba4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1b5f49e-4fde-42f4-a42a-40dd814c571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys, subprocess, textwrap\n",
    "\n",
    "# def sh(cmd):\n",
    "#     print(\">\", cmd)\n",
    "#     r = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "#     print(r.stdout)\n",
    "#     if r.stderr.strip():\n",
    "#         print(\"[stderr]\")\n",
    "#         print(r.stderr)\n",
    "\n",
    "# print(\"python:\", sys.executable)\n",
    "# print(\"version:\", sys.version)\n",
    "\n",
    "# # í˜„ì¬ íŒ¨í‚¤ì§€ ìƒíƒœ í™•ì¸\n",
    "# sh(\"python -c \\\"import numpy; print('numpy', numpy.__version__)\\\"\")\n",
    "# sh(\"python -c \\\"import pyarrow; print('pyarrow', pyarrow.__version__)\\\"\")\n",
    "# sh(\"python -c \\\"import datasets; print('datasets', datasets.__version__)\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b2f1ee4-078f-4f37-9e75-6da6b135d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys, subprocess\n",
    "\n",
    "# def pip(cmd):\n",
    "#     print(\">\", cmd)\n",
    "#     r = subprocess.run([sys.executable, \"-m\", \"pip\"] + cmd.split(), capture_output=True, text=True)\n",
    "#     print(r.stdout)\n",
    "#     if r.stderr.strip():\n",
    "#         print(\"[stderr]\")\n",
    "#         print(r.stderr)\n",
    "\n",
    "# # 1) ì œê±°\n",
    "# pip(\"uninstall -y pyarrow datasets numpy\")\n",
    "\n",
    "# # 2) ì¬ì„¤ì¹˜: numpy<2 + ìµœì‹  pyarrow + datasets(ë„ˆê°€ ì“°ë˜ ë²„ì „)\n",
    "# pip(\"install numpy<2 pyarrow>=14 datasets==2.19.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f6d4dab-9416-4c6e-b037-2526c17623ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… METRICS: ['ContextPrecision', 'ContextRecall', 'Faithfulness']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4888\\1708373533.py:6: DeprecationWarning: Importing context_precision from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_precision\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4888\\1708373533.py:6: DeprecationWarning: Importing context_recall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_recall\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4888\\1708373533.py:6: DeprecationWarning: Importing faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import faithfulness\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n"
     ]
    }
   ],
   "source": [
    "# ---- RAGAS metrics: version-tolerant loader ----\n",
    "def build_metrics():\n",
    "    # Aì•ˆ: embeddings ì˜ì¡´ ê°€ëŠ¥ì„±ì´ í° AnswerRelevancyëŠ” ë¹¼ê³  \"ì™„ì£¼\"ë¶€í„°\n",
    "    # 1) í•¨ìˆ˜í˜• metric\n",
    "    try:\n",
    "        from ragas.metrics import context_precision, context_recall, faithfulness\n",
    "        return [context_precision, context_recall, faithfulness]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) í´ë˜ìŠ¤í˜• metric\n",
    "    try:\n",
    "        from ragas.metrics import ContextPrecision, ContextRecall, Faithfulness\n",
    "        return [ContextPrecision(), ContextRecall(), Faithfulness()]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 3) fallback íƒìƒ‰\n",
    "    import ragas.metrics as m\n",
    "    wanted = [\"ContextPrecision\", \"ContextRecall\", \"Faithfulness\"]\n",
    "    found = []\n",
    "    for name in wanted:\n",
    "        if hasattr(m, name):\n",
    "            found.append(getattr(m, name)())\n",
    "    if found:\n",
    "        return found\n",
    "\n",
    "    raise ImportError(\n",
    "        \"RAGAS metrics import failed for A-plan (without AnswerRelevancy). \"\n",
    "        \"Paste `pip show ragas` and `python -c \\\"import ragas; print(ragas.__version__)\\\"`.\"\n",
    "    )\n",
    "\n",
    "METRICS = build_metrics()\n",
    "print(\"âœ… METRICS:\", [getattr(x, '__name__', x.__class__.__name__) for x in METRICS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24085385-5708-4be6-8d18-1c17f11f456d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ragas version: 0.4.3\n"
     ]
    }
   ],
   "source": [
    "import ragas\n",
    "print(\"ragas version:\", getattr(ragas, \"__version__\", \"unknown\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85cba8ec-b4a6-4dcf-8fda-13b78e62e686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… METRICS: ['ContextPrecision', 'ContextRecall', 'Faithfulness', 'AnswerRelevancy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4888\\3044559028.py:1: DeprecationWarning: Importing context_precision from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_precision\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness, answer_relevancy\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4888\\3044559028.py:1: DeprecationWarning: Importing context_recall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_recall\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness, answer_relevancy\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4888\\3044559028.py:1: DeprecationWarning: Importing faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import faithfulness\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness, answer_relevancy\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4888\\3044559028.py:1: DeprecationWarning: Importing answer_relevancy from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import answer_relevancy\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness, answer_relevancy\n"
     ]
    }
   ],
   "source": [
    "from ragas.metrics import context_precision, context_recall, faithfulness, answer_relevancy\n",
    "\n",
    "METRICS = [context_precision, context_recall, faithfulness, answer_relevancy]\n",
    "print(\"âœ… METRICS:\", [getattr(m, \"__name__\", m.__class__.__name__) for m in METRICS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac8615-1f58-462f-8f2e-811d673d8d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22cee99-4aaa-40fb-bbbb-451aa89c8c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53db9df-4693-41e1-b255-bebb90c4be53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "663e3c80",
   "metadata": {},
   "source": [
    "## 0) Environment & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3772574e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: C:\\ai\\source\\chatbot_app\n",
      "TESTSET_PATH: C:\\ai\\source\\chatbot_app\\ragas_testset_10_selected.jsonl\n",
      "exists: True\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PATH CONFIG (only this cell is modified)\n",
    "# ============================================================\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys, importlib\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# âœ… í”„ë¡œì íŠ¸ ë£¨íŠ¸ (ìƒˆ ê²½ë¡œ)\n",
    "PROJECT_ROOT = Path(r\"C:\\ai\\source\\chatbot_app\")\n",
    "\n",
    "# âœ… ëª¨ë“ˆ ê²½ë¡œ (ì›ë˜ ì“°ë˜ êµ¬ì¡° ê·¸ëŒ€ë¡œ)\n",
    "MODULE_DIR = PROJECT_ROOT / \"modules\"\n",
    "\n",
    "# âœ… í™˜ê²½ë³€ìˆ˜\n",
    "ENV_PATH = PROJECT_ROOT / \".env\"\n",
    "\n",
    "# âœ… ê²°ê³¼ ì €ì¥ ë£¨íŠ¸\n",
    "RUNS_DIR = PROJECT_ROOT / \"results\" / \"ragas_runs\"\n",
    "\n",
    "# â­•ï¸ ì—¬ê¸°ì„œ ì–´ë–¤ í…ŒìŠ¤íŠ¸ì…‹ ì“¸ì§€ ë„¤ê°€ ì§ì ‘ ì„ íƒ\n",
    "# TESTSET_PATH = PROJECT_ROOT / \"ragas_testset_single.jsonl\"\n",
    "# TESTSET_PATH = PROJECT_ROOT / \"ragas_testset_v1_from_docx.jsonl\"\n",
    "TESTSET_PATH = PROJECT_ROOT / \"ragas_testset_10_selected.jsonl\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# setup\n",
    "# ------------------------------------------------------------\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "sys.path.insert(0, str(MODULE_DIR))\n",
    "importlib.invalidate_caches()\n",
    "\n",
    "if ENV_PATH.exists():\n",
    "    load_dotenv(ENV_PATH)\n",
    "\n",
    "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"TESTSET_PATH:\", TESTSET_PATH)\n",
    "print(\"exists:\", TESTSET_PATH.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc0093e",
   "metadata": {},
   "source": [
    "## 1) Load testset (JSONL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8108580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… rows: 10\n",
      "âœ… keys example: dict_keys(['question_id', 'question', 'ground_truth', 'contexts', 'meta'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>contexts</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q010</td>\n",
       "      <td>ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì§‘ì£¼ì¸ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?</td>\n",
       "      <td>ë„¤, ê°•ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ27ì¡°ì— ë”°ë¥´ë©´,\\n ì œ26ì¡°ì œ4í•­ ...</td>\n",
       "      <td>[ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ27ì¡° ì œ1í•­, ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì‹œí–‰ë ¹ ì œ34ì¡°, ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸...</td>\n",
       "      <td>{'source': 'RAGAS í•™ìŠµìš© ì§ˆë¬¸.docx', 'version': 'v1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q016</td>\n",
       "      <td>ì„ëŒ€ì¸ì´ ë³´ì¦ê¸ˆì„ ì•ˆ ëŒë ¤ì¤˜ì„œ ì œê°€ ì¼ë¶€ëŸ¬ ì „ì…ì‹ ê³ ë¥¼ ìœ ì§€í•˜ê³  ìˆëŠ”ë°, ë‹¤ë¥¸ ì§‘ìœ¼ë¡œ...</td>\n",
       "      <td>ë‹¤ë¥¸ ì§‘ìœ¼ë¡œ ì „ì…ì‹ ê³ ë¥¼ í•˜ë©´,\\n ê¸°ì¡´ ì£¼íƒì— ëŒ€í•œ ëŒ€í•­ë ¥ì„ ìƒì‹¤í•˜ê²Œ ë˜ì–´ ì„ì°¨ì¸ìœ¼...</td>\n",
       "      <td>[ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ3ì¡° ì œ1í•­]</td>\n",
       "      <td>{'source': 'RAGAS í•™ìŠµìš© ì§ˆë¬¸.docx', 'version': 'v1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q002</td>\n",
       "      <td>ê³„ì•½ì„œì— 1ë…„ì´ë¼ê³  ì¨ ìˆìœ¼ë©´, 1ë…„ ì§€ë‚˜ë©´ ë¬´ì¡°ê±´ ë‚˜ê°€ì•¼ í•˜ë‚˜ìš”?</td>\n",
       "      <td>ì•„ë‹ˆìš”. ê³„ì•½ì„œì— 1ë…„ì´ë¼ê³  ì í˜€ ìˆì–´ë„, 1ë…„ì´ ì§€ë‚˜ë©´ ë¬´ì¡°ê±´ ë‚˜ê°€ì•¼ í•˜ëŠ” ê²ƒì€ ...</td>\n",
       "      <td>[ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ4ì¡° ì œ1í•­]</td>\n",
       "      <td>{'source': 'RAGAS í•™ìŠµìš© ì§ˆë¬¸.docx', 'version': 'v1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question_id                                           question  \\\n",
       "0        q010               ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì§‘ì£¼ì¸ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?   \n",
       "1        q016  ì„ëŒ€ì¸ì´ ë³´ì¦ê¸ˆì„ ì•ˆ ëŒë ¤ì¤˜ì„œ ì œê°€ ì¼ë¶€ëŸ¬ ì „ì…ì‹ ê³ ë¥¼ ìœ ì§€í•˜ê³  ìˆëŠ”ë°, ë‹¤ë¥¸ ì§‘ìœ¼ë¡œ...   \n",
       "2        q002              ê³„ì•½ì„œì— 1ë…„ì´ë¼ê³  ì¨ ìˆìœ¼ë©´, 1ë…„ ì§€ë‚˜ë©´ ë¬´ì¡°ê±´ ë‚˜ê°€ì•¼ í•˜ë‚˜ìš”?   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  ë„¤, ê°•ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ27ì¡°ì— ë”°ë¥´ë©´,\\n ì œ26ì¡°ì œ4í•­ ...   \n",
       "1  ë‹¤ë¥¸ ì§‘ìœ¼ë¡œ ì „ì…ì‹ ê³ ë¥¼ í•˜ë©´,\\n ê¸°ì¡´ ì£¼íƒì— ëŒ€í•œ ëŒ€í•­ë ¥ì„ ìƒì‹¤í•˜ê²Œ ë˜ì–´ ì„ì°¨ì¸ìœ¼...   \n",
       "2  ì•„ë‹ˆìš”. ê³„ì•½ì„œì— 1ë…„ì´ë¼ê³  ì í˜€ ìˆì–´ë„, 1ë…„ì´ ì§€ë‚˜ë©´ ë¬´ì¡°ê±´ ë‚˜ê°€ì•¼ í•˜ëŠ” ê²ƒì€ ...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ27ì¡° ì œ1í•­, ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì‹œí–‰ë ¹ ì œ34ì¡°, ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸...   \n",
       "1                                 [ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ3ì¡° ì œ1í•­]   \n",
       "2                                 [ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ4ì¡° ì œ1í•­]   \n",
       "\n",
       "                                                meta  \n",
       "0  {'source': 'RAGAS í•™ìŠµìš© ì§ˆë¬¸.docx', 'version': 'v1...  \n",
       "1  {'source': 'RAGAS í•™ìŠµìš© ì§ˆë¬¸.docx', 'version': 'v1...  \n",
       "2  {'source': 'RAGAS í•™ìŠµìš© ì§ˆë¬¸.docx', 'version': 'v1...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TESTSET_JSONL = PROJECT_ROOT / \"ragas_testset_10_selected.jsonl\"  # change if needed\n",
    "assert TESTSET_JSONL.exists(), f\"âŒ JSONL not found: {TESTSET_JSONL}\"\n",
    "\n",
    "rows = []\n",
    "with open(TESTSET_JSONL, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        rows.append(json.loads(line))\n",
    "\n",
    "print(\"âœ… rows:\", len(rows))\n",
    "print(\"âœ… keys example:\", rows[0].keys())\n",
    "pd.DataFrame(rows[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347b7dac-4985-472c-a539-581bb0105eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fd5607-f5ef-4c8c-a324-21e45c1831e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec1529b4",
   "metadata": {},
   "source": [
    "## 2) Define baseline & experiment configs\n",
    "\n",
    "- Keep **base_cfg** stable.\n",
    "- Only put **changed knobs** in `exp_cfg = replace(base_cfg, ...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69c6ca41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RAGConfig(normalize_model='solar-pro2', generation_model='gpt-4o-mini', temperature=0.1, normalize_temperature=0.0, embedding_backend='upstage', embedding_model='solar-embedding-1-large-passage', k_law=7, k_rule=7, k_case=3, search_multiplier=4, enable_bm25=True, sparse_mode='auto', sparse_k_law=None, sparse_k_rule=None, sparse_k_case=None, bm25_algorithm='okapi', bm25_k1=1.5, bm25_b=0.85, bm25_use_kiwi=True, bm25_max_doc_chars=3000, enable_bm25_title=True, bm25_title_field='title', bm25_title_max_chars=512, hybrid_sparse_title_ratio=0.35, hybrid_fusion='rrf', hybrid_dense_weight=0.5, hybrid_sparse_weight=0.5, rrf_k=60, enable_rerank=True, rerank_threshold=0.22, rerank_model='rerank-multilingual-v3.0', rerank_max_documents=18, rerank_doc_max_chars=3000, case_candidate_k=40, case_expand_top_n=None, case_context_top_k=50, dedupe_key_fields=['chunk_id', 'id']),\n",
       " RAGConfig(normalize_model='solar-pro2', generation_model='gpt-4o-mini', temperature=0.1, normalize_temperature=0.0, embedding_backend='upstage', embedding_model='solar-embedding-1-large-passage', k_law=7, k_rule=7, k_case=3, search_multiplier=4, enable_bm25=True, sparse_mode='auto', sparse_k_law=None, sparse_k_rule=None, sparse_k_case=None, bm25_algorithm='okapi', bm25_k1=1.5, bm25_b=0.85, bm25_use_kiwi=True, bm25_max_doc_chars=2200, enable_bm25_title=True, bm25_title_field='title', bm25_title_max_chars=512, hybrid_sparse_title_ratio=0.35, hybrid_fusion='rrf', hybrid_dense_weight=0.5, hybrid_sparse_weight=0.5, rrf_k=60, enable_rerank=True, rerank_threshold=0.26, rerank_model='rerank-multilingual-v3.0', rerank_max_documents=14, rerank_doc_max_chars=2200, case_candidate_k=40, case_expand_top_n=None, case_context_top_k=50, dedupe_key_fields=['chunk_id', 'id']))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import replace\n",
    "from rag_module import RAGConfig\n",
    "\n",
    "# =========================\n",
    "# Base config (edit as needed)\n",
    "# =========================\n",
    "base_cfg = RAGConfig(\n",
    "    # ---- LLM ----\n",
    "    normalize_model=\"solar-pro2\",\n",
    "    generation_model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    "    normalize_temperature=0.0,\n",
    "\n",
    "    # ---- Embedding ----\n",
    "    embedding_backend=\"upstage\",\n",
    "    embedding_model=\"solar-embedding-1-large-passage\",\n",
    "\n",
    "    # ---- Dense Retrieval ----\n",
    "    k_law=7,\n",
    "    k_rule=7,\n",
    "    k_case=3,\n",
    "    search_multiplier=4,\n",
    "\n",
    "    # ---- Hybrid Fusion ----\n",
    "    hybrid_dense_weight=0.5,\n",
    "    hybrid_sparse_weight=0.5,\n",
    "\n",
    "    # ---- BM25 / Sparse ----\n",
    "    enable_bm25=True,\n",
    "    sparse_mode=\"auto\",\n",
    "    bm25_algorithm=\"okapi\",\n",
    "    bm25_k1=1.5,\n",
    "    bm25_b=0.85,\n",
    "    bm25_use_kiwi=True,\n",
    "\n",
    "    # ---- BM25-title ----\n",
    "    enable_bm25_title=True,\n",
    "    bm25_title_field=\"title\",\n",
    "    hybrid_sparse_title_ratio=0.35,\n",
    "\n",
    "    # ---- Rerank ----\n",
    "    enable_rerank=True,\n",
    "    rerank_model=\"rerank-multilingual-v3.0\",\n",
    "    rerank_threshold=0.22,\n",
    "    rerank_max_documents=18,\n",
    "\n",
    "    # ---- Output trimming ----\n",
    "    bm25_max_doc_chars=3000,\n",
    "    rerank_doc_max_chars=3000,\n",
    "\n",
    "    # ---- Dedupe ----\n",
    "    dedupe_key_fields=[\"chunk_id\", \"id\"],\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Experiment config (only diffs here)\n",
    "# =========================\n",
    "exp_cfg = replace(\n",
    "    base_cfg,\n",
    "    rerank_threshold=0.26,\n",
    "    rerank_max_documents=14,\n",
    "    bm25_max_doc_chars=2200,\n",
    "    rerank_doc_max_chars=2200,\n",
    ")\n",
    "base_cfg, exp_cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b0bfd",
   "metadata": {},
   "source": [
    "## (ì¶”ê°€) SYSTEM PROMPT ì‹¤í—˜\n",
    "\n",
    "- ì—¬ê¸°ì„œ **í”„ë¡¬í”„íŠ¸ë§Œ** ë°”ê¿”ë„ BASE vs EXP ë¹„êµê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "- íŒŒì´í”„ë¼ì¸ì´ `answer_with_trace(question, system_prompt=...)`ë¥¼ ì§€ì›í•˜ì§€ ì•Šë”ë¼ë„,\n",
    "  ì•„ë˜ `run_pipe_to_samples()`ê°€ ê°€ëŠ¥í•œ ë°©ì‹ìœ¼ë¡œ ìš°íšŒí•´ì„œ ì£¼ì…ì„ ì‹œë„í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27e40aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE prompt chars: 454\n",
      "EXP  prompt chars: 585\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# SYSTEM PROMPT (BASE vs EXP)\n",
    "# =========================\n",
    "SYSTEM_PROMPT_BASE = \"\"\"\n",
    "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì£¼íƒ ì„ëŒ€ì°¨(ì „ì›”ì„¸) ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë²•ë¥ ì •ë³´ AIì…ë‹ˆë‹¤.\n",
    "ì•„ë˜ [ì°¸ê³  ë¬¸ì„œ]ë¥¼ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì§ì ‘ ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "[ìµœìš°ì„  ê·œì¹™]\n",
    "- ì§ˆë¬¸ì— ëŒ€í•œ ê²°ë¡ ì„ ê°€ì¥ ë¨¼ì € ì œì‹œí•˜ì„¸ìš”.\n",
    "- ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ ì—†ëŠ” ë‚´ìš©ì€ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "- ì°¸ê³  ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ë¡ í•˜ê±°ë‚˜ ì¼ë°˜í™”í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "- íŒë‹¨ì´ ì–´ë ¤ìš´ ê²½ìš°, ê·¼ê±° ë¶€ì¡±ì„ ëª…í™•íˆ ë°íˆì„¸ìš”.\n",
    "\n",
    "[ë‹µë³€ í˜•ì‹ â€” ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”]\n",
    "1. ê²°ë¡   \n",
    "   - ì§ˆë¬¸ì— ëŒ€í•´ ê°€ëŠ¥í•œì§€ / ë¶ˆê°€ëŠ¥í•œì§€ / í•´ì•¼ í•˜ëŠ”ì§€ë¥¼\n",
    "     ë‹¨ì •ì ì¸ ë¬¸ì¥ìœ¼ë¡œ ë¨¼ì € ì œì‹œí•˜ì„¸ìš”.\n",
    "\n",
    "2. ì´ìœ   \n",
    "   - ìœ„ ê²°ë¡ ì´ ë‚˜ì˜¤ëŠ” ì´ìœ ë¥¼\n",
    "     ì°¸ê³  ë¬¸ì„œì˜ ë‚´ìš©ì— ê·¼ê±°í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "   - ë¬¸ì„œì˜ ì·¨ì§€Â·ë‚´ìš©ê³¼ ì§ì ‘ ì—°ê²°ë˜ë„ë¡ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "3. í•œê³„ ëª…ì‹œ  \n",
    "   - ì°¸ê³  ë¬¸ì„œë§Œìœ¼ë¡œ íŒë‹¨ì´ ì™„ì „íˆ í™•ì •ë˜ì§€ ì•ŠëŠ” ê²½ìš°,\n",
    "     ê·¸ í•œê³„ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œë§Œ ë°íˆì„¸ìš”.\n",
    "\"\"\".strip()\n",
    "\n",
    "# âœ… EXP í”„ë¡¬í”„íŠ¸ë¥¼ ì—¬ê¸°ì„œë§Œ ìˆ˜ì •í•´ì„œ ë¹„êµ\n",
    "SYSTEM_PROMPT_EXP = SYSTEM_PROMPT_BASE + \"\"\"\n",
    "\n",
    "[EXP ê·œì¹™]\n",
    "- ë‹µë³€ì— í¬í•¨ë˜ëŠ” ëª¨ë“  íŒë‹¨ê³¼ ì„¤ëª…ì€ ë°˜ë“œì‹œ [ì°¸ê³  ë¬¸ì„œ]ì˜ ëª…ì‹œì  ë‚´ìš©ì— ê·¼ê±°í•˜ì„¸ìš”.\n",
    "- ì°¸ê³  ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì‘ì„±í•˜ì§€ ë§ê³ ,\n",
    "  íŒë‹¨ì´ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°ì—ëŠ” â€œì°¸ê³  ë¬¸ì„œìƒ ê·¼ê±° ë¶€ì¡±ìœ¼ë¡œ íŒë‹¨ ë¶ˆê°€â€ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"BASE prompt chars:\", len(SYSTEM_PROMPT_BASE))\n",
    "print(\"EXP  prompt chars:\", len(SYSTEM_PROMPT_EXP))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fbbb5",
   "metadata": {},
   "source": [
    "## 3) Build pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba0f69f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 14:55:54,265 - rag_module - INFO - ğŸ”— Pinecone 3ì¤‘ ì¸ë±ìŠ¤ ì—°ê²° ì¤‘...\n",
      "2026-02-06 14:55:57,422 - rag_module - INFO - âœ… [Law / Rule / Case] 3ê°œ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ!\n",
      "2026-02-06 14:55:58,658 - rag_module - INFO - âœ… Kiwi í† í¬ë‚˜ì´ì € ì‚¬ìš© (BM25)\n",
      "2026-02-06 14:56:01,218 - rag_module - INFO - ğŸ”— Pinecone 3ì¤‘ ì¸ë±ìŠ¤ ì—°ê²° ì¤‘...\n",
      "2026-02-06 14:56:01,221 - rag_module - INFO - âœ… [Law / Rule / Case] 3ê°œ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ!\n",
      "2026-02-06 14:56:01,927 - rag_module - INFO - âœ… Kiwi í† í¬ë‚˜ì´ì € ì‚¬ìš© (BM25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… pipelines ready\n"
     ]
    }
   ],
   "source": [
    "from rag_module import create_pipeline\n",
    "\n",
    "base_pipe = create_pipeline(config=base_cfg)\n",
    "exp_pipe  = create_pipeline(config=exp_cfg)\n",
    "\n",
    "print(\"âœ… pipelines ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6959059d-0ad1-4770-a338-6be9623871f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8fd6fa-516a-44f7-aa82-3095b2320555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e6dfb91",
   "metadata": {},
   "source": [
    "## 4) (Optional) Quick trace sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85371f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„¹ï¸ Skip or customize depending on your pipeline API.\n"
     ]
    }
   ],
   "source": [
    "# If your rag_module exposes a trace / debug method, call it here.\n",
    "# Otherwise you can skip this cell.\n",
    "\n",
    "# Example (adjust to your actual API):\n",
    "# ans, trace = base_pipe.answer_with_trace(\"í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ...\")\n",
    "# display(trace)\n",
    "\n",
    "print(\"â„¹ï¸ Skip or customize depending on your pipeline API.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16739f05",
   "metadata": {},
   "source": [
    "## 5) Build RAGAS samples from your pipeline outputs\n",
    "\n",
    "This converts each testset row into the RAGAS format:\n",
    "- `question`\n",
    "- `answer`\n",
    "- `contexts` (list[str])\n",
    "- `ground_truth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a8d6173",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 14:57:44,799 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:57:44,816 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸: ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "\n",
      "â€» [ìš©ì–´ ì‚¬ì „]ì— \"ì§‘ì£¼ì¸\"ë§Œ ëª…ì‹œë˜ì–´ ìˆì–´ \"ì¡°ì •\"ì€ ë³€í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„ ì™œê³¡ ë°©ì§€ë¥¼ ìœ„í•´ ìµœì†Œí•œì˜ ë³€í™˜ë§Œ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.\n",
      "2026-02-06 14:57:44,817 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸: ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "\n",
      "â€» [ìš©ì–´ ì‚¬ì „]ì— \"ì§‘ì£¼ì¸\"ë§Œ ëª…ì‹œë˜ì–´ ìˆì–´ \"ì¡°ì •\"ì€ ë³€í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„ ì™œê³¡ ë°©ì§€ë¥¼ ìœ„í•´ ìµœì†Œí•œì˜ ë³€í™˜ë§Œ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.'\n",
      "2026-02-06 14:57:45,525 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:57:48,094 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:57:50,527 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:57:57,765 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:57:57,773 - rag_module - INFO - ğŸ“Œ Rerank selected=18 (threshold=0.22)\n",
      "2026-02-06 14:57:57,776 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:58:02,319 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:03,190 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:03,193 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ë³´ì¦ê¸ˆ)ì„ ë³´ì¦ê¸ˆë¯¸ë°˜í™˜(ì•ˆ ëŒë ¤ì¤˜ì„œ)í•´ì„œ ì œê°€ ì¼ë¶€ëŸ¬ ì£¼ë¯¼ë“±ë¡(ì „ì…ì‹ ê³ )ì„ ìœ ì§€í•˜ê³  ìˆëŠ”ë°, ë‹¤ë¥¸ ì„ì°¨ì£¼íƒ(ë‹¤ë¥¸ ì§‘)ìœ¼ë¡œ ì£¼ë¯¼ë“±ë¡(ì „ì…ì‹ ê³ )ì„ í•˜ë©´ ì œ ì„ì°¨ì¸ ê¶Œë¦¬ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n",
      "2026-02-06 14:58:03,194 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ë³´ì¦ê¸ˆ)ì„ ë³´ì¦ê¸ˆë¯¸ë°˜í™˜(ì•ˆ ëŒë ¤ì¤˜ì„œ)í•´ì„œ ì œê°€ ì¼ë¶€ëŸ¬ ì£¼ë¯¼ë“±ë¡(ì „ì…ì‹ ê³ )ì„ ìœ ì§€í•˜ê³  ìˆëŠ”ë°, ë‹¤ë¥¸ ì„ì°¨ì£¼íƒ(ë‹¤ë¥¸ ì§‘)ìœ¼ë¡œ ì£¼ë¯¼ë“±ë¡(ì „ì…ì‹ ê³ )ì„ í•˜ë©´ ì œ ì„ì°¨ì¸ ê¶Œë¦¬ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?'\n",
      "2026-02-06 14:58:03,740 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:04,894 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:05,821 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:08,751 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:08,759 - rag_module - INFO - ğŸ“Œ Rerank selected=18 (threshold=0.22)\n",
      "2026-02-06 14:58:08,761 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:58:14,157 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:15,586 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:15,590 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ê³„ì•½ì„œì— 1ë…„ì´ë¼ê³  ì¨ ìˆìœ¼ë©´, 1ë…„ ì§€ë‚˜ë©´ ë¬´ì¡°ê±´ ë‚˜ê°€ì•¼ í•˜ë‚˜ìš”? â†’ ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ë©´, 1ë…„ ê²½ê³¼ ì‹œ ë¬´ì¡°ê±´ ì£¼íƒì˜ì¸ë„ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ë©´, 1ë…„ ê²½ê³¼ ì‹œ ë¬´ì¡°ê±´ ì£¼íƒì˜ì¸ë„ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”? (ê³„ì•½ì„œ(ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ)ì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ë©´, 1ë…„ ê²½ê³¼ ì‹œ ë¬´ì¡°ê±´ í‡´ê±°(ì£¼íƒì˜ì¸ë„)ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”?)  \n",
      "\n",
      "â€» [ìš©ì–´ ì‚¬ì „]ì— ë”°ë¼ 'ê³„ì•½ì„œ' â†’ 'ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ', 'ë‚˜ê°€ì•¼' â†’ 'ì£¼íƒì˜ì¸ë„'ë¡œ ë³€í™˜í•˜ì˜€ìœ¼ë©°, ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„ ì™œê³¡ ì—†ì´ ìµœì†Œí•œì˜ ë³€í™˜ë§Œ ìˆ˜í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
      "2026-02-06 14:58:15,591 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ê³„ì•½ì„œì— 1ë…„ì´ë¼ê³  ì¨ ìˆìœ¼ë©´, 1ë…„ ì§€ë‚˜ë©´ ë¬´ì¡°ê±´ ë‚˜ê°€ì•¼ í•˜ë‚˜ìš”? â†’ ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ë©´, 1ë…„ ê²½ê³¼ ì‹œ ë¬´ì¡°ê±´ ì£¼íƒì˜ì¸ë„ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ë©´, 1ë…„ ê²½ê³¼ ì‹œ ë¬´ì¡°ê±´ ì£¼íƒì˜ì¸ë„ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”? (ê³„ì•½ì„œ(ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ)ì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ë©´, 1ë…„ ê²½ê³¼ ì‹œ ë¬´ì¡°ê±´ í‡´ê±°(ì£¼íƒì˜ì¸ë„)ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”?)  \n",
      "\n",
      "â€» [ìš©ì–´ ì‚¬ì „]ì— ë”°ë¼ 'ê³„ì•½ì„œ' â†’ 'ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ', 'ë‚˜ê°€ì•¼' â†’ 'ì£¼íƒì˜ì¸ë„'ë¡œ ë³€í™˜í•˜ì˜€ìœ¼ë©°, ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„ ì™œê³¡ ì—†ì´ ìµœì†Œí•œì˜ ë³€í™˜ë§Œ ìˆ˜í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.'\n",
      "2026-02-06 14:58:16,045 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:16,979 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:17,751 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:20,734 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:20,741 - rag_module - INFO - ğŸ“Œ Rerank selected=18 (threshold=0.22)\n",
      "2026-02-06 14:58:20,744 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:58:25,674 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:26,364 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:26,368 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì„ëŒ€ì¸(ì„ëŒ€ì¸)ê°€ â€œì£¼ë¯¼ë“±ë¡(ì£¼ë¯¼ë“±ë¡) í•˜ì§€ ë§ì•„ë‹¬ë¼â€ê³  íŠ¹ì•½ì‚¬í•­(íŠ¹ì•½ì‚¬í•­)ì„ ë„£ìê³  í•©ë‹ˆë‹¤. ì´ íŠ¹ì•½ì‚¬í•­(íŠ¹ì•½ì‚¬í•­)ì„ ì§€í‚¤ë©´ ì •ë§ ë¬¸ì œ(ë¬´íš¨ì—¬ë¶€)ê°€ ìƒê¸°ë‚˜ìš”?\n",
      "2026-02-06 14:58:26,369 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì„ëŒ€ì¸(ì„ëŒ€ì¸)ê°€ â€œì£¼ë¯¼ë“±ë¡(ì£¼ë¯¼ë“±ë¡) í•˜ì§€ ë§ì•„ë‹¬ë¼â€ê³  íŠ¹ì•½ì‚¬í•­(íŠ¹ì•½ì‚¬í•­)ì„ ë„£ìê³  í•©ë‹ˆë‹¤. ì´ íŠ¹ì•½ì‚¬í•­(íŠ¹ì•½ì‚¬í•­)ì„ ì§€í‚¤ë©´ ì •ë§ ë¬¸ì œ(ë¬´íš¨ì—¬ë¶€)ê°€ ìƒê¸°ë‚˜ìš”?'\n",
      "2026-02-06 14:58:27,081 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:27,836 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:28,502 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:31,110 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:31,115 - rag_module - INFO - ğŸ“Œ Rerank selected=5 (threshold=0.22)\n",
      "2026-02-06 14:58:31,117 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:58:35,703 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:36,181 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:36,185 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ê²½ê¸°ë„ì— ì‚¬ëŠ”ë° ì„ì°¨ì£¼íƒì´ ê²½ë§¤ì ˆì°¨ë¡œ ë„˜ì–´ê°€ë©´, ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ì¼ë¶€ë¼ë„ ìš°ì„ ë³€ì œê¶Œìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\n",
      "2026-02-06 14:58:36,187 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ê²½ê¸°ë„ì— ì‚¬ëŠ”ë° ì„ì°¨ì£¼íƒì´ ê²½ë§¤ì ˆì°¨ë¡œ ë„˜ì–´ê°€ë©´, ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ì¼ë¶€ë¼ë„ ìš°ì„ ë³€ì œê¶Œìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?'\n",
      "2026-02-06 14:58:36,896 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:37,583 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:38,537 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:41,514 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:41,522 - rag_module - INFO - ğŸ“Œ Rerank selected=7 (threshold=0.22)\n",
      "2026-02-06 14:58:41,524 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:58:45,750 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:46,420 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:46,422 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ê³„ì•½ê¸°ê°„ ì¤‘ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ë°”ë€Œì—ˆê³ , ìƒˆ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ë‚˜ê°€ë¼ê³  í•´ìš”. ì €ëŠ” ëˆ„êµ¬ì—ê²Œ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)ì„ ì²­êµ¬í•´ì•¼ í•˜ë‚˜ìš”?\n",
      "2026-02-06 14:58:46,424 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ê³„ì•½ê¸°ê°„ ì¤‘ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ë°”ë€Œì—ˆê³ , ìƒˆ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ë‚˜ê°€ë¼ê³  í•´ìš”. ì €ëŠ” ëˆ„êµ¬ì—ê²Œ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)ì„ ì²­êµ¬í•´ì•¼ í•˜ë‚˜ìš”?'\n",
      "2026-02-06 14:58:47,118 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:47,791 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:48,697 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:52,001 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:52,007 - rag_module - INFO - ğŸ“Œ Rerank selected=5 (threshold=0.22)\n",
      "2026-02-06 14:58:52,009 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:58:56,442 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:57,041 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:57,042 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ë¬µì‹œì ê°±ì‹ (ë¬µì‹œì ê°±ì‹ )ìœ¼ë¡œ ì—°ì¥ëœ ì¤„ ëª¨ë¥´ê³  ì‚´ì•˜ëŠ”ë°, ì£¼íƒì˜ì¸ë„(ì£¼íƒì˜ì¸ë„) ê°€ë ¤ë©´ ì–¸ì œê¹Œì§€ ì‚´ì•„ì•¼ í•˜ë‚˜ìš”?\n",
      "2026-02-06 14:58:57,043 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ë¬µì‹œì ê°±ì‹ (ë¬µì‹œì ê°±ì‹ )ìœ¼ë¡œ ì—°ì¥ëœ ì¤„ ëª¨ë¥´ê³  ì‚´ì•˜ëŠ”ë°, ì£¼íƒì˜ì¸ë„(ì£¼íƒì˜ì¸ë„) ê°€ë ¤ë©´ ì–¸ì œê¹Œì§€ ì‚´ì•„ì•¼ í•˜ë‚˜ìš”?'\n",
      "2026-02-06 14:58:58,039 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:58,701 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:58:59,783 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:02,813 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:02,819 - rag_module - INFO - ğŸ“Œ Rerank selected=17 (threshold=0.22)\n",
      "2026-02-06 14:59:02,821 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:59:07,811 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:08,737 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:08,740 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì‹ ì¶• ì„ì°¨ì£¼íƒì¸ë° ì„ëŒ€ì°¨ë³´ì¦ê¸ˆì´ ë„ˆë¬´ ë†’ì•„ì„œ ë¶ˆì•ˆí•©ë‹ˆë‹¤. ì‹¤ê±°ë˜ê°€ë³´ë‹¤ í›¨ì”¬ ë¹„ì‹¼ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ê³„ì•½ë„ ë²•ì ìœ¼ë¡œ ë¬¸ì œë  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì‹ ì¶• ì„ì°¨ì£¼íƒ(ì„ì°¨ì£¼íƒ)ì¸ë° ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)ì´ ë„ˆë¬´ ë†’ì•„ì„œ ë¶ˆì•ˆí•©ë‹ˆë‹¤. ì‹¤ê±°ë˜ê°€ë³´ë‹¤ í›¨ì”¬ ë¹„ì‹¼ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ) ê³„ì•½ë„ ë²•ì ìœ¼ë¡œ ë¬¸ì œë  ìˆ˜ ìˆë‚˜ìš”?\n",
      "2026-02-06 14:59:08,740 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì‹ ì¶• ì„ì°¨ì£¼íƒì¸ë° ì„ëŒ€ì°¨ë³´ì¦ê¸ˆì´ ë„ˆë¬´ ë†’ì•„ì„œ ë¶ˆì•ˆí•©ë‹ˆë‹¤. ì‹¤ê±°ë˜ê°€ë³´ë‹¤ í›¨ì”¬ ë¹„ì‹¼ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ê³„ì•½ë„ ë²•ì ìœ¼ë¡œ ë¬¸ì œë  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì‹ ì¶• ì„ì°¨ì£¼íƒ(ì„ì°¨ì£¼íƒ)ì¸ë° ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)ì´ ë„ˆë¬´ ë†’ì•„ì„œ ë¶ˆì•ˆí•©ë‹ˆë‹¤. ì‹¤ê±°ë˜ê°€ë³´ë‹¤ í›¨ì”¬ ë¹„ì‹¼ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ) ê³„ì•½ë„ ë²•ì ìœ¼ë¡œ ë¬¸ì œë  ìˆ˜ ìˆë‚˜ìš”?'\n",
      "2026-02-06 14:59:09,429 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:10,364 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:11,302 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:14,490 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:14,497 - rag_module - INFO - ğŸ“Œ Rerank selected=18 (threshold=0.22)\n",
      "2026-02-06 14:59:14,499 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:59:18,243 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:19,134 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:19,135 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì£¼ë¯¼ë“±ë¡Â·í™•ì •ì¼ì í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”? (ì£¼ë¯¼ë“±ë¡Â·í™•ì •ì¼ì í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”?)  \n",
      "\n",
      "â€» [ìš©ì–´ ì‚¬ì „]ì— 'ì „ì…ì‹ ê³ ' â†’ 'ì£¼ë¯¼ë“±ë¡' ë§¤í•‘ë§Œ ì¡´ì¬í•˜ë©°, 'í™•ì •ì¼ìë¶€'ëŠ” ë³„ë„ ì •ì˜ë˜ì§€ ì•Šì•„ ì›ë¬¸ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
      "2026-02-06 14:59:19,135 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì£¼ë¯¼ë“±ë¡Â·í™•ì •ì¼ì í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”? (ì£¼ë¯¼ë“±ë¡Â·í™•ì •ì¼ì í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”?)  \n",
      "\n",
      "â€» [ìš©ì–´ ì‚¬ì „]ì— 'ì „ì…ì‹ ê³ ' â†’ 'ì£¼ë¯¼ë“±ë¡' ë§¤í•‘ë§Œ ì¡´ì¬í•˜ë©°, 'í™•ì •ì¼ìë¶€'ëŠ” ë³„ë„ ì •ì˜ë˜ì§€ ì•Šì•„ ì›ë¬¸ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤.'\n",
      "2026-02-06 14:59:19,836 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:20,757 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:21,910 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:25,086 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:25,091 - rag_module - INFO - ğŸ“Œ Rerank selected=18 (threshold=0.22)\n",
      "2026-02-06 14:59:25,094 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:59:30,342 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:32,371 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:32,374 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : 'ì „ì„¸ì‚¬ê¸°'ëŠ” ìš©ì–´ ì‚¬ì „ì— 'ì „ì„¸í”¼í•´'ë¡œ ì§ì ‘ ë§¤í•‘ë˜ì§€ ì•Šì•˜ìœ¼ë‚˜, ë¬¸ë§¥ìƒ 'ê¶Œë¦¬ë¦¬ìŠ¤í¬'ë¡œ ëŒ€ì²´ ê°€ëŠ¥í•œ ê²ƒìœ¼ë¡œ íŒë‹¨í•˜ì˜€ìŠµë‹ˆë‹¤. ì •í™•í•œ ë²•ë¥  ìš©ì–´ ì ìš©ì„ ìœ„í•´ ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "\n",
      "(ìµœì¢… ì¶œë ¥ ì‹œ ìœ„ ì°¸ê³  ë¬¸êµ¬ ì œì™¸)  \n",
      "\n",
      "ìµœì¢… ì¶œë ¥:  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?\n",
      "2026-02-06 14:59:32,375 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : 'ì „ì„¸ì‚¬ê¸°'ëŠ” ìš©ì–´ ì‚¬ì „ì— 'ì „ì„¸í”¼í•´'ë¡œ ì§ì ‘ ë§¤í•‘ë˜ì§€ ì•Šì•˜ìœ¼ë‚˜, ë¬¸ë§¥ìƒ 'ê¶Œë¦¬ë¦¬ìŠ¤í¬'ë¡œ ëŒ€ì²´ ê°€ëŠ¥í•œ ê²ƒìœ¼ë¡œ íŒë‹¨í•˜ì˜€ìŠµë‹ˆë‹¤. ì •í™•í•œ ë²•ë¥  ìš©ì–´ ì ìš©ì„ ìœ„í•´ ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "\n",
      "(ìµœì¢… ì¶œë ¥ ì‹œ ìœ„ ì°¸ê³  ë¬¸êµ¬ ì œì™¸)  \n",
      "\n",
      "ìµœì¢… ì¶œë ¥:  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?'\n",
      "2026-02-06 14:59:32,875 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:33,809 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:35,019 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:38,296 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:38,302 - rag_module - INFO - ğŸ“Œ Rerank selected=18 (threshold=0.22)\n",
      "2026-02-06 14:59:38,304 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:59:42,909 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:43,650 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:43,652 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "\n",
      "(â€» ì°¸ê³ : \"ì¡°ì •\"ì€ ìš©ì–´ ì‚¬ì „ì— ì—†ëŠ” ì¼ë°˜ ë²•ë¥  ìš©ì–´ì´ë¯€ë¡œ ë³€í™˜í•˜ì§€ ì•ŠìŒ)\n",
      "2026-02-06 14:59:43,654 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "\n",
      "(â€» ì°¸ê³ : \"ì¡°ì •\"ì€ ìš©ì–´ ì‚¬ì „ì— ì—†ëŠ” ì¼ë°˜ ë²•ë¥  ìš©ì–´ì´ë¯€ë¡œ ë³€í™˜í•˜ì§€ ì•ŠìŒ)'\n",
      "2026-02-06 14:59:44,156 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:46,807 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:49,527 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:56,592 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:59:56,597 - rag_module - INFO - ğŸ“Œ Rerank selected=2 (threshold=0.26)\n",
      "2026-02-06 14:59:56,598 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 15:00:01,160 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:01,877 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:01,880 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ë³´ì¦ê¸ˆ)ì„ ë³´ì¦ê¸ˆë¯¸ë°˜í™˜(ì•ˆëŒë ¤ì¤Œ)í•´ì„œ ì œê°€ ì¼ë¶€ëŸ¬ ì£¼ë¯¼ë“±ë¡(ì „ì…ì‹ ê³ )ì„ ìœ ì§€í•˜ê³  ìˆëŠ”ë°, ë‹¤ë¥¸ ì„ì°¨ì£¼íƒ(ë‹¤ë¥¸ ì§‘)ìœ¼ë¡œ ì£¼ë¯¼ë“±ë¡(ì „ì…ì‹ ê³ )ì„ í•˜ë©´ ì œ ì„ì°¨ì¸(ì„ì°¨ì¸) ê¶Œë¦¬ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n",
      "2026-02-06 15:00:01,881 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ë³´ì¦ê¸ˆ)ì„ ë³´ì¦ê¸ˆë¯¸ë°˜í™˜(ì•ˆëŒë ¤ì¤Œ)í•´ì„œ ì œê°€ ì¼ë¶€ëŸ¬ ì£¼ë¯¼ë“±ë¡(ì „ì…ì‹ ê³ )ì„ ìœ ì§€í•˜ê³  ìˆëŠ”ë°, ë‹¤ë¥¸ ì„ì°¨ì£¼íƒ(ë‹¤ë¥¸ ì§‘)ìœ¼ë¡œ ì£¼ë¯¼ë“±ë¡(ì „ì…ì‹ ê³ )ì„ í•˜ë©´ ì œ ì„ì°¨ì¸(ì„ì°¨ì¸) ê¶Œë¦¬ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?'\n",
      "2026-02-06 15:00:03,373 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:04,587 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:05,518 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:08,356 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:08,360 - rag_module - INFO - ğŸ“Œ Rerank selected=13 (threshold=0.26)\n",
      "2026-02-06 15:00:08,362 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 15:00:14,201 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:15,858 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:15,862 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ê³„ì•½ì„œì— 1ë…„ì´ë¼ê³  ì¨ ìˆìœ¼ë©´, 1ë…„ ì§€ë‚˜ë©´ ë¬´ì¡°ê±´ ë‚˜ê°€ì•¼ í•˜ë‚˜ìš”? â†’ ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ë©´, 1ë…„ ê²½ê³¼ ì‹œ ë¬´ì¡°ê±´ ì£¼íƒì˜ì¸ë„ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ë©´, 1ë…„ ê²½ê³¼ ì‹œ ë¬´ì¡°ê±´ ì£¼íƒì˜ì¸ë„ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”? (ê³„ì•½ì„œ(ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ)ì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ë©´, 1ë…„ ê²½ê³¼ ì‹œ ë¬´ì¡°ê±´ í‡´ê±°(ì£¼íƒì˜ì¸ë„)ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”?)  \n",
      "\n",
      "â€» [ìš©ì–´ ì‚¬ì „]ì— ë”°ë¼ 'ê³„ì•½ì„œ' â†’ 'ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ', 'ë‚˜ê°€ì•¼' â†’ 'ì£¼íƒì˜ì¸ë„'ë¡œ ë³€í™˜í•˜ì˜€ìœ¼ë©°, ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„ ì™œê³¡ ì—†ì´ ìµœì†Œí•œì˜ ë³€í™˜ë§Œ ìˆ˜í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
      "2026-02-06 15:00:15,864 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ê³„ì•½ì„œì— 1ë…„ì´ë¼ê³  ì¨ ìˆìœ¼ë©´, 1ë…„ ì§€ë‚˜ë©´ ë¬´ì¡°ê±´ ë‚˜ê°€ì•¼ í•˜ë‚˜ìš”? â†’ ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ë©´, 1ë…„ ê²½ê³¼ ì‹œ ë¬´ì¡°ê±´ ì£¼íƒì˜ì¸ë„ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ë©´, 1ë…„ ê²½ê³¼ ì‹œ ë¬´ì¡°ê±´ ì£¼íƒì˜ì¸ë„ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”? (ê³„ì•½ì„œ(ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ)ì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ë©´, 1ë…„ ê²½ê³¼ ì‹œ ë¬´ì¡°ê±´ í‡´ê±°(ì£¼íƒì˜ì¸ë„)ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”?)  \n",
      "\n",
      "â€» [ìš©ì–´ ì‚¬ì „]ì— ë”°ë¼ 'ê³„ì•½ì„œ' â†’ 'ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ', 'ë‚˜ê°€ì•¼' â†’ 'ì£¼íƒì˜ì¸ë„'ë¡œ ë³€í™˜í•˜ì˜€ìœ¼ë©°, ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„ ì™œê³¡ ì—†ì´ ìµœì†Œí•œì˜ ë³€í™˜ë§Œ ìˆ˜í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.'\n",
      "2026-02-06 15:00:16,345 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:17,865 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:18,816 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:21,852 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:21,858 - rag_module - INFO - ğŸ“Œ Rerank selected=14 (threshold=0.26)\n",
      "2026-02-06 15:00:21,859 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 15:00:28,148 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:28,908 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:28,912 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ â€œì£¼ë¯¼ë“±ë¡(ì£¼ë¯¼ë“±ë¡) í•˜ì§€ ë§ì•„ë‹¬ë¼â€ê³  íŠ¹ì•½ì‚¬í•­(íŠ¹ì•½ì‚¬í•­)ì„ ë„£ìê³  í•©ë‹ˆë‹¤. ì´ íŠ¹ì•½ì‚¬í•­(íŠ¹ì•½ì‚¬í•­)ì„ ì§€í‚¤ë©´ ì •ë§ ë¬¸ì œê°€ ìƒê¸°ë‚˜ìš”?\n",
      "2026-02-06 15:00:28,913 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ â€œì£¼ë¯¼ë“±ë¡(ì£¼ë¯¼ë“±ë¡) í•˜ì§€ ë§ì•„ë‹¬ë¼â€ê³  íŠ¹ì•½ì‚¬í•­(íŠ¹ì•½ì‚¬í•­)ì„ ë„£ìê³  í•©ë‹ˆë‹¤. ì´ íŠ¹ì•½ì‚¬í•­(íŠ¹ì•½ì‚¬í•­)ì„ ì§€í‚¤ë©´ ì •ë§ ë¬¸ì œê°€ ìƒê¸°ë‚˜ìš”?'\n",
      "2026-02-06 15:00:29,378 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:30,052 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:30,979 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:33,625 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:33,630 - rag_module - INFO - ğŸ“Œ Rerank selected=5 (threshold=0.26)\n",
      "2026-02-06 15:00:33,632 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 15:00:37,624 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:38,256 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:38,260 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ê²½ê¸°ë„ì— ì‚¬ëŠ”ë° ì„ì°¨ì£¼íƒì´ ê²½ë§¤ì ˆì°¨ë¡œ ë„˜ì–´ê°€ë©´, ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ì¼ë¶€ë¼ë„ ìš°ì„ ë³€ì œê¶Œìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\n",
      "2026-02-06 15:00:38,261 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ê²½ê¸°ë„ì— ì‚¬ëŠ”ë° ì„ì°¨ì£¼íƒì´ ê²½ë§¤ì ˆì°¨ë¡œ ë„˜ì–´ê°€ë©´, ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ì¼ë¶€ë¼ë„ ìš°ì„ ë³€ì œê¶Œìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?'\n",
      "2026-02-06 15:00:38,962 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:39,876 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:40,629 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:43,649 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:43,656 - rag_module - INFO - ğŸ“Œ Rerank selected=6 (threshold=0.26)\n",
      "2026-02-06 15:00:43,659 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 15:00:47,609 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:48,338 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:48,340 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ê³„ì•½ê¸°ê°„ ì¤‘ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ë°”ë€Œì—ˆê³ , ìƒˆ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ë‚˜ê°€ë¼ê³  í•´ìš”. ì €ëŠ” ëˆ„êµ¬ì—ê²Œ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)ì„ ì²­êµ¬í•´ì•¼ í•˜ë‚˜ìš”?\n",
      "2026-02-06 15:00:48,341 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ê³„ì•½ê¸°ê°„ ì¤‘ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ë°”ë€Œì—ˆê³ , ìƒˆ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ë‚˜ê°€ë¼ê³  í•´ìš”. ì €ëŠ” ëˆ„êµ¬ì—ê²Œ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)ì„ ì²­êµ¬í•´ì•¼ í•˜ë‚˜ìš”?'\n",
      "2026-02-06 15:00:48,821 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:49,493 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:50,443 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:53,458 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:53,464 - rag_module - INFO - ğŸ“Œ Rerank selected=4 (threshold=0.26)\n",
      "2026-02-06 15:00:53,466 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 15:00:58,094 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:58,868 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:00:58,872 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ë¬µì‹œì ê°±ì‹ (ë¬µì‹œì ê°±ì‹ )ìœ¼ë¡œ ì—°ì¥ëœ ì¤„ ëª¨ë¥´ê³  ì‚´ì•˜ëŠ”ë°, ì£¼íƒì˜ì¸ë„(ì£¼íƒì˜ì¸ë„) ê°€ë ¤ë©´ ì–¸ì œê¹Œì§€ ì‚´ì•„ì•¼ í•˜ë‚˜ìš”?\n",
      "2026-02-06 15:00:58,873 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ë¬µì‹œì ê°±ì‹ (ë¬µì‹œì ê°±ì‹ )ìœ¼ë¡œ ì—°ì¥ëœ ì¤„ ëª¨ë¥´ê³  ì‚´ì•˜ëŠ”ë°, ì£¼íƒì˜ì¸ë„(ì£¼íƒì˜ì¸ë„) ê°€ë ¤ë©´ ì–¸ì œê¹Œì§€ ì‚´ì•„ì•¼ í•˜ë‚˜ìš”?'\n",
      "2026-02-06 15:00:59,565 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:00,376 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:01,131 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:04,197 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:04,205 - rag_module - INFO - ğŸ“Œ Rerank selected=14 (threshold=0.26)\n",
      "2026-02-06 15:01:04,207 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 15:01:09,647 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:10,821 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:10,824 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì‹ ì¶• ì„ì°¨ì£¼íƒì¸ë° ì„ëŒ€ì°¨ë³´ì¦ê¸ˆì´ ë„ˆë¬´ ë†’ì•„ì„œ ë¶ˆì•ˆí•©ë‹ˆë‹¤. ì‹¤ê±°ë˜ê°€ë³´ë‹¤ í›¨ì”¬ ë¹„ì‹¼ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ê³„ì•½ë„ ë²•ì ìœ¼ë¡œ ë¬¸ì œë  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "\n",
      "(ë³€ê²½ëœ ì§ˆë¬¸: ì‹ ì¶• ì„ì°¨ì£¼íƒ(ë¹Œë¼)ì¸ë° ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì „ì„¸ê¸ˆ)ì´ ë„ˆë¬´ ë†’ì•„ì„œ ë¶ˆì•ˆí•©ë‹ˆë‹¤. ì‹¤ê±°ë˜ê°€ë³´ë‹¤ í›¨ì”¬ ë¹„ì‹¼ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì „ì„¸ê¸ˆ) ê³„ì•½ë„ ë²•ì ìœ¼ë¡œ ë¬¸ì œë  ìˆ˜ ìˆë‚˜ìš”?)  \n",
      "\n",
      "â€» ì°¸ê³ : ì›ë¬¸ì˜ \"ì „ì„¸ê°€\"ëŠ” ìš©ì–´ ì‚¬ì „ì— ëª…ì‹œë˜ì§€ ì•Šì•„ \"ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ\"ìœ¼ë¡œ ëŒ€ì²´í•˜ì˜€ìœ¼ë©°, \"ì‹¤ê±°ë˜ê°€\"ëŠ” ë²•ë¥  ìš©ì–´ê°€ ì•„ë‹ˆë¯€ë¡œ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
      "2026-02-06 15:01:10,825 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì‹ ì¶• ì„ì°¨ì£¼íƒì¸ë° ì„ëŒ€ì°¨ë³´ì¦ê¸ˆì´ ë„ˆë¬´ ë†’ì•„ì„œ ë¶ˆì•ˆí•©ë‹ˆë‹¤. ì‹¤ê±°ë˜ê°€ë³´ë‹¤ í›¨ì”¬ ë¹„ì‹¼ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ê³„ì•½ë„ ë²•ì ìœ¼ë¡œ ë¬¸ì œë  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "\n",
      "(ë³€ê²½ëœ ì§ˆë¬¸: ì‹ ì¶• ì„ì°¨ì£¼íƒ(ë¹Œë¼)ì¸ë° ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì „ì„¸ê¸ˆ)ì´ ë„ˆë¬´ ë†’ì•„ì„œ ë¶ˆì•ˆí•©ë‹ˆë‹¤. ì‹¤ê±°ë˜ê°€ë³´ë‹¤ í›¨ì”¬ ë¹„ì‹¼ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì „ì„¸ê¸ˆ) ê³„ì•½ë„ ë²•ì ìœ¼ë¡œ ë¬¸ì œë  ìˆ˜ ìˆë‚˜ìš”?)  \n",
      "\n",
      "â€» ì°¸ê³ : ì›ë¬¸ì˜ \"ì „ì„¸ê°€\"ëŠ” ìš©ì–´ ì‚¬ì „ì— ëª…ì‹œë˜ì§€ ì•Šì•„ \"ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ\"ìœ¼ë¡œ ëŒ€ì²´í•˜ì˜€ìœ¼ë©°, \"ì‹¤ê±°ë˜ê°€\"ëŠ” ë²•ë¥  ìš©ì–´ê°€ ì•„ë‹ˆë¯€ë¡œ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤.'\n",
      "2026-02-06 15:01:11,521 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:12,469 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:13,211 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:16,210 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:16,216 - rag_module - INFO - ğŸ“Œ Rerank selected=14 (threshold=0.26)\n",
      "2026-02-06 15:01:16,218 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 15:01:20,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:21,994 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:21,997 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì£¼ë¯¼ë“±ë¡Â·í™•ì •ì¼ì í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”? (ì£¼ë¯¼ë“±ë¡Â·í™•ì •ì¼ì í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”?)  \n",
      "\n",
      "â€» [ìš©ì–´ ì‚¬ì „]ì— 'ì „ì…ì‹ ê³ 'ëŠ” 'ì£¼ë¯¼ë“±ë¡'ìœ¼ë¡œë§Œ ë§¤í•‘ë˜ì–´ ìˆìœ¼ë©°, 'í™•ì •ì¼ìë¶€'ëŠ” ë³„ë„ ë§¤í•‘ ëŒ€ìƒì´ ì•„ë‹ˆë¯€ë¡œ ì›ë¬¸ì„ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
      "2026-02-06 15:01:21,998 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì£¼ë¯¼ë“±ë¡Â·í™•ì •ì¼ì í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”? (ì£¼ë¯¼ë“±ë¡Â·í™•ì •ì¼ì í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”?)  \n",
      "\n",
      "â€» [ìš©ì–´ ì‚¬ì „]ì— 'ì „ì…ì‹ ê³ 'ëŠ” 'ì£¼ë¯¼ë“±ë¡'ìœ¼ë¡œë§Œ ë§¤í•‘ë˜ì–´ ìˆìœ¼ë©°, 'í™•ì •ì¼ìë¶€'ëŠ” ë³„ë„ ë§¤í•‘ ëŒ€ìƒì´ ì•„ë‹ˆë¯€ë¡œ ì›ë¬¸ì„ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤.'\n",
      "2026-02-06 15:01:22,692 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:23,805 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:24,543 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:27,495 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:27,501 - rag_module - INFO - ğŸ“Œ Rerank selected=14 (threshold=0.26)\n",
      "2026-02-06 15:01:27,503 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 15:01:33,828 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:34,474 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:34,478 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬) í”¼í•´ìë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨ ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?\n",
      "2026-02-06 15:01:34,479 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬) í”¼í•´ìë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨ ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?'\n",
      "2026-02-06 15:01:35,190 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:36,088 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:37,014 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:39,908 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:39,914 - rag_module - INFO - ğŸ“Œ Rerank selected=4 (threshold=0.26)\n",
      "2026-02-06 15:01:39,916 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 15:01:44,255 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BASE_SAMPLES: 10\n",
      "âœ… EXP_SAMPLES : 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì§‘ì£¼ì¸ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?</td>\n",
       "      <td>A. í•œ ì¤„ ê²°ë¡ &nbsp;&nbsp;\\n- ê°€ëŠ¥í•©ë‹ˆë‹¤. ì¡°ì •ì—ì„œ í•©ì˜í•œ ë‚´ìš©ì€ ë²•ì  íš¨ë ¥ì´ ìˆìœ¼ë©°,...</td>\n",
       "      <td>[page_content='â‘  ì„ëŒ€ì¸ì´ ì„ëŒ€ì°¨ê¸°ê°„ì´ ëë‚˜ê¸° 6ê°œì›” ì „ë¶€í„° 2ê°œì›” ì „...</td>\n",
       "      <td>ë„¤, ê°•ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ27ì¡°ì— ë”°ë¥´ë©´,\\n ì œ26ì¡°ì œ4í•­ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               question  \\\n",
       "0  ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì§‘ì£¼ì¸ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  A. í•œ ì¤„ ê²°ë¡   \\n- ê°€ëŠ¥í•©ë‹ˆë‹¤. ì¡°ì •ì—ì„œ í•©ì˜í•œ ë‚´ìš©ì€ ë²•ì  íš¨ë ¥ì´ ìˆìœ¼ë©°,...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [page_content='â‘  ì„ëŒ€ì¸ì´ ì„ëŒ€ì°¨ê¸°ê°„ì´ ëë‚˜ê¸° 6ê°œì›” ì „ë¶€í„° 2ê°œì›” ì „...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  ë„¤, ê°•ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ27ì¡°ì— ë”°ë¥´ë©´,\\n ì œ26ì¡°ì œ4í•­ ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shrink_contexts(ctxs, max_chars=2400, max_contexts=30):\n",
    "    out = []\n",
    "    for c in (ctxs or []):\n",
    "        if c is None:\n",
    "            continue\n",
    "        s = str(c).strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        out.append(s[:max_chars])\n",
    "        if len(out) >= max_contexts:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "def row_get_ground_truth(r: dict):\n",
    "    return r.get(\"ground_truth\") or r.get(\"reference\") or r.get(\"gt\") or r.get(\"answer\")\n",
    "\n",
    "def run_pipe_to_samples(pipe, rows, system_prompt=None, max_chars=2400, max_contexts=30, limit=None):\n",
    "    samples = []\n",
    "    n = len(rows) if limit is None else min(limit, len(rows))\n",
    "\n",
    "    for i in range(n):\n",
    "        r = rows[i]\n",
    "        q = r.get(\"question\") or r.get(\"query\")\n",
    "        if not q:\n",
    "            continue\n",
    "\n",
    "        # âœ… íŒŒì´í”„ í˜¸ì¶œ + í”„ë¡¬í”„íŠ¸ ì£¼ì…(ê°€ëŠ¥í•œ ë°©ì‹ìœ¼ë¡œ ì‹œë„)\n",
    "        try:\n",
    "            out = pipe.answer_with_trace(q, system_prompt=system_prompt) if system_prompt else pipe.answer_with_trace(q)\n",
    "        except TypeError:\n",
    "            # íŒŒì´í”„ë¼ì¸ì´ system_prompt ì¸ìë¥¼ ë°›ì§€ ì•ŠëŠ” ê²½ìš°: ì†ì„±/ì„¸í„°ë¡œ ìš°íšŒ ì‹œë„\n",
    "            if system_prompt:\n",
    "                if hasattr(pipe, \"set_system_prompt\") and callable(getattr(pipe, \"set_system_prompt\")):\n",
    "                    pipe.set_system_prompt(system_prompt)\n",
    "                elif hasattr(pipe, \"system_prompt\"):\n",
    "                    try:\n",
    "                        setattr(pipe, \"system_prompt\", system_prompt)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                elif hasattr(pipe, \"prompt\"):\n",
    "                    try:\n",
    "                        setattr(pipe, \"prompt\", system_prompt)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            out = pipe.answer_with_trace(q)\n",
    "\n",
    "        # outì´ dictì¼ ìˆ˜ë„ ìˆê³ , (answer, ctxs, trace) íŠœí”Œì¼ ìˆ˜ë„ ìˆì–´ì„œ ì•ˆì „ ì²˜ë¦¬\n",
    "        ans, ctxs, trace = \"\", [], None\n",
    "\n",
    "        if isinstance(out, dict):\n",
    "            ans = out.get(\"answer\") or out.get(\"result\") or out.get(\"output\") or out.get(\"text\") or \"\"\n",
    "            ctxs = out.get(\"contexts\") or out.get(\"context\") or out.get(\"docs\") or []\n",
    "            trace = out.get(\"trace\") or out.get(\"debug\") or out.get(\"meta\")\n",
    "        elif isinstance(out, tuple):\n",
    "            # í”í•œ íŒ¨í„´ë“¤ ëŒ€ì‘\n",
    "            if len(out) == 3:\n",
    "                ans, ctxs, trace = out\n",
    "            elif len(out) == 2:\n",
    "                ans, ctxs = out\n",
    "            elif len(out) == 1:\n",
    "                ans = out[0]\n",
    "        else:\n",
    "            ans = str(out)\n",
    "\n",
    "        samples.append({\n",
    "            \"question\": q,\n",
    "            \"answer\": ans or \"\",\n",
    "            \"contexts\": shrink_contexts(ctxs, max_chars=max_chars, max_contexts=max_contexts),\n",
    "            \"ground_truth\": row_get_ground_truth(r) or \"\",\n",
    "            \"_trace\": trace,  # âœ… traceë„ ê°™ì´ ë³´ê´€(ì›í•˜ë©´ ì €ì¥ ê°€ëŠ¥)\n",
    "        })\n",
    "\n",
    "    return samples\n",
    "\n",
    "# âœ… ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸: 1ë¬¸ì œë§Œ (ì›í•˜ë©´ limit=1 ì¶”ì²œ)\n",
    "BASE_SAMPLES = run_pipe_to_samples(base_pipe, rows, system_prompt=SYSTEM_PROMPT_BASE, limit=None)\n",
    "EXP_SAMPLES  = run_pipe_to_samples(exp_pipe,  rows, system_prompt=SYSTEM_PROMPT_EXP,  limit=None)\n",
    "\n",
    "print(\"âœ… BASE_SAMPLES:\", len(BASE_SAMPLES))\n",
    "print(\"âœ… EXP_SAMPLES :\", len(EXP_SAMPLES))\n",
    "\n",
    "pd.DataFrame([{k: v for k, v in BASE_SAMPLES[0].items() if k != \"_trace\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286a3c26",
   "metadata": {},
   "source": [
    "## 6) RAGAS evaluation (prepared cell)\n",
    "\n",
    "- Creates per-sample detail dataframe (when supported by your RAGAS version)\n",
    "- Creates summary dataframe (mean over samples)\n",
    "- Keeps timing metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10a15582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… METRICS: ['ContextPrecision', 'ContextRecall', 'Faithfulness', 'AnswerRelevancy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4888\\3329233587.py:30: DeprecationWarning: Importing context_precision from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_precision\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4888\\3329233587.py:30: DeprecationWarning: Importing context_recall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_recall\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4888\\3329233587.py:30: DeprecationWarning: Importing faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import faithfulness\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4888\\3329233587.py:34: DeprecationWarning: Importing answer_relevancy from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import answer_relevancy\n",
      "  from ragas.metrics import answer_relevancy\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# RAGAS compare + clean saving (ragas==0.3.2 compatible)\n",
    "# FIXES:\n",
    "#  1) detail.csvì—ì„œ _trace ì œê±° (traceëŠ” trace.jsonlë¡œë§Œ)\n",
    "#  2) samplesì— run_tagë¥¼ ë¯¸ë¦¬ ì£¼ì…í•´ì„œ trace.jsonlì— íƒœê·¸ê°€ ë‚¨ë„ë¡\n",
    "#  3) ground_truths=[...] ì•ˆì „ì¥ì¹˜ ì¶”ê°€ (ë²„ì „/í™˜ê²½ í˜¸í™˜ì„±â†‘)\n",
    "#  4) samples/detail ì»¬ëŸ¼ ì¶©ëŒ ë°©ì§€(ê°€ëŠ¥í•œ í•œ ì•ˆì „í•˜ê²Œ merge)\n",
    "# ============================================================\n",
    "\n",
    "import time, json, re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.llms import llm_factory\n",
    "\n",
    "# ----------------------------\n",
    "# LLM + METRICS (ragas 0.3.2)\n",
    "# ----------------------------\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()  # OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©\n",
    "llm = llm_factory(\"gpt-4o-mini\", client=client)\n",
    "\n",
    "def build_metrics_032():\n",
    "    from ragas.metrics import context_precision, context_recall, faithfulness\n",
    "    metrics = [context_precision, context_recall, faithfulness]\n",
    "    # answer_relevancyëŠ” í™˜ê²½ì— ë”°ë¼ ì—†ì„ ìˆ˜ ìˆì–´ optional\n",
    "    try:\n",
    "        from ragas.metrics import answer_relevancy\n",
    "        metrics.append(answer_relevancy)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    return metrics\n",
    "\n",
    "METRICS = build_metrics_032()\n",
    "print(\"âœ… METRICS:\", [getattr(m, \"__name__\", m.__class__.__name__) for m in METRICS])\n",
    "\n",
    "# ----------------------------\n",
    "# utils\n",
    "# ----------------------------\n",
    "def _json_safe(obj):\n",
    "    \"\"\"Make config/meta safe to dump to json.\"\"\"\n",
    "    try:\n",
    "        json.dumps(obj, ensure_ascii=False)\n",
    "        return obj\n",
    "    except TypeError:\n",
    "        if hasattr(obj, \"model_dump\"):\n",
    "            return obj.model_dump()\n",
    "        if hasattr(obj, \"dict\"):\n",
    "            return obj.dict()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            return obj.__dict__\n",
    "        return str(obj)\n",
    "\n",
    "def _write_json(path: Path, data):\n",
    "    path.write_text(json.dumps(_json_safe(data), ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "def _write_jsonl(path: Path, rows):\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(_json_safe(r), ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def _next_run_dir(project_root: Path, prefix: str):\n",
    "    runs_root = Path(project_root) / \"results\" / \"ragas_runs\"\n",
    "    runs_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pat = re.compile(rf\"^{re.escape(prefix)}_(\\d{{4}})_\")\n",
    "    nums = []\n",
    "    for p in runs_root.iterdir():\n",
    "        if p.is_dir():\n",
    "            m = pat.match(p.name)\n",
    "            if m:\n",
    "                nums.append(int(m.group(1)))\n",
    "    next_idx = (max(nums) + 1) if nums else 1\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = runs_root / f\"{prefix}_{next_idx:04d}_{ts}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=False)\n",
    "    return run_dir, next_idx, ts\n",
    "\n",
    "def _strip_trace(samples):\n",
    "    \"\"\"detail.csvì—ëŠ” _traceë¥¼ ë„£ì§€ ì•Šê¸°(íŒŒì¼ í­ë°œ ë°©ì§€).\"\"\"\n",
    "    out = []\n",
    "    for s in samples:\n",
    "        if isinstance(s, dict):\n",
    "            out.append({k: v for k, v in s.items() if k != \"_trace\"})\n",
    "        else:\n",
    "            out.append(s)\n",
    "    return out\n",
    "\n",
    "# ----------------------------\n",
    "# core eval\n",
    "# ----------------------------\n",
    "def eval_ragas_with_details(samples, run_tag: str):\n",
    "    # âœ… samplesì— run_tagë¥¼ ë¯¸ë¦¬ ì£¼ì… (trace.jsonlì—ì„œ íƒœê·¸ ìœ ì§€)\n",
    "    for s in samples:\n",
    "        if isinstance(s, dict):\n",
    "            s[\"run_tag\"] = run_tag\n",
    "            # âœ… ì•ˆì „ì¥ì¹˜: ground_truthsë„ í•¨ê»˜\n",
    "            if \"ground_truths\" not in s:\n",
    "                gt = s.get(\"ground_truth\") or \"\"\n",
    "                s[\"ground_truths\"] = [gt] if isinstance(gt, str) else (gt or [])\n",
    "\n",
    "    ds = Dataset.from_list(samples)\n",
    "\n",
    "    t0 = time.time()\n",
    "    res = evaluate(dataset=ds, metrics=METRICS, llm=llm)  # âœ… 0.3.2 ì•ˆì „ íŒ¨í„´\n",
    "    eval_sec = time.time() - t0\n",
    "\n",
    "    t1 = time.time()\n",
    "    detail_df = res.to_pandas() if hasattr(res, \"to_pandas\") else pd.DataFrame()\n",
    "    to_pandas_sec = time.time() - t1\n",
    "\n",
    "    # âœ… detailì—ëŠ” _trace ì œì™¸\n",
    "    samples_df = pd.DataFrame(_strip_trace(samples))\n",
    "\n",
    "    # merge per-sample metrics back onto samples (ê¸¸ì´ ë™ì¼í•  ë•Œë§Œ)\n",
    "    if len(detail_df) == len(samples_df) and len(detail_df) > 0:\n",
    "        # ì¶©ëŒ ì»¬ëŸ¼ ë°©ì§€: detail_dfì˜ ì»¬ëŸ¼ì´ samples_dfì— ì´ë¯¸ ìˆìœ¼ë©´ prefix\n",
    "        overlap = set(samples_df.columns) & set(detail_df.columns)\n",
    "        if overlap:\n",
    "            detail_df = detail_df.rename(columns={c: f\"metric__{c}\" for c in overlap})\n",
    "\n",
    "        out_detail = pd.concat(\n",
    "            [samples_df.reset_index(drop=True), detail_df.reset_index(drop=True)],\n",
    "            axis=1\n",
    "        )\n",
    "    else:\n",
    "        out_detail = samples_df.copy()\n",
    "\n",
    "    out_detail[\"eval_seconds\"] = round(eval_sec, 3)\n",
    "    out_detail[\"to_pandas_seconds\"] = round(to_pandas_sec, 3)\n",
    "\n",
    "    # summary (mean of numeric metric columns if available)\n",
    "    summary = {}\n",
    "    if len(detail_df) > 0:\n",
    "        summary = detail_df.mean(numeric_only=True).to_dict()\n",
    "    elif isinstance(res, dict):\n",
    "        summary = {k: float(v) for k, v in res.items() if isinstance(v, (int, float))}\n",
    "\n",
    "    summary[\"run_tag\"] = run_tag\n",
    "    summary[\"eval_seconds\"] = round(eval_sec, 3)\n",
    "    summary[\"to_pandas_seconds\"] = round(to_pandas_sec, 3)\n",
    "\n",
    "    return res, out_detail, pd.DataFrame([summary])\n",
    "\n",
    "# ----------------------------\n",
    "# compare + save (clean)\n",
    "# ----------------------------\n",
    "def run_compare_and_save(\n",
    "    base_samples,\n",
    "    exp_samples,\n",
    "    project_root: Path,\n",
    "    prefix=\"ragas_compare\",\n",
    "    base_cfg=None,\n",
    "    exp_cfg=None,\n",
    "):\n",
    "    # --- sanity ---\n",
    "    print(f\"âœ… base_samples: {len(base_samples)} | exp_samples: {len(exp_samples)}\")\n",
    "\n",
    "    base_res, base_detail_df, base_summary_df = eval_ragas_with_details(base_samples, \"baseline\")\n",
    "    exp_res,  exp_detail_df,  exp_summary_df  = eval_ragas_with_details(exp_samples,  \"experiment\")\n",
    "\n",
    "    summary_df = pd.concat([base_summary_df, exp_summary_df], ignore_index=True)\n",
    "    detail_df  = pd.concat([base_detail_df,  exp_detail_df],  ignore_index=True)\n",
    "\n",
    "    run_dir, run_id, ts = _next_run_dir(project_root, prefix)\n",
    "\n",
    "    out_summary = run_dir / \"summary.csv\"\n",
    "    out_detail  = run_dir / \"detail.csv\"\n",
    "    out_meta    = run_dir / \"meta.json\"\n",
    "    out_config  = run_dir / \"config.json\"\n",
    "    out_base_in = run_dir / \"samples_base.jsonl\"\n",
    "    out_exp_in  = run_dir / \"samples_exp.jsonl\"\n",
    "    out_trace   = run_dir / \"trace.jsonl\"\n",
    "\n",
    "    summary_df.to_csv(out_summary, index=False, encoding=\"utf-8-sig\")\n",
    "    detail_df.to_csv(out_detail, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # config snapshot (best-effort)\n",
    "    cfg_payload = {\n",
    "        \"base_cfg\": _json_safe(base_cfg) if base_cfg is not None else None,\n",
    "        \"exp_cfg\":  _json_safe(exp_cfg)  if exp_cfg  is not None else None,\n",
    "        \"llm\": {\"model\": \"gpt-4o-mini\"},\n",
    "        \"metrics\": [getattr(m, \"__name__\", m.__class__.__name__) for m in METRICS],\n",
    "        \"created_at\": datetime.now().isoformat(),\n",
    "    }\n",
    "    _write_json(out_config, cfg_payload)\n",
    "\n",
    "    # input snapshots (ì›ë³¸ ìœ ì§€: _trace í¬í•¨)\n",
    "    _write_jsonl(out_base_in, base_samples)\n",
    "    _write_jsonl(out_exp_in,  exp_samples)\n",
    "\n",
    "    # trace snapshot (best-effort) - samplesì˜ _traceë§Œ ëª¨ì•„ì„œ ì €ì¥\n",
    "    trace_rows = []\n",
    "    for s in list(base_samples) + list(exp_samples):\n",
    "        if isinstance(s, dict) and (\"_trace\" in s) and (s.get(\"_trace\") is not None):\n",
    "            trace_rows.append({\n",
    "                \"run_tag\": s.get(\"run_tag\"),\n",
    "                \"question\": s.get(\"question\"),\n",
    "                \"_trace\": s.get(\"_trace\"),\n",
    "            })\n",
    "\n",
    "    # traceê°€ ì•„ì˜ˆ ì—†ìœ¼ë©´ ìµœì†Œ ì •ë³´ë¼ë„ ë‚¨ê¹€\n",
    "    if not trace_rows:\n",
    "        cols = [c for c in [\"run_tag\", \"question\", \"eval_seconds\"] if c in detail_df.columns]\n",
    "        trace_rows = detail_df[cols].to_dict(orient=\"records\") if cols else []\n",
    "\n",
    "    _write_jsonl(out_trace, trace_rows)\n",
    "\n",
    "    meta = {\n",
    "        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"ragas_version\": \"0.3.2\",\n",
    "        \"run_id\": run_id,\n",
    "        \"timestamp\": ts,\n",
    "        \"run_dir\": str(run_dir),\n",
    "        \"prefix\": prefix,\n",
    "        \"n_base_samples\": len(base_samples),\n",
    "        \"n_exp_samples\": len(exp_samples),\n",
    "        \"saved\": {\n",
    "            \"summary\": str(out_summary),\n",
    "            \"detail\": str(out_detail),\n",
    "            \"meta\": str(out_meta),\n",
    "            \"config\": str(out_config),\n",
    "            \"samples_base\": str(out_base_in),\n",
    "            \"samples_exp\": str(out_exp_in),\n",
    "            \"trace\": str(out_trace),\n",
    "        },\n",
    "    }\n",
    "    _write_json(out_meta, meta)\n",
    "\n",
    "    print(f\"âœ… Saved to: {run_dir}\")\n",
    "    print(f\"   - summary: {out_summary.name}\")\n",
    "    print(f\"   - detail : {out_detail.name}\")\n",
    "    print(f\"   - meta   : {out_meta.name}\")\n",
    "    print(f\"   - config : {out_config.name}\")\n",
    "    print(f\"   - inputs : {out_base_in.name}, {out_exp_in.name}\")\n",
    "    print(f\"   - trace  : {out_trace.name}\")\n",
    "\n",
    "    return {\n",
    "        \"base_res\": base_res,\n",
    "        \"exp_res\": exp_res,\n",
    "        \"summary_df\": summary_df,\n",
    "        \"detail_df\": detail_df,\n",
    "        \"run_dir\": run_dir,\n",
    "        \"out_summary\": out_summary,\n",
    "        \"out_detail\": out_detail,\n",
    "        \"out_meta\": out_meta,\n",
    "        \"out_config\": out_config,\n",
    "        \"out_samples_base\": out_base_in,\n",
    "        \"out_samples_exp\": out_exp_in,\n",
    "        \"out_trace\": out_trace,\n",
    "        \"run_id\": run_id,\n",
    "    }\n",
    "\n",
    "# ============================\n",
    "# USAGE (ì˜ˆì‹œ)\n",
    "# ============================\n",
    "# result = run_compare_and_save(\n",
    "#     base_samples=BASE_SAMPLES,\n",
    "#     exp_samples=EXP_SAMPLES,\n",
    "#     project_root=PROJECT_ROOT,\n",
    "#     prefix=\"ragas_compare\",\n",
    "#     base_cfg=base_cfg,\n",
    "#     exp_cfg=exp_cfg,\n",
    "# )\n",
    "# display(result[\"summary_df\"])\n",
    "# display(result[\"detail_df\"].head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee50b62",
   "metadata": {},
   "source": [
    "## 7) Run + compare + save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f39454-f368-4272-a7ed-116ed98f2ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29525fd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4888\\269887898.py:34: DeprecationWarning: Importing context_precision from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_precision\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4888\\269887898.py:34: DeprecationWarning: Importing context_recall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_recall\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4888\\269887898.py:34: DeprecationWarning: Importing faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import faithfulness\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4888\\269887898.py:37: DeprecationWarning: Importing answer_relevancy from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import answer_relevancy\n",
      "  from ragas.metrics import answer_relevancy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… METRICS: ['ContextPrecision', 'ContextRecall', 'Faithfulness', 'AnswerRelevancy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|                                                                               | 0/40 [00:00<?, ?it/s]2026-02-06 15:01:50,021 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:53,152 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:01:56,369 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:02:00,493 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:02:03,659 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:02:07,207 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:02:10,189 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:02:36,597 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:03:18,621 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:04:00,522 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:04:00,536 - ragas.executor - ERROR - Exception raised in Job[1]: InstructorRetryException(<failed_attempts>\n",
      "\n",
      "<generation number=\"1\">\n",
      "<exception>\n",
      "    The output is incomplete due to a max_tokens length limit.\n",
      "</exception>\n",
      "<completion>\n",
      "    ChatCompletion(id='chatcmpl-D69CtEv7OKcSqvxsI0WjvbzaluGgA', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n    \"classifications\": [\\n        {\\n            \"statement\": \"ë„¤, ê°•ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\\n            \"reason\": \"The answer directly affirms the ability to enforce the agreement, which aligns with the context regarding enforcement.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ27ì¡°ì— ë”°ë¥´ë©´,\",\\n            \"reason\": \"This statement references a specific law that is relevant to the context provided.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì œ26ì¡°ì œ4í•­ í›„ë‹¨ì— ë”°ë¼ ê°•ì œì§‘í–‰ì„ ìŠ¹ë‚™í•˜ëŠ” ì·¨ì§€ì˜ ë‚´ìš©ì´ ê¸°ì¬ëœ ì¡°ì •ì„œì˜ ì •ë³¸ì€\",\\n            \"reason\": \"This statement refers to a specific provision in the law that is mentioned in the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ã€Œë¯¼ì‚¬ì§‘í–‰ë²•ã€ ì œ56ì¡°ì—ë„ ë¶ˆêµ¬í•˜ê³ \",\\n            \"reason\": \"This statement references another law that is relevant to the enforcement context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì§‘í–‰ë ¥ ìˆëŠ” ì§‘í–‰ê¶Œì›ê³¼ ê°™ì€ íš¨ë ¥ì„ ê°€ì§‘ë‹ˆë‹¤.\",\\n            \"reason\": \"This statement explains the legal effect of the adjustment document, which is consistent with the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì¦‰, ì¡°ì •ì„œëŠ” ë‹¨ìˆœí•œ í•©ì˜ì„œê°€ ì•„ë‹ˆë¼\",\\n            \"reason\": \"This statement clarifies the nature of the adjustment document, which is supported by the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ê°•ì œì§‘í–‰ì´ ê°€ëŠ¥í•œ ì§‘í–‰ê¶Œì›ì…ë‹ˆë‹¤.\",\\n            \"reason\": \"This statement reiterates the enforcement capability of the adjustment document, aligning with the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë˜í•œ ì¡°ì •ì„œê°€ ì§‘í–‰ë ¥ì„ ê°–ê¸° ìœ„í•´ì„œëŠ”\",\\n            \"reason\": \"This statement introduces conditions for the enforcement of the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë²•ê³¼ ì‹œí–‰ë ¹ì—ì„œ ì •í•œ í˜•ì‹ê³¼ ìš”ê±´ì„ ê°–ì¶”ì–´ì•¼ í•©ë‹ˆë‹¤.\",\\n            \"reason\": \"This statement discusses the requirements for the adjustment document, which is mentioned in the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì´ì— ëŒ€í•´ ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì‹œí–‰ë ¹ ì œ34ì¡°ì— ë”°ë¥´ë©´,\",\\n            \"reason\": \"This statement references a specific regulation that is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì¡°ì •ì„œì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì‚¬í•­ì´ ê¸°ì¬ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:\",\\n            \"reason\": \"This statement introduces the necessary contents of the adjustment document, which is supported by the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì‚¬ê±´ë²ˆí˜¸ ë° ì‚¬ê±´ëª…\",\\n            \"reason\": \"This statement lists specific requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë‹¹ì‚¬ìì˜ ì„±ëª…, ìƒë…„ì›”ì¼ ë° ì£¼ì†Œ\",\\n            \"reason\": \"This statement continues to list requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ì°¨ì£¼íƒ ì†Œì¬ì§€\",\\n            \"reason\": \"This statement continues to list requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì‹ ì²­ì˜ ì·¨ì§€ ë° ì´ìœ \",\\n            \"reason\": \"This statement continues to list requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì¡°ì •ë‚´ìš©(ê°•ì œì§‘í–‰ì„ ìŠ¹ë‚™í•˜ëŠ” ì·¨ì§€ì˜ í•©ì˜ë¥¼ í¬í•¨)\",\\n            \"reason\": \"This statement continues to list requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì‘ì„±ì¼\",\\n            \"reason\": \"This statement continues to list requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ê·¸ë¦¬ê³  ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì‹œí–‰ë ¹ ì œ35ì¡°ì— ë”°ë¥´ë©´,\",\\n            \"reason\": \"This statement references another specific regulation that is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì¡°ì •ìœ„ì›íšŒëŠ” ì¡°ì •ì„œê°€ ì‘ì„±ëœ ê²½ìš°\",\\n            \"reason\": \"This statement discusses the role of the adjustment committee, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\":', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1770357731, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_f4ae844694', usage=CompletionUsage(completion_tokens=3072, prompt_tokens=13536, total_tokens=16608, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=8448)))\n",
      "</completion>\n",
      "</generation>\n",
      "\n",
      "<generation number=\"2\">\n",
      "<exception>\n",
      "    The output is incomplete due to a max_tokens length limit.\n",
      "</exception>\n",
      "<completion>\n",
      "    ChatCompletion(id='chatcmpl-D69DIniE2AqQSzcBX2Umjx2RgKqyQ', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n    \"classifications\": [\\n        {\\n            \"statement\": \"ë„¤, ê°•ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\\n            \"reason\": \"The answer directly affirms the ability to enforce the agreement, which aligns with the context discussing enforcement.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ27ì¡°ì— ë”°ë¥´ë©´,\",\\n            \"reason\": \"This statement references a specific law that is relevant to the context provided.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì œ26ì¡°ì œ4í•­ í›„ë‹¨ì— ë”°ë¼ ê°•ì œì§‘í–‰ì„ ìŠ¹ë‚™í•˜ëŠ” ì·¨ì§€ì˜ ë‚´ìš©ì´ ê¸°ì¬ëœ ì¡°ì •ì„œì˜ ì •ë³¸ì€\",\\n            \"reason\": \"This statement directly relates to the context discussing the enforcement of agreements under the law.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ã€Œë¯¼ì‚¬ì§‘í–‰ë²•ã€ ì œ56ì¡°ì—ë„ ë¶ˆêµ¬í•˜ê³ \",\\n            \"reason\": \"This statement references another law that is relevant to the enforcement context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì§‘í–‰ë ¥ ìˆëŠ” ì§‘í–‰ê¶Œì›ê³¼ ê°™ì€ íš¨ë ¥ì„ ê°€ì§‘ë‹ˆë‹¤.\",\\n            \"reason\": \"This statement explains the legal effect of the adjustment document, which is directly related to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì¦‰, ì¡°ì •ì„œëŠ” ë‹¨ìˆœí•œ í•©ì˜ì„œê°€ ì•„ë‹ˆë¼\",\\n            \"reason\": \"This statement clarifies the nature of the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ê°•ì œì§‘í–‰ì´ ê°€ëŠ¥í•œ ì§‘í–‰ê¶Œì›ì…ë‹ˆë‹¤.\",\\n            \"reason\": \"This statement reiterates the enforceability of the adjustment document, which is consistent with the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë˜í•œ ì¡°ì •ì„œê°€ ì§‘í–‰ë ¥ì„ ê°–ê¸° ìœ„í•´ì„œëŠ”\",\\n            \"reason\": \"This statement discusses the requirements for the adjustment document to have enforceability, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë²•ê³¼ ì‹œí–‰ë ¹ì—ì„œ ì •í•œ í˜•ì‹ê³¼ ìš”ê±´ì„ ê°–ì¶”ì–´ì•¼ í•©ë‹ˆë‹¤.\",\\n            \"reason\": \"This statement outlines the necessary conditions for enforceability, which aligns with the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì´ì— ëŒ€í•´ ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì‹œí–‰ë ¹ ì œ34ì¡°ì— ë”°ë¥´ë©´,\",\\n            \"reason\": \"This statement references a specific regulation that is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì¡°ì •ì„œì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì‚¬í•­ì´ ê¸°ì¬ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:\",\\n            \"reason\": \"This statement introduces a list of requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì‚¬ê±´ë²ˆí˜¸ ë° ì‚¬ê±´ëª…\",\\n            \"reason\": \"This statement is part of the list of requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë‹¹ì‚¬ìì˜ ì„±ëª…, ìƒë…„ì›”ì¼ ë° ì£¼ì†Œ\",\\n            \"reason\": \"This statement is part of the list of requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ì°¨ì£¼íƒ ì†Œì¬ì§€\",\\n            \"reason\": \"This statement is part of the list of requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì‹ ì²­ì˜ ì·¨ì§€ ë° ì´ìœ \",\\n            \"reason\": \"This statement is part of the list of requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì¡°ì •ë‚´ìš©(ê°•ì œì§‘í–‰ì„ ìŠ¹ë‚™í•˜ëŠ” ì·¨ì§€ì˜ í•©ì˜ë¥¼ í¬í•¨)\",\\n            \"reason\": \"This statement is part of the list of requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì‘ì„±ì¼\",\\n            \"reason\": \"This statement is part of the list of requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ê·¸ë¦¬ê³  ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì‹œí–‰ë ¹ ì œ35ì¡°ì— ë”°ë¥´ë©´,\",\\n            \"reason\": \"This statement references another specific regulation that is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì¡°ì •ìœ„ì›íšŒëŠ” ì¡°ì •ì„œê°€ ì‘ì„±ëœ ê²½ìš°\",\\n            \"reason\": \"This statement discusses the responsibilities of the adjustment committee,', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1770357756, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_f4ae844694', usage=CompletionUsage(completion_tokens=3072, prompt_tokens=13536, total_tokens=16608, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=8448)))\n",
      "</completion>\n",
      "</generation>\n",
      "\n",
      "<generation number=\"3\">\n",
      "<exception>\n",
      "    The output is incomplete due to a max_tokens length limit.\n",
      "</exception>\n",
      "<completion>\n",
      "    ChatCompletion(id='chatcmpl-D69Dy8grhp2izHdY8Kpahef1w8YYq', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n    \"classifications\": [\\n        {\\n            \"statement\": \"ë„¤, ê°•ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\\n            \"reason\": \"The answer directly affirms the ability to enforce the agreement, which aligns with the context discussing enforcement.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ27ì¡°ì— ë”°ë¥´ë©´,\",\\n            \"reason\": \"This statement references a specific law that is relevant to the context provided.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì œ26ì¡°ì œ4í•­ í›„ë‹¨ì— ë”°ë¼ ê°•ì œì§‘í–‰ì„ ìŠ¹ë‚™í•˜ëŠ” ì·¨ì§€ì˜ ë‚´ìš©ì´ ê¸°ì¬ëœ ì¡°ì •ì„œì˜ ì •ë³¸ì€\",\\n            \"reason\": \"This statement directly relates to the context discussing the enforcement of agreements under the law.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ã€Œë¯¼ì‚¬ì§‘í–‰ë²•ã€ ì œ56ì¡°ì—ë„ ë¶ˆêµ¬í•˜ê³ \",\\n            \"reason\": \"This statement references another law that is relevant to the enforcement context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì§‘í–‰ë ¥ ìˆëŠ” ì§‘í–‰ê¶Œì›ê³¼ ê°™ì€ íš¨ë ¥ì„ ê°€ì§‘ë‹ˆë‹¤.\",\\n            \"reason\": \"This statement explains the legal effect of the adjustment document, which is directly related to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì¦‰, ì¡°ì •ì„œëŠ” ë‹¨ìˆœí•œ í•©ì˜ì„œê°€ ì•„ë‹ˆë¼\",\\n            \"reason\": \"This statement clarifies the nature of the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ê°•ì œì§‘í–‰ì´ ê°€ëŠ¥í•œ ì§‘í–‰ê¶Œì›ì…ë‹ˆë‹¤.\",\\n            \"reason\": \"This statement reiterates the enforceability of the adjustment document, which is consistent with the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë˜í•œ ì¡°ì •ì„œê°€ ì§‘í–‰ë ¥ì„ ê°–ê¸° ìœ„í•´ì„œëŠ”\",\\n            \"reason\": \"This statement discusses the requirements for the adjustment document to have enforceability, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë²•ê³¼ ì‹œí–‰ë ¹ì—ì„œ ì •í•œ í˜•ì‹ê³¼ ìš”ê±´ì„ ê°–ì¶”ì–´ì•¼ í•©ë‹ˆë‹¤.\",\\n            \"reason\": \"This statement outlines the necessary conditions for enforceability, which aligns with the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì´ì— ëŒ€í•´ ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì‹œí–‰ë ¹ ì œ34ì¡°ì— ë”°ë¥´ë©´,\",\\n            \"reason\": \"This statement references a specific regulation that is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì¡°ì •ì„œì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì‚¬í•­ì´ ê¸°ì¬ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:\",\\n            \"reason\": \"This statement introduces a list of requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì‚¬ê±´ë²ˆí˜¸ ë° ì‚¬ê±´ëª…\",\\n            \"reason\": \"This statement is part of the list of requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë‹¹ì‚¬ìì˜ ì„±ëª…, ìƒë…„ì›”ì¼ ë° ì£¼ì†Œ\",\\n            \"reason\": \"This statement is part of the list of requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ì°¨ì£¼íƒ ì†Œì¬ì§€\",\\n            \"reason\": \"This statement is part of the list of requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì‹ ì²­ì˜ ì·¨ì§€ ë° ì´ìœ \",\\n            \"reason\": \"This statement is part of the list of requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì¡°ì •ë‚´ìš©(ê°•ì œì§‘í–‰ì„ ìŠ¹ë‚™í•˜ëŠ” ì·¨ì§€ì˜ í•©ì˜ë¥¼ í¬í•¨)\",\\n            \"reason\": \"This statement is part of the list of requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì‘ì„±ì¼\",\\n            \"reason\": \"This statement is part of the list of requirements for the adjustment document, which is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ê·¸ë¦¬ê³  ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì‹œí–‰ë ¹ ì œ35ì¡°ì— ë”°ë¥´ë©´,\",\\n            \"reason\": \"This statement references another specific regulation that is relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì¡°ì •ìœ„ì›íšŒëŠ” ì¡°ì •ì„œê°€ ì‘ì„±ëœ ê²½ìš°\",\\n            \"reason\": \"This statement discusses the responsibilities of the adjustment committee,', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1770357798, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_f4ae844694', usage=CompletionUsage(completion_tokens=3072, prompt_tokens=13536, total_tokens=16608, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=8448)))\n",
      "</completion>\n",
      "</generation>\n",
      "\n",
      "</failed_attempts>\n",
      "\n",
      "<last_exception>\n",
      "    The output is incomplete due to a max_tokens length limit.\n",
      "</last_exception>)\n",
      "2026-02-06 15:04:04,362 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:04:25,783 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:04:28,406 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:04:29,169 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 15:04:29,843 - ragas.executor - ERROR - Exception raised in Job[3]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 15:04:32,753 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:04:37,374 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:04:40,515 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:04:43,852 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:04:46,825 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:04:49,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:04:52,854 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:05:16,251 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:05:23,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:05:44,095 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:05:46,476 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:05:47,147 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 15:05:47,842 - ragas.executor - ERROR - Exception raised in Job[7]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 15:05:50,029 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:05:52,943 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:05:55,687 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:05:58,686 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:06:01,439 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:06:04,425 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:06:08,106 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:06:22,039 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:06:27,851 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:06:44,512 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:06:47,020 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:06:47,719 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 15:06:48,404 - ragas.executor - ERROR - Exception raised in Job[11]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 15:06:50,631 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:06:53,405 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:06:56,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:06:59,559 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:07:02,252 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:07:24,625 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:07:40,611 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:07:46,600 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:07:58,080 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:08:00,256 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:08:01,045 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 15:08:01,727 - ragas.executor - ERROR - Exception raised in Job[15]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 15:08:04,246 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:08:07,046 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:08:09,975 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:08:12,999 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:08:16,096 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:08:18,997 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:08:21,637 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:08:35,161 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:08:41,333 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:09:01,323 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:09:04,009 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:09:04,711 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 15:09:05,335 - ragas.executor - ERROR - Exception raised in Job[19]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 15:09:07,800 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:09:10,864 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:09:13,721 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:09:16,717 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:09:19,469 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:09:40,995 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:09:58,985 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:10:21,296 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:10:21,303 - ragas.executor - ERROR - Exception raised in Job[21]: InstructorRetryException(<failed_attempts>\n",
      "\n",
      "<generation number=\"1\">\n",
      "<exception>\n",
      "    The output is incomplete due to a max_tokens length limit.\n",
      "</exception>\n",
      "<completion>\n",
      "    ChatCompletion(id='chatcmpl-D69JpTfFNuUN7WKIvNwx1ddYidFNl', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n    \"classifications\": [\\n        {\\n            \"statement\": \"ì›ì¹™ì ìœ¼ë¡œ ìƒˆ ì§‘ì£¼ì¸ì—ê²Œ ë³´ì¦ê¸ˆì„ ì²­êµ¬í•´ì•¼ í•©ë‹ˆë‹¤.\",\\n            \"reason\": \"The statement aligns with the context that discusses the obligations of the new landlord regarding the security deposit.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ3ì¡° ì œ1í•­ì— ë”°ë¥´ë©´,\",\\n            \"reason\": \"The reference to the housing lease protection law is relevant to the context provided.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ì°¨ì¸ì´ ì£¼íƒì˜ ì¸ë„ì™€ ì£¼ë¯¼ë“±ë¡ì„ ë§ˆì³ ëŒ€í•­ë ¥ì„ ê°–ì¶˜ ìƒíƒœë¼ë©´,\",\\n            \"reason\": \"This condition is mentioned in the context regarding the tenant\\'s rights and obligations.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ê·¸ ì´í›„ì— ì£¼íƒì„ ë§¤ìˆ˜í•œ ìƒˆ ì§‘ì£¼ì¸ì—ê²Œë„ ì„ëŒ€ì°¨ì˜ íš¨ë ¥ì„ ì£¼ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\\n            \"reason\": \"This statement reflects the legal principle discussed in the context about the transfer of lease rights to the new landlord.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì¦‰, ì„ëŒ€ì°¨ê´€ê³„ëŠ” ì¢…ì „ ì§‘ì£¼ì¸ ê°œì¸ì—ê²Œë§Œ ë¬¶ì—¬ ìˆëŠ” ê²ƒì´ ì•„ë‹ˆë¼,\",\\n            \"reason\": \"This statement is consistent with the context that explains the nature of the lease relationship.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì£¼íƒ ì†Œìœ ê¶Œê³¼ ê²°í•©ëœ ìƒíƒœë¡œ ìƒˆ ì§‘ì£¼ì¸ì—ê²Œ ì´ì „ë©ë‹ˆë‹¤.\",\\n            \"reason\": \"This is a direct reference to the legal transfer of rights mentioned in the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì´ ê²½ìš° ë³´ì¦ê¸ˆ ë°˜í™˜ì˜ë¬´ ì—­ì‹œ í•¨ê»˜ ì´ì „ë©ë‹ˆë‹¤.\",\\n            \"reason\": \"This statement is supported by the context that discusses the obligations of the new landlord regarding the security deposit.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ3ì¡° ì œ4í•­ì— ë”°ë¥´ë©´,\",\\n            \"reason\": \"The reference to the housing lease protection law is relevant to the context provided.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ì°¨ì£¼íƒì˜ ì–‘ìˆ˜ì¸(ê·¸ ë°–ì— ì„ëŒ€í•  ê¶Œë¦¬ë¥¼ ìŠ¹ê³„í•œ ìë¥¼ í¬í•¨í•œë‹¤)ì€\",\\n            \"reason\": \"This statement is consistent with the context that discusses the rights of the new landlord.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ëŒ€ì¸ì˜ ì§€ìœ„ë¥¼ ìŠ¹ê³„í•œ ê²ƒìœ¼ë¡œ ë³¸ë‹¤ê³  ëª…í™•íˆ ê·œì •í•˜ê³  ìˆìŠµë‹ˆë‹¤.\",\\n            \"reason\": \"This is a direct reference to the legal principle discussed in the context about the transfer of landlord status.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì´ëŠ” ì£¼íƒ ì†Œìœ ê¶Œì„ ì·¨ë“í•œ ìƒˆ ì§‘ì£¼ì¸ì´\",\\n            \"reason\": \"This statement reflects the legal principle discussed in the context about the new landlord\\'s obligations.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë²•ë¥ ìƒ ë‹¹ì—°íˆ ì¢…ì „ ì„ëŒ€ì¸ì˜ ì§€ìœ„ì™€ ì˜ë¬´ë¥¼ ìŠ¹ê³„í•œë‹¤ëŠ” ì˜ë¯¸ì´ë©°,\",\\n            \"reason\": \"This is a direct reference to the legal transfer of obligations mentioned in the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë³´ì¦ê¸ˆ ë°˜í™˜ì˜ë¬´ë„ ì´ì— í¬í•¨ë©ë‹ˆë‹¤.\",\\n            \"reason\": \"This statement is supported by the context that discusses the obligations of the new landlord regarding the security deposit.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë”°ë¼ì„œ ê³„ì•½ê¸°ê°„ ì¤‘ ì§‘ì£¼ì¸ì´ ë°”ë€Œì—ˆê³ ,\",\\n            \"reason\": \"This statement is a summary of the situation described in the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ì°¨ì¸ì´ ëŒ€í•­ë ¥ì„ ê°–ì¶˜ ìƒíƒœë¼ë©´,\",\\n            \"reason\": \"This condition is mentioned in the context regarding the tenant\\'s rights and obligations.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ì°¨ì¸ì€ ì¢…ì „ ì§‘ì£¼ì¸ì´ ì•„ë‹ˆë¼ ìƒˆ ì§‘ì£¼ì¸ì—ê²Œ ë³´ì¦ê¸ˆ ë°˜í™˜ì„ ì²­êµ¬í•´ì•¼ í•©ë‹ˆë‹¤.\",\\n            \"reason\": \"This statement directly reflects the legal principle discussed in the context about the tenant\\'s rights.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë°˜ëŒ€ë¡œ, ì„ì°¨ì¸ì´ ëŒ€í•­ë ¥ì„ ê°–ì¶”ì§€ ëª»í•œ ìƒíƒœì—ì„œ\",\\n            \"reason\": \"This condition is mentioned in the context regarding the tenant\\'s rights and obligations.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì£¼íƒ ì†Œìœ ê¶Œì´ ì´ì „ëœ ê²½ìš°ì—ëŠ”\",\\n            \"reason\": \"This statement reflects the legal principle discussed in the', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1770358161, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_f4ae844694', usage=CompletionUsage(completion_tokens=3072, prompt_tokens=11499, total_tokens=14571, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=6912)))\n",
      "</completion>\n",
      "</generation>\n",
      "\n",
      "<generation number=\"2\">\n",
      "<exception>\n",
      "    The output is incomplete due to a max_tokens length limit.\n",
      "</exception>\n",
      "<completion>\n",
      "    ChatCompletion(id='chatcmpl-D69K9fRWlawDRXyRlEQGkqo9e7dXF', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n    \"classifications\": [\\n        {\\n            \"statement\": \"ì›ì¹™ì ìœ¼ë¡œ ìƒˆ ì§‘ì£¼ì¸ì—ê²Œ ë³´ì¦ê¸ˆì„ ì²­êµ¬í•´ì•¼ í•©ë‹ˆë‹¤.\",\\n            \"reason\": \"The statement aligns with the context that discusses the obligations of the new landlord regarding the security deposit.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ3ì¡° ì œ1í•­ì— ë”°ë¥´ë©´,\",\\n            \"reason\": \"This references a specific law that is relevant to the context provided.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ì°¨ì¸ì´ ì£¼íƒì˜ ì¸ë„ì™€ ì£¼ë¯¼ë“±ë¡ì„ ë§ˆì³ ëŒ€í•­ë ¥ì„ ê°–ì¶˜ ìƒíƒœë¼ë©´,\",\\n            \"reason\": \"This condition is mentioned in the context regarding the tenant\\'s rights.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ê·¸ ì´í›„ì— ì£¼íƒì„ ë§¤ìˆ˜í•œ ìƒˆ ì§‘ì£¼ì¸ì—ê²Œë„ ì„ëŒ€ì°¨ì˜ íš¨ë ¥ì„ ì£¼ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\\n            \"reason\": \"This is consistent with the context that explains the transfer of rental rights to the new landlord.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì¦‰, ì„ëŒ€ì°¨ê´€ê³„ëŠ” ì¢…ì „ ì§‘ì£¼ì¸ ê°œì¸ì—ê²Œë§Œ ë¬¶ì—¬ ìˆëŠ” ê²ƒì´ ì•„ë‹ˆë¼,\",\\n            \"reason\": \"This statement reflects the legal principle discussed in the context about the continuity of rental agreements.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì£¼íƒ ì†Œìœ ê¶Œê³¼ ê²°í•©ëœ ìƒíƒœë¡œ ìƒˆ ì§‘ì£¼ì¸ì—ê²Œ ì´ì „ë©ë‹ˆë‹¤.\",\\n            \"reason\": \"This is a direct reference to the legal transfer of rights mentioned in the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì´ ê²½ìš° ë³´ì¦ê¸ˆ ë°˜í™˜ì˜ë¬´ ì—­ì‹œ í•¨ê»˜ ì´ì „ë©ë‹ˆë‹¤.\",\\n            \"reason\": \"This statement is supported by the context that discusses the obligations of the new landlord regarding the security deposit.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ3ì¡° ì œ4í•­ì— ë”°ë¥´ë©´,\",\\n            \"reason\": \"This references another specific law relevant to the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ì°¨ì£¼íƒì˜ ì–‘ìˆ˜ì¸(ê·¸ ë°–ì— ì„ëŒ€í•  ê¶Œë¦¬ë¥¼ ìŠ¹ê³„í•œ ìë¥¼ í¬í•¨í•œë‹¤)ì€\",\\n            \"reason\": \"This is consistent with the context that discusses the rights of the new landlord.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ëŒ€ì¸ì˜ ì§€ìœ„ë¥¼ ìŠ¹ê³„í•œ ê²ƒìœ¼ë¡œ ë³¸ë‹¤ê³  ëª…í™•íˆ ê·œì •í•˜ê³  ìˆìŠµë‹ˆë‹¤.\",\\n            \"reason\": \"This statement is supported by the context regarding the legal succession of landlord rights.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì´ëŠ” ì£¼íƒ ì†Œìœ ê¶Œì„ ì·¨ë“í•œ ìƒˆ ì§‘ì£¼ì¸ì´ ë²•ë¥ ìƒ ë‹¹ì—°íˆ ì¢…ì „ ì„ëŒ€ì¸ì˜ ì§€ìœ„ì™€ ì˜ë¬´ë¥¼ ìŠ¹ê³„í•œë‹¤ëŠ” ì˜ë¯¸ì´ë©°,\",\\n            \"reason\": \"This reflects the legal implications discussed in the context about the new landlord\\'s responsibilities.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë³´ì¦ê¸ˆ ë°˜í™˜ì˜ë¬´ë„ ì´ì— í¬í•¨ë©ë‹ˆë‹¤.\",\\n            \"reason\": \"This is consistent with the context that discusses the obligations of the new landlord regarding the security deposit.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë”°ë¼ì„œ ê³„ì•½ê¸°ê°„ ì¤‘ ì§‘ì£¼ì¸ì´ ë°”ë€Œì—ˆê³ ,\",\\n            \"reason\": \"This statement directly relates to the situation described in the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ì°¨ì¸ì´ ëŒ€í•­ë ¥ì„ ê°–ì¶˜ ìƒíƒœë¼ë©´,\",\\n            \"reason\": \"This condition is mentioned in the context regarding the tenant\\'s rights.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ì°¨ì¸ì€ ì¢…ì „ ì§‘ì£¼ì¸ì´ ì•„ë‹ˆë¼ ìƒˆ ì§‘ì£¼ì¸ì—ê²Œ ë³´ì¦ê¸ˆ ë°˜í™˜ì„ ì²­êµ¬í•´ì•¼ í•©ë‹ˆë‹¤.\",\\n            \"reason\": \"This is a direct conclusion drawn from the context regarding the security deposit claims.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë°˜ëŒ€ë¡œ, ì„ì°¨ì¸ì´ ëŒ€í•­ë ¥ì„ ê°–ì¶”ì§€ ëª»í•œ ìƒíƒœì—ì„œ ì£¼íƒ ì†Œìœ ê¶Œì´ ì´ì „ëœ ê²½ìš°ì—ëŠ”\",\\n            \"reason\": \"This statement discusses a scenario that is relevant to the context provided.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ëŒ€ì°¨ê´€ê³„ ìì²´ë¥¼ ìƒˆ ì§‘ì£¼ì¸ì—ê²Œ ì£¼ì¥í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ,\",\\n            \"reason\": \"This reflects the legal implications discussed in the context about the tenant\\'s rights.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì´ ê²½ìš°ì—ëŠ” ì¢…ì „ ì§‘ì£¼ì¸ì—ê²Œë§Œ ë³´ì¦ê¸ˆì„ ì²­êµ¬í•´ì•¼ í•©ë‹ˆë‹¤.\",\\n            \"reason\": \"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1770358181, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_f4ae844694', usage=CompletionUsage(completion_tokens=3072, prompt_tokens=11499, total_tokens=14571, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=6912)))\n",
      "</completion>\n",
      "</generation>\n",
      "\n",
      "<generation number=\"3\">\n",
      "<exception>\n",
      "    The output is incomplete due to a max_tokens length limit.\n",
      "</exception>\n",
      "<completion>\n",
      "    ChatCompletion(id='chatcmpl-D69KRM762QNFk1jVvFqXtn3agfG38', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n    \"classifications\": [\\n        {\\n            \"statement\": \"ì›ì¹™ì ìœ¼ë¡œ ìƒˆ ì§‘ì£¼ì¸ì—ê²Œ ë³´ì¦ê¸ˆì„ ì²­êµ¬í•´ì•¼ í•©ë‹ˆë‹¤.\",\\n            \"reason\": \"The statement aligns with the context that discusses the obligations of the new landlord regarding the security deposit.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ3ì¡° ì œ1í•­ì— ë”°ë¥´ë©´,\",\\n            \"reason\": \"This references a specific law that is relevant to the context provided.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ì°¨ì¸ì´ ì£¼íƒì˜ ì¸ë„ì™€ ì£¼ë¯¼ë“±ë¡ì„ ë§ˆì³ ëŒ€í•­ë ¥ì„ ê°–ì¶˜ ìƒíƒœë¼ë©´,\",\\n            \"reason\": \"The concept of \\'ëŒ€í•­ë ¥\\' (the right to claim) is mentioned in the context, making this statement relevant.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ê·¸ ì´í›„ì— ì£¼íƒì„ ë§¤ìˆ˜í•œ ìƒˆ ì§‘ì£¼ì¸ì—ê²Œë„ ì„ëŒ€ì°¨ì˜ íš¨ë ¥ì„ ì£¼ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\\n            \"reason\": \"This statement is consistent with the context that explains the transfer of rental rights to the new landlord.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì¦‰, ì„ëŒ€ì°¨ê´€ê³„ëŠ” ì¢…ì „ ì§‘ì£¼ì¸ ê°œì¸ì—ê²Œë§Œ ë¬¶ì—¬ ìˆëŠ” ê²ƒì´ ì•„ë‹ˆë¼,\",\\n            \"reason\": \"This reflects the context\\'s explanation of the rental relationship not being limited to the previous landlord.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì£¼íƒ ì†Œìœ ê¶Œê³¼ ê²°í•©ëœ ìƒíƒœë¡œ ìƒˆ ì§‘ì£¼ì¸ì—ê²Œ ì´ì „ë©ë‹ˆë‹¤.\",\\n            \"reason\": \"This is a direct interpretation of the context regarding the transfer of ownership and rights.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì´ ê²½ìš° ë³´ì¦ê¸ˆ ë°˜í™˜ì˜ë¬´ ì—­ì‹œ í•¨ê»˜ ì´ì „ë©ë‹ˆë‹¤.\",\\n            \"reason\": \"This statement is supported by the context that discusses the obligations of the new landlord regarding the security deposit.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ3ì¡° ì œ4í•­ì— ë”°ë¥´ë©´,\",\\n            \"reason\": \"This references another specific law that is relevant to the context provided.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ì°¨ì£¼íƒì˜ ì–‘ìˆ˜ì¸(ê·¸ ë°–ì— ì„ëŒ€í•  ê¶Œë¦¬ë¥¼ ìŠ¹ê³„í•œ ìë¥¼ í¬í•¨í•œë‹¤)ì€\",\\n            \"reason\": \"This statement is relevant as it discusses the rights of the new landlord as mentioned in the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ëŒ€ì¸ì˜ ì§€ìœ„ë¥¼ ìŠ¹ê³„í•œ ê²ƒìœ¼ë¡œ ë³¸ë‹¤ê³  ëª…í™•íˆ ê·œì •í•˜ê³  ìˆìŠµë‹ˆë‹¤.\",\\n            \"reason\": \"This is a direct interpretation of the context regarding the transfer of landlord status.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì´ëŠ” ì£¼íƒ ì†Œìœ ê¶Œì„ ì·¨ë“í•œ ìƒˆ ì§‘ì£¼ì¸ì´ ë²•ë¥ ìƒ ë‹¹ì—°íˆ ì¢…ì „ ì„ëŒ€ì¸ì˜ ì§€ìœ„ì™€ ì˜ë¬´ë¥¼ ìŠ¹ê³„í•œë‹¤ëŠ” ì˜ë¯¸ì´ë©°,\",\\n            \"reason\": \"This statement is consistent with the context that explains the legal implications of ownership transfer.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë³´ì¦ê¸ˆ ë°˜í™˜ì˜ë¬´ë„ ì´ì— í¬í•¨ë©ë‹ˆë‹¤.\",\\n            \"reason\": \"This is supported by the context that discusses the obligations of the new landlord regarding the security deposit.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë”°ë¼ì„œ ê³„ì•½ê¸°ê°„ ì¤‘ ì§‘ì£¼ì¸ì´ ë°”ë€Œì—ˆê³ ,\",\\n            \"reason\": \"This statement is a summary of the situation described in the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ì°¨ì¸ì´ ëŒ€í•­ë ¥ì„ ê°–ì¶˜ ìƒíƒœë¼ë©´,\",\\n            \"reason\": \"This is relevant as it refers to the condition of the tenant\\'s rights mentioned in the context.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ì°¨ì¸ì€ ì¢…ì „ ì§‘ì£¼ì¸ì´ ì•„ë‹ˆë¼ ìƒˆ ì§‘ì£¼ì¸ì—ê²Œ ë³´ì¦ê¸ˆ ë°˜í™˜ì„ ì²­êµ¬í•´ì•¼ í•©ë‹ˆë‹¤.\",\\n            \"reason\": \"This statement directly reflects the conclusion drawn in the context regarding the security deposit.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ë°˜ëŒ€ë¡œ, ì„ì°¨ì¸ì´ ëŒ€í•­ë ¥ì„ ê°–ì¶”ì§€ ëª»í•œ ìƒíƒœì—ì„œ ì£¼íƒ ì†Œìœ ê¶Œì´ ì´ì „ëœ ê²½ìš°ì—ëŠ”\",\\n            \"reason\": \"This statement introduces a condition that is discussed in the context regarding the tenant\\'s rights.\",\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"ì„ëŒ€ì°¨ê´€ê³„ ìì²´ë¥¼ ìƒˆ ì§‘ì£¼ì¸ì—ê²Œ ì£¼ì¥í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ,\",\\n            \"reason\": \"This is consistent with the context that explains the limitations of the tenant\\'s rights under certain conditions.\",\\n            \"attributed', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1770358199, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_f4ae844694', usage=CompletionUsage(completion_tokens=3072, prompt_tokens=11499, total_tokens=14571, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=6912)))\n",
      "</completion>\n",
      "</generation>\n",
      "\n",
      "</failed_attempts>\n",
      "\n",
      "<last_exception>\n",
      "    The output is incomplete due to a max_tokens length limit.\n",
      "</last_exception>)\n",
      "2026-02-06 15:10:26,180 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:10:44,410 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:10:46,802 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:10:47,511 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 15:10:48,178 - ragas.executor - ERROR - Exception raised in Job[23]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 15:10:49,669 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:10:52,711 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:10:55,567 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:10:58,543 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:11:01,271 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:11:04,085 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:11:06,885 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:11:32,785 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:11:38,885 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:11:53,002 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:11:55,479 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:11:56,145 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 15:11:56,785 - ragas.executor - ERROR - Exception raised in Job[27]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 15:11:58,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:12:01,702 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:12:04,410 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:12:07,724 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:12:10,473 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:12:13,222 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:12:15,944 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 15:12:33,410 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# One-cell: RAGAS compare + save (+ delta outputs + dataset fingerprint)\n",
    "# Adds:\n",
    "#  - delta_summary.csv\n",
    "#  - delta_detail.csv\n",
    "#  - top_regressions.csv\n",
    "#  - top_improvements.csv\n",
    "#  - meta.json: testset fingerprint (path/lines/sha1) if TESTSET_JSONL exists\n",
    "# ============================================================\n",
    "\n",
    "import time, re, json, hashlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "from openai import OpenAI\n",
    "from ragas import evaluate\n",
    "from ragas.llms import llm_factory\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# LLM (non-deprecated)\n",
    "# ----------------------------\n",
    "client = OpenAI()\n",
    "llm = llm_factory(\"gpt-4o-mini\", client=client)  # âœ… client ì „ë‹¬\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# METRICS (version-tolerant)\n",
    "# ----------------------------\n",
    "def build_metrics():\n",
    "    from ragas.metrics import context_precision, context_recall, faithfulness\n",
    "    metrics = [context_precision, context_recall, faithfulness]\n",
    "    try:\n",
    "        from ragas.metrics import answer_relevancy\n",
    "        metrics.append(answer_relevancy)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    return metrics\n",
    "\n",
    "METRICS = build_metrics()\n",
    "print(\"âœ… METRICS:\", [getattr(m, \"__name__\", m.__class__.__name__) for m in METRICS])\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# JSON helpers (safe)\n",
    "# ----------------------------\n",
    "def _json_safe(obj):\n",
    "    try:\n",
    "        json.dumps(obj, ensure_ascii=False)\n",
    "        return obj\n",
    "    except TypeError:\n",
    "        if hasattr(obj, \"model_dump\"):\n",
    "            return obj.model_dump()\n",
    "        if hasattr(obj, \"dict\"):\n",
    "            return obj.dict()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            return obj.__dict__\n",
    "        return str(obj)\n",
    "\n",
    "def _write_json(path: Path, data):\n",
    "    path.write_text(json.dumps(_json_safe(data), ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "def _write_jsonl(path: Path, rows):\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(_json_safe(r), ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def _df_to_jsonl_rows(df, prefer_cols):\n",
    "    cols = [c for c in prefer_cols if c in df.columns]\n",
    "    if cols:\n",
    "        df = df[cols].copy()\n",
    "    return df.to_dict(orient=\"records\"), cols\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# dataset fingerprint helpers\n",
    "# ----------------------------\n",
    "def _file_sha1(path: Path, chunk_size=1024 * 1024) -> str:\n",
    "    h = hashlib.sha1()\n",
    "    with path.open(\"rb\") as f:\n",
    "        while True:\n",
    "            b = f.read(chunk_size)\n",
    "            if not b:\n",
    "                break\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def _count_jsonl_lines(path: Path) -> int:\n",
    "    n = 0\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                n += 1\n",
    "    return n\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# core: eval + detail/summary frames\n",
    "# ----------------------------\n",
    "def eval_ragas_with_details(samples, run_tag: str):\n",
    "    ds = Dataset.from_list(samples)\n",
    "\n",
    "    t0 = time.time()\n",
    "    res = evaluate(dataset=ds, metrics=METRICS, llm=llm)  # âœ… llmì€ ì—¬ê¸°ë¡œ\n",
    "    eval_sec = time.time() - t0\n",
    "\n",
    "    t1 = time.time()\n",
    "    detail_df = res.to_pandas() if hasattr(res, \"to_pandas\") else pd.DataFrame()\n",
    "    to_pandas_sec = time.time() - t1\n",
    "\n",
    "    samples_df = pd.DataFrame(samples)\n",
    "\n",
    "    # merge\n",
    "    if len(detail_df) == len(samples_df) and len(detail_df) > 0:\n",
    "        out_detail = pd.concat(\n",
    "            [samples_df.reset_index(drop=True), detail_df.reset_index(drop=True)],\n",
    "            axis=1\n",
    "        )\n",
    "    else:\n",
    "        out_detail = samples_df.copy()\n",
    "\n",
    "    out_detail[\"run_tag\"] = run_tag\n",
    "    out_detail[\"eval_seconds\"] = round(eval_sec, 3)\n",
    "    out_detail[\"to_pandas_seconds\"] = round(to_pandas_sec, 3)\n",
    "\n",
    "    # summary\n",
    "    summary = {}\n",
    "    if len(detail_df) > 0:\n",
    "        summary = detail_df.mean(numeric_only=True).to_dict()\n",
    "    elif isinstance(res, dict):\n",
    "        summary = {k: float(v) for k, v in res.items() if isinstance(v, (int, float))}\n",
    "\n",
    "    summary[\"run_tag\"] = run_tag\n",
    "    summary[\"eval_seconds\"] = round(eval_sec, 3)\n",
    "    summary[\"to_pandas_seconds\"] = round(to_pandas_sec, 3)\n",
    "\n",
    "    return res, out_detail, pd.DataFrame([summary])\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# run dir allocator\n",
    "# ----------------------------\n",
    "def _next_run_dir(project_root: Path, prefix: str):\n",
    "    runs_root = Path(project_root) / \"results\" / \"ragas_runs\"\n",
    "    runs_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pat = re.compile(rf\"^{re.escape(prefix)}_(\\d{{4}})_\")\n",
    "    nums = []\n",
    "    for p in runs_root.iterdir():\n",
    "        if p.is_dir():\n",
    "            m = pat.match(p.name)\n",
    "            if m:\n",
    "                nums.append(int(m.group(1)))\n",
    "    next_id = (max(nums) + 1) if nums else 1\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = runs_root / f\"{prefix}_{next_id:04d}_{ts}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=False)\n",
    "    return run_dir, next_id, ts\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# delta builders\n",
    "# ----------------------------\n",
    "def _pick_question_col(df: pd.DataFrame) -> str:\n",
    "    for c in [\"question\", \"normalized_question\", \"normalized_query\", \"query\"]:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return \"\"\n",
    "\n",
    "def _ensure_question_id(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # prefer an existing stable id\n",
    "    for c in [\"question_id\", \"id\", \"sample_id\"]:\n",
    "        if c in df.columns:\n",
    "            df = df.copy()\n",
    "            df[\"__qid__\"] = df[c].astype(str)\n",
    "            return df\n",
    "    # fallback: hash question text\n",
    "    qcol = _pick_question_col(df)\n",
    "    df = df.copy()\n",
    "    if qcol:\n",
    "        def _h(x: str) -> str:\n",
    "            s = (x or \"\").strip().encode(\"utf-8\")\n",
    "            return hashlib.sha1(s).hexdigest()[:12]\n",
    "        df[\"__qid__\"] = df[qcol].astype(str).map(_h)\n",
    "    else:\n",
    "        df[\"__qid__\"] = [f\"row{i:04d}\" for i in range(len(df))]\n",
    "    return df\n",
    "\n",
    "def _metric_cols(df: pd.DataFrame) -> list:\n",
    "    # heuristic: numeric columns from ragas result + common metric names\n",
    "    prefer = [\n",
    "        \"context_precision\", \"context_recall\", \"faithfulness\", \"answer_relevancy\",\n",
    "        \"ContextPrecision\", \"ContextRecall\", \"Faithfulness\", \"AnswerRelevancy\",\n",
    "    ]\n",
    "    cols = [c for c in prefer if c in df.columns]\n",
    "    if cols:\n",
    "        return cols\n",
    "\n",
    "    # fallback: any numeric columns that are not obvious non-metrics\n",
    "    exclude = set([\"eval_seconds\", \"to_pandas_seconds\"])\n",
    "    num_cols = []\n",
    "    for c in df.columns:\n",
    "        if c in exclude:\n",
    "            continue\n",
    "        if pd.api.types.is_numeric_dtype(df[c]):\n",
    "            num_cols.append(c)\n",
    "    return num_cols\n",
    "\n",
    "\n",
    "def _make_delta_summary(summary_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # summary_df has rows: baseline/experiment\n",
    "    metric_cols = [c for c in summary_df.columns if c not in [\"run_tag\"]]\n",
    "    base = summary_df[summary_df[\"run_tag\"] == \"baseline\"].iloc[0].to_dict()\n",
    "    exp  = summary_df[summary_df[\"run_tag\"] == \"experiment\"].iloc[0].to_dict()\n",
    "\n",
    "    rows = []\n",
    "    for c in metric_cols:\n",
    "        if c == \"run_tag\":\n",
    "            continue\n",
    "        b = base.get(c)\n",
    "        e = exp.get(c)\n",
    "        if isinstance(b, (int, float)) and isinstance(e, (int, float)):\n",
    "            rows.append({\"metric\": c, \"baseline\": float(b), \"experiment\": float(e), \"delta\": float(e - b)})\n",
    "        else:\n",
    "            # keep non-numeric too\n",
    "            rows.append({\"metric\": c, \"baseline\": b, \"experiment\": e, \"delta\": None})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def _make_delta_detail(detail_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = _ensure_question_id(detail_df)\n",
    "\n",
    "    base = df[df[\"run_tag\"] == \"baseline\"].copy()\n",
    "    exp  = df[df[\"run_tag\"] == \"experiment\"].copy()\n",
    "\n",
    "    # --- choose question column ---\n",
    "    qcol = _pick_question_col(df)\n",
    "\n",
    "    # --- metric columns ---\n",
    "    mcols = _metric_cols(df)\n",
    "\n",
    "    # --- info columns to keep (these overlap across base/exp) ---\n",
    "    info_cols = [\"__qid__\"]\n",
    "    if qcol:\n",
    "        info_cols.append(qcol)\n",
    "    for c in [\"ground_truth\", \"reference\", \"answer\", \"contexts\"]:\n",
    "        if c in df.columns:\n",
    "            info_cols.append(c)\n",
    "\n",
    "    # --- select + rename (so no overlap) ---\n",
    "    base_small = base[info_cols + mcols].copy()\n",
    "    exp_small  = exp[info_cols + mcols].copy()\n",
    "\n",
    "    rename_base = {c: f\"{c}_base\" for c in info_cols if c != \"__qid__\"}\n",
    "    rename_exp  = {c: f\"{c}_exp\"  for c in info_cols if c != \"__qid__\"}\n",
    "    rename_base.update({c: f\"{c}_base\" for c in mcols})\n",
    "    rename_exp.update({c: f\"{c}_exp\"  for c in mcols})\n",
    "\n",
    "    base_small = base_small.rename(columns=rename_base)\n",
    "    exp_small  = exp_small.rename(columns=rename_exp)\n",
    "\n",
    "    # --- merge safely ---\n",
    "    merged = exp_small.merge(base_small, on=\"__qid__\", how=\"outer\")\n",
    "\n",
    "    # --- compute deltas ---\n",
    "    for c in mcols:\n",
    "        cb = f\"{c}_base\"\n",
    "        ce = f\"{c}_exp\"\n",
    "        if cb in merged.columns and ce in merged.columns:\n",
    "            merged[f\"{c}_delta\"] = merged[ce] - merged[cb]\n",
    "\n",
    "    # --- convenience: make a unified question column (prefer exp, fallback base) ---\n",
    "    if qcol:\n",
    "        qe = f\"{qcol}_exp\"\n",
    "        qb = f\"{qcol}_base\"\n",
    "        if qe in merged.columns or qb in merged.columns:\n",
    "            merged[qcol] = None\n",
    "            if qe in merged.columns:\n",
    "                merged[qcol] = merged[qe]\n",
    "            if qb in merged.columns:\n",
    "                merged[qcol] = merged[qcol].fillna(merged[qb])\n",
    "\n",
    "    # --- order columns nicely ---\n",
    "    ordered = [\"__qid__\"]\n",
    "    if qcol and qcol in merged.columns:\n",
    "        ordered.append(qcol)\n",
    "\n",
    "    # keep references (unified view is optional; we keep exp/base separately)\n",
    "    for c in [\"ground_truth\", \"reference\"]:\n",
    "        # add unified if you want; here we keep exp/base columns only\n",
    "        pass\n",
    "\n",
    "    # metrics grouped\n",
    "    for c in mcols:\n",
    "        for suf in [\"_base\", \"_exp\", \"_delta\"]:\n",
    "            col = f\"{c}{suf}\"\n",
    "            if col in merged.columns:\n",
    "                ordered.append(col)\n",
    "\n",
    "    # then common info columns (exp/base)\n",
    "    tail_info = []\n",
    "    for c in [\"ground_truth\", \"reference\", \"answer\", \"contexts\"]:\n",
    "        ce, cb = f\"{c}_exp\", f\"{c}_base\"\n",
    "        if ce in merged.columns:\n",
    "            tail_info.append(ce)\n",
    "        if cb in merged.columns:\n",
    "            tail_info.append(cb)\n",
    "\n",
    "    remaining = [c for c in merged.columns if c not in ordered and c not in tail_info]\n",
    "    return merged[ordered + remaining + tail_info].copy()\n",
    "\n",
    "\n",
    "\n",
    "def _make_top_changes(delta_detail_df: pd.DataFrame, top_k=10) -> tuple[pd.DataFrame, pd.DataFrame, str]:\n",
    "    # choose primary metric for sorting\n",
    "    candidates = [\n",
    "        \"answer_relevancy_delta\", \"AnswerRelevancy_delta\",\n",
    "        \"faithfulness_delta\", \"Faithfulness_delta\",\n",
    "        \"context_precision_delta\", \"ContextPrecision_delta\",\n",
    "        \"context_recall_delta\", \"ContextRecall_delta\",\n",
    "    ]\n",
    "    sort_col = next((c for c in candidates if c in delta_detail_df.columns), None)\n",
    "    if sort_col is None:\n",
    "        # fallback: first *_delta numeric column\n",
    "        delta_cols = [c for c in delta_detail_df.columns if c.endswith(\"_delta\") and pd.api.types.is_numeric_dtype(delta_detail_df[c])]\n",
    "        sort_col = delta_cols[0] if delta_cols else \"\"\n",
    "\n",
    "    if not sort_col:\n",
    "        # nothing to rank\n",
    "        return pd.DataFrame(), pd.DataFrame(), \"\"\n",
    "\n",
    "    # pick minimal view columns\n",
    "    qcol = _pick_question_col(delta_detail_df)\n",
    "    view_cols = [c for c in [\"__qid__\", qcol, sort_col] if c and c in delta_detail_df.columns]\n",
    "    # add also base/exp of that metric if present\n",
    "    base_col = sort_col.replace(\"_delta\", \"_base\")\n",
    "    exp_col  = sort_col.replace(\"_delta\", \"_exp\")\n",
    "    for c in [base_col, exp_col]:\n",
    "        if c in delta_detail_df.columns and c not in view_cols:\n",
    "            view_cols.append(c)\n",
    "\n",
    "    regress = delta_detail_df.sort_values(sort_col, ascending=True).head(top_k)[view_cols].copy()\n",
    "    improve = delta_detail_df.sort_values(sort_col, ascending=False).head(top_k)[view_cols].copy()\n",
    "    return regress, improve, sort_col\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# main: compare + save (csv/json + optional snapshots)\n",
    "# ----------------------------\n",
    "def run_compare_and_save_all(\n",
    "    base_samples,\n",
    "    exp_samples,\n",
    "    project_root: Path,\n",
    "    prefix=\"ragas_compare\",\n",
    "    save_snapshots=True,\n",
    "    save_config=True,\n",
    "    save_samples_jsonl=True,\n",
    "    save_trace_jsonl=True,\n",
    "    trace_cols_priority=None,\n",
    "    save_delta_outputs=True,\n",
    "    top_k=10,\n",
    "):\n",
    "    # 1) evaluate\n",
    "    base_res, base_detail_df, base_summary_df = eval_ragas_with_details(base_samples, \"baseline\")\n",
    "    exp_res,  exp_detail_df,  exp_summary_df  = eval_ragas_with_details(exp_samples,  \"experiment\")\n",
    "\n",
    "    summary_df = pd.concat([base_summary_df, exp_summary_df], ignore_index=True)\n",
    "    detail_df  = pd.concat([base_detail_df,  exp_detail_df],  ignore_index=True)\n",
    "\n",
    "    # 2) run dir\n",
    "    run_dir, run_id, ts = _next_run_dir(project_root, prefix)\n",
    "\n",
    "    # 3) basic outputs\n",
    "    out_summary = run_dir / \"summary.csv\"\n",
    "    out_detail  = run_dir / \"detail.csv\"\n",
    "    out_meta    = run_dir / \"meta.json\"\n",
    "\n",
    "    summary_df.to_csv(out_summary, index=False, encoding=\"utf-8-sig\")\n",
    "    detail_df.to_csv(out_detail, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # --- dataset fingerprint (optional) ---\n",
    "    testset_info = None\n",
    "    if \"TESTSET_JSONL\" in globals():\n",
    "        p = Path(globals()[\"TESTSET_JSONL\"])\n",
    "        if p.exists():\n",
    "            testset_info = {\n",
    "                \"testset_path\": str(p),\n",
    "                \"testset_lines\": _count_jsonl_lines(p),\n",
    "                \"testset_sha1\": _file_sha1(p),\n",
    "            }\n",
    "\n",
    "    meta = {\n",
    "        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"run_id\": run_id,\n",
    "        \"timestamp\": ts,\n",
    "        \"run_dir\": str(run_dir),\n",
    "        \"prefix\": prefix,\n",
    "        \"n_base_samples\": len(base_samples),\n",
    "        \"n_exp_samples\": len(exp_samples),\n",
    "        \"metrics\": [getattr(m, \"__name__\", m.__class__.__name__) for m in METRICS],\n",
    "        \"llm\": {\"model\": \"gpt-4o-mini\"},\n",
    "        \"testset\": testset_info,\n",
    "    }\n",
    "    _write_json(out_meta, meta)\n",
    "\n",
    "    # 3-1) DELTA outputs (â­ï¸ NEW)\n",
    "    extra = {}\n",
    "    if save_delta_outputs:\n",
    "        # delta_summary\n",
    "        delta_summary_df = _make_delta_summary(summary_df)\n",
    "        out_delta_summary = run_dir / \"delta_summary.csv\"\n",
    "        delta_summary_df.to_csv(out_delta_summary, index=False, encoding=\"utf-8-sig\")\n",
    "        extra[\"out_delta_summary\"] = str(out_delta_summary)\n",
    "\n",
    "        # delta_detail\n",
    "        delta_detail_df = _make_delta_detail(detail_df)\n",
    "        out_delta_detail = run_dir / \"delta_detail.csv\"\n",
    "        delta_detail_df.to_csv(out_delta_detail, index=False, encoding=\"utf-8-sig\")\n",
    "        extra[\"out_delta_detail\"] = str(out_delta_detail)\n",
    "\n",
    "        # top changes (regressions/improvements)\n",
    "        top_regress, top_improve, sort_col = _make_top_changes(delta_detail_df, top_k=top_k)\n",
    "        out_top_regress = run_dir / \"top_regressions.csv\"\n",
    "        out_top_improve = run_dir / \"top_improvements.csv\"\n",
    "        top_regress.to_csv(out_top_regress, index=False, encoding=\"utf-8-sig\")\n",
    "        top_improve.to_csv(out_top_improve, index=False, encoding=\"utf-8-sig\")\n",
    "        extra[\"out_top_regressions\"] = str(out_top_regress)\n",
    "        extra[\"out_top_improvements\"] = str(out_top_improve)\n",
    "        extra[\"top_rank_metric\"] = sort_col\n",
    "\n",
    "    # 4) optional snapshots\n",
    "    if save_snapshots:\n",
    "        # 4-1) config.json\n",
    "        if save_config:\n",
    "            cfg_payload = {\n",
    "                \"created_at\": datetime.now().isoformat(),\n",
    "                \"llm\": {\"model\": \"gpt-4o-mini\"},\n",
    "                \"metrics\": [getattr(m, \"__name__\", m.__class__.__name__) for m in METRICS],\n",
    "                \"base_cfg\": _json_safe(globals().get(\"base_cfg\")) if \"base_cfg\" in globals() else None,\n",
    "                \"exp_cfg\":  _json_safe(globals().get(\"exp_cfg\"))  if \"exp_cfg\"  in globals() else None,\n",
    "            }\n",
    "            out_config = run_dir / \"config.json\"\n",
    "            _write_json(out_config, cfg_payload)\n",
    "            extra[\"out_config\"] = str(out_config)\n",
    "\n",
    "        # 4-2) input samples jsonl\n",
    "        if save_samples_jsonl:\n",
    "            out_samples_base = run_dir / \"samples_base.jsonl\"\n",
    "            out_samples_exp  = run_dir / \"samples_exp.jsonl\"\n",
    "            _write_jsonl(out_samples_base, base_samples)\n",
    "            _write_jsonl(out_samples_exp,  exp_samples)\n",
    "            extra[\"out_samples_base\"] = str(out_samples_base)\n",
    "            extra[\"out_samples_exp\"]  = str(out_samples_exp)\n",
    "\n",
    "        # 4-3) trace jsonl (from detail_df)\n",
    "        if save_trace_jsonl:\n",
    "            if trace_cols_priority is None:\n",
    "                trace_cols_priority = [\n",
    "                    \"id\", \"sample_id\", \"__qid__\",\n",
    "                    \"question\", \"normalized_question\", \"normalized_query\", \"query\",\n",
    "                    \"answer\", \"ground_truth\", \"reference\",\n",
    "                    \"contexts\",\n",
    "                    \"_trace\",\n",
    "                    \"retrieved_doc_ids\", \"retrieved_docs\", \"retrieval_scores\",\n",
    "                    \"rerank_selected_ids\", \"rerank_scores\",\n",
    "                    \"final_context_ids\", \"final_contexts\",\n",
    "                    \"latency_ms\", \"latency_sec\",\n",
    "                    \"run_tag\",\n",
    "                ]\n",
    "            trace_rows, used_cols = _df_to_jsonl_rows(detail_df, trace_cols_priority)\n",
    "            out_trace = run_dir / \"trace.jsonl\"\n",
    "            _write_jsonl(out_trace, trace_rows)\n",
    "            extra[\"out_trace\"] = str(out_trace)\n",
    "            extra[\"trace_cols_used\"] = used_cols\n",
    "\n",
    "    return {\n",
    "        \"base_res\": base_res,\n",
    "        \"exp_res\": exp_res,\n",
    "        \"summary_df\": summary_df,\n",
    "        \"detail_df\": detail_df,\n",
    "        \"run_dir\": str(run_dir),\n",
    "        \"out_summary\": str(out_summary),\n",
    "        \"out_detail\": str(out_detail),\n",
    "        \"out_meta\": str(out_meta),\n",
    "        **extra,\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# RUN\n",
    "# ----------------------------\n",
    "result = run_compare_and_save_all(\n",
    "    base_samples=BASE_SAMPLES,\n",
    "    exp_samples=EXP_SAMPLES,\n",
    "    project_root=PROJECT_ROOT,\n",
    "    prefix=\"ragas_compare\",\n",
    "    save_snapshots=True,\n",
    "    save_config=True,\n",
    "    save_samples_jsonl=True,\n",
    "    save_trace_jsonl=True,\n",
    "    save_delta_outputs=True,  # âœ… NEW\n",
    "    top_k=10,                 # âœ… NEW\n",
    ")\n",
    "\n",
    "print(\"âœ… run_dir:\", result[\"run_dir\"])\n",
    "print(\"âœ… saved:\", result[\"out_summary\"], result[\"out_detail\"], result[\"out_meta\"])\n",
    "\n",
    "# NEW delta outputs\n",
    "if \"out_delta_summary\" in result:\n",
    "    print(\"âœ… delta saved:\", result[\"out_delta_summary\"], result.get(\"out_delta_detail\"))\n",
    "    print(\"âœ… top changes metric:\", result.get(\"top_rank_metric\"))\n",
    "    print(\"âœ… top regressions:\", result.get(\"out_top_regressions\"))\n",
    "    print(\"âœ… top improvements:\", result.get(\"out_top_improvements\"))\n",
    "\n",
    "# snapshots\n",
    "if \"out_config\" in result:\n",
    "    print(\"âœ… extra saved config :\", result[\"out_config\"])\n",
    "if \"out_samples_base\" in result:\n",
    "    print(\"âœ… extra saved samples:\", result[\"out_samples_base\"], \"and\", result.get(\"out_samples_exp\"))\n",
    "if \"out_trace\" in result:\n",
    "    print(\"âœ… extra saved trace  :\", result[\"out_trace\"])\n",
    "    print(\"âœ… trace columns used :\", result.get(\"trace_cols_used\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6845ece-5d8b-47af-8aaf-0a1dc5ef87c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa7f586-c190-4912-a1c7-b08b1f1703db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0e570-c6a8-44d7-8628-8f2fb44c5755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df58dc-5dbf-4542-945f-0cf156a581dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ccdd3-e88b-4212-b6a2-fe100c7f1cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860dd3a7-6a46-4477-84a4-ef2861fe6829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c068515-0f85-4ef4-84dd-c22ad87302dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e96bfa9-487a-49b6-b4b1-df555cf06ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3be758-526b-4c43-a796-c5036f476881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5335ed-f34b-4677-950b-bd10cb6a0cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c55f40-ddfa-4a3a-a7dc-abd143d6eda4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97946b48-b0d8-4dd8-9a89-f6a451d7e36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d03785-23ae-4846-9368-4a45eaf6d3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab5d29-e922-4a2c-a0c0-fcb337ae36ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv chatbot_app)",
   "language": "python",
   "name": "chatbot-app-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
