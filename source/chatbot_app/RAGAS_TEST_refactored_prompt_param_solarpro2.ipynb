{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4decb793",
   "metadata": {},
   "source": [
    "# RAGAS Evaluation Notebook (Clean)\n",
    "\n",
    "This notebook evaluates **baseline vs experiment** RAG pipelines using RAGAS and saves **summary/detail** outputs per run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5272651f",
   "metadata": {},
   "source": [
    "## ğŸ”§ ìˆ˜ì • í¬ì¸íŠ¸(ê°€ì¥ ìì£¼ ë°”ê¾¸ëŠ” ê³³)\n",
    "\n",
    "1) **SYSTEM_PROMPT_BASE / SYSTEM_PROMPT_EXP** (í”„ë¡¬í”„íŠ¸ ë¹„êµ)\n",
    "2) **base_cfg / exp_cfg** (íŒŒë¼ë¯¸í„° ë¹„êµ)\n",
    "\n",
    "ì´ ë‘ êµ°ë°ë§Œ ë°”ê¾¸ê³  ì•„ë˜ ì‹¤í–‰ ì…€ë“¤ì„ ëŒë¦¬ë©´, ê°™ì€ í…ŒìŠ¤íŠ¸ì…‹ìœ¼ë¡œ BASE vs EXPê°€ ìë™ ë¹„êµë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf76203-b1ff-4ee3-b17e-06004982adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdaa3541-ee50-497b-81cd-91c2274ba4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1b5f49e-4fde-42f4-a42a-40dd814c571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys, subprocess, textwrap\n",
    "\n",
    "# def sh(cmd):\n",
    "#     print(\">\", cmd)\n",
    "#     r = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "#     print(r.stdout)\n",
    "#     if r.stderr.strip():\n",
    "#         print(\"[stderr]\")\n",
    "#         print(r.stderr)\n",
    "\n",
    "# print(\"python:\", sys.executable)\n",
    "# print(\"version:\", sys.version)\n",
    "\n",
    "# # í˜„ì¬ íŒ¨í‚¤ì§€ ìƒíƒœ í™•ì¸\n",
    "# sh(\"python -c \\\"import numpy; print('numpy', numpy.__version__)\\\"\")\n",
    "# sh(\"python -c \\\"import pyarrow; print('pyarrow', pyarrow.__version__)\\\"\")\n",
    "# sh(\"python -c \\\"import datasets; print('datasets', datasets.__version__)\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b2f1ee4-078f-4f37-9e75-6da6b135d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys, subprocess\n",
    "\n",
    "# def pip(cmd):\n",
    "#     print(\">\", cmd)\n",
    "#     r = subprocess.run([sys.executable, \"-m\", \"pip\"] + cmd.split(), capture_output=True, text=True)\n",
    "#     print(r.stdout)\n",
    "#     if r.stderr.strip():\n",
    "#         print(\"[stderr]\")\n",
    "#         print(r.stderr)\n",
    "\n",
    "# # 1) ì œê±°\n",
    "# pip(\"uninstall -y pyarrow datasets numpy\")\n",
    "\n",
    "# # 2) ì¬ì„¤ì¹˜: numpy<2 + ìµœì‹  pyarrow + datasets(ë„ˆê°€ ì“°ë˜ ë²„ì „)\n",
    "# pip(\"install numpy<2 pyarrow>=14 datasets==2.19.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f6d4dab-9416-4c6e-b037-2526c17623ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… METRICS: ['ContextPrecision', 'ContextRecall', 'Faithfulness']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7124\\1708373533.py:6: DeprecationWarning: Importing context_precision from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_precision\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7124\\1708373533.py:6: DeprecationWarning: Importing context_recall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_recall\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7124\\1708373533.py:6: DeprecationWarning: Importing faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import faithfulness\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n"
     ]
    }
   ],
   "source": [
    "# ---- RAGAS metrics: version-tolerant loader ----\n",
    "def build_metrics():\n",
    "    # Aì•ˆ: embeddings ì˜ì¡´ ê°€ëŠ¥ì„±ì´ í° AnswerRelevancyëŠ” ë¹¼ê³  \"ì™„ì£¼\"ë¶€í„°\n",
    "    # 1) í•¨ìˆ˜í˜• metric\n",
    "    try:\n",
    "        from ragas.metrics import context_precision, context_recall, faithfulness\n",
    "        return [context_precision, context_recall, faithfulness]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) í´ë˜ìŠ¤í˜• metric\n",
    "    try:\n",
    "        from ragas.metrics import ContextPrecision, ContextRecall, Faithfulness\n",
    "        return [ContextPrecision(), ContextRecall(), Faithfulness()]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 3) fallback íƒìƒ‰\n",
    "    import ragas.metrics as m\n",
    "    wanted = [\"ContextPrecision\", \"ContextRecall\", \"Faithfulness\"]\n",
    "    found = []\n",
    "    for name in wanted:\n",
    "        if hasattr(m, name):\n",
    "            found.append(getattr(m, name)())\n",
    "    if found:\n",
    "        return found\n",
    "\n",
    "    raise ImportError(\n",
    "        \"RAGAS metrics import failed for A-plan (without AnswerRelevancy). \"\n",
    "        \"Paste `pip show ragas` and `python -c \\\"import ragas; print(ragas.__version__)\\\"`.\"\n",
    "    )\n",
    "\n",
    "METRICS = build_metrics()\n",
    "print(\"âœ… METRICS:\", [getattr(x, '__name__', x.__class__.__name__) for x in METRICS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24085385-5708-4be6-8d18-1c17f11f456d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ragas version: 0.4.3\n"
     ]
    }
   ],
   "source": [
    "import ragas\n",
    "print(\"ragas version:\", getattr(ragas, \"__version__\", \"unknown\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85cba8ec-b4a6-4dcf-8fda-13b78e62e686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… METRICS: ['ContextPrecision', 'ContextRecall', 'Faithfulness', 'AnswerRelevancy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7124\\3044559028.py:1: DeprecationWarning: Importing context_precision from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_precision\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness, answer_relevancy\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7124\\3044559028.py:1: DeprecationWarning: Importing context_recall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_recall\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness, answer_relevancy\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7124\\3044559028.py:1: DeprecationWarning: Importing faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import faithfulness\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness, answer_relevancy\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7124\\3044559028.py:1: DeprecationWarning: Importing answer_relevancy from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import answer_relevancy\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness, answer_relevancy\n"
     ]
    }
   ],
   "source": [
    "from ragas.metrics import context_precision, context_recall, faithfulness, answer_relevancy\n",
    "\n",
    "METRICS = [context_precision, context_recall, faithfulness, answer_relevancy]\n",
    "print(\"âœ… METRICS:\", [getattr(m, \"__name__\", m.__class__.__name__) for m in METRICS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac8615-1f58-462f-8f2e-811d673d8d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22cee99-4aaa-40fb-bbbb-451aa89c8c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53db9df-4693-41e1-b255-bebb90c4be53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "663e3c80",
   "metadata": {},
   "source": [
    "## 0) Environment & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3772574e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: C:\\ai\\source\\chatbot_app\n",
      "TESTSET_PATH: C:\\ai\\source\\chatbot_app\\ragas_testset_10_selected.jsonl\n",
      "exists: True\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PATH CONFIG (only this cell is modified)\n",
    "# ============================================================\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys, importlib\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# âœ… í”„ë¡œì íŠ¸ ë£¨íŠ¸ (ìƒˆ ê²½ë¡œ)\n",
    "PROJECT_ROOT = Path(r\"C:\\ai\\source\\chatbot_app\")\n",
    "\n",
    "# âœ… ëª¨ë“ˆ ê²½ë¡œ (ì›ë˜ ì“°ë˜ êµ¬ì¡° ê·¸ëŒ€ë¡œ)\n",
    "MODULE_DIR = PROJECT_ROOT / \"modules\"\n",
    "\n",
    "# âœ… í™˜ê²½ë³€ìˆ˜\n",
    "ENV_PATH = PROJECT_ROOT / \".env\"\n",
    "\n",
    "# âœ… ê²°ê³¼ ì €ì¥ ë£¨íŠ¸\n",
    "RUNS_DIR = PROJECT_ROOT / \"results\" / \"ragas_runs\"\n",
    "\n",
    "# â­•ï¸ ì—¬ê¸°ì„œ ì–´ë–¤ í…ŒìŠ¤íŠ¸ì…‹ ì“¸ì§€ ë„¤ê°€ ì§ì ‘ ì„ íƒ\n",
    "# TESTSET_PATH = PROJECT_ROOT / \"ragas_testset_single.jsonl\"\n",
    "# TESTSET_PATH = PROJECT_ROOT / \"ragas_testset_v1_from_docx.jsonl\"\n",
    "TESTSET_PATH = PROJECT_ROOT / \"ragas_testset_10_selected.jsonl\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# setup\n",
    "# ------------------------------------------------------------\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "sys.path.insert(0, str(MODULE_DIR))\n",
    "importlib.invalidate_caches()\n",
    "\n",
    "if ENV_PATH.exists():\n",
    "    load_dotenv(ENV_PATH)\n",
    "\n",
    "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"TESTSET_PATH:\", TESTSET_PATH)\n",
    "print(\"exists:\", TESTSET_PATH.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc0093e",
   "metadata": {},
   "source": [
    "## 1) Load testset (JSONL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8108580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… rows: 10\n",
      "âœ… keys example: dict_keys(['question_id', 'question', 'ground_truth', 'contexts', 'meta'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>contexts</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q010</td>\n",
       "      <td>ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì§‘ì£¼ì¸ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?</td>\n",
       "      <td>ë„¤, ê°•ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ27ì¡°ì— ë”°ë¥´ë©´,\\n ì œ26ì¡°ì œ4í•­ ...</td>\n",
       "      <td>[ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ27ì¡° ì œ1í•­, ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì‹œí–‰ë ¹ ì œ34ì¡°, ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸...</td>\n",
       "      <td>{'source': 'RAGAS í•™ìŠµìš© ì§ˆë¬¸.docx', 'version': 'v1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q016</td>\n",
       "      <td>ì„ëŒ€ì¸ì´ ë³´ì¦ê¸ˆì„ ì•ˆ ëŒë ¤ì¤˜ì„œ ì œê°€ ì¼ë¶€ëŸ¬ ì „ì…ì‹ ê³ ë¥¼ ìœ ì§€í•˜ê³  ìˆëŠ”ë°, ë‹¤ë¥¸ ì§‘ìœ¼ë¡œ...</td>\n",
       "      <td>ë‹¤ë¥¸ ì§‘ìœ¼ë¡œ ì „ì…ì‹ ê³ ë¥¼ í•˜ë©´,\\n ê¸°ì¡´ ì£¼íƒì— ëŒ€í•œ ëŒ€í•­ë ¥ì„ ìƒì‹¤í•˜ê²Œ ë˜ì–´ ì„ì°¨ì¸ìœ¼...</td>\n",
       "      <td>[ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ3ì¡° ì œ1í•­]</td>\n",
       "      <td>{'source': 'RAGAS í•™ìŠµìš© ì§ˆë¬¸.docx', 'version': 'v1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q002</td>\n",
       "      <td>ê³„ì•½ì„œì— 1ë…„ì´ë¼ê³  ì¨ ìˆìœ¼ë©´, 1ë…„ ì§€ë‚˜ë©´ ë¬´ì¡°ê±´ ë‚˜ê°€ì•¼ í•˜ë‚˜ìš”?</td>\n",
       "      <td>ì•„ë‹ˆìš”. ê³„ì•½ì„œì— 1ë…„ì´ë¼ê³  ì í˜€ ìˆì–´ë„, 1ë…„ì´ ì§€ë‚˜ë©´ ë¬´ì¡°ê±´ ë‚˜ê°€ì•¼ í•˜ëŠ” ê²ƒì€ ...</td>\n",
       "      <td>[ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ4ì¡° ì œ1í•­]</td>\n",
       "      <td>{'source': 'RAGAS í•™ìŠµìš© ì§ˆë¬¸.docx', 'version': 'v1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question_id                                           question  \\\n",
       "0        q010               ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì§‘ì£¼ì¸ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?   \n",
       "1        q016  ì„ëŒ€ì¸ì´ ë³´ì¦ê¸ˆì„ ì•ˆ ëŒë ¤ì¤˜ì„œ ì œê°€ ì¼ë¶€ëŸ¬ ì „ì…ì‹ ê³ ë¥¼ ìœ ì§€í•˜ê³  ìˆëŠ”ë°, ë‹¤ë¥¸ ì§‘ìœ¼ë¡œ...   \n",
       "2        q002              ê³„ì•½ì„œì— 1ë…„ì´ë¼ê³  ì¨ ìˆìœ¼ë©´, 1ë…„ ì§€ë‚˜ë©´ ë¬´ì¡°ê±´ ë‚˜ê°€ì•¼ í•˜ë‚˜ìš”?   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  ë„¤, ê°•ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ27ì¡°ì— ë”°ë¥´ë©´,\\n ì œ26ì¡°ì œ4í•­ ...   \n",
       "1  ë‹¤ë¥¸ ì§‘ìœ¼ë¡œ ì „ì…ì‹ ê³ ë¥¼ í•˜ë©´,\\n ê¸°ì¡´ ì£¼íƒì— ëŒ€í•œ ëŒ€í•­ë ¥ì„ ìƒì‹¤í•˜ê²Œ ë˜ì–´ ì„ì°¨ì¸ìœ¼...   \n",
       "2  ì•„ë‹ˆìš”. ê³„ì•½ì„œì— 1ë…„ì´ë¼ê³  ì í˜€ ìˆì–´ë„, 1ë…„ì´ ì§€ë‚˜ë©´ ë¬´ì¡°ê±´ ë‚˜ê°€ì•¼ í•˜ëŠ” ê²ƒì€ ...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ27ì¡° ì œ1í•­, ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì‹œí–‰ë ¹ ì œ34ì¡°, ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸...   \n",
       "1                                 [ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ3ì¡° ì œ1í•­]   \n",
       "2                                 [ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ4ì¡° ì œ1í•­]   \n",
       "\n",
       "                                                meta  \n",
       "0  {'source': 'RAGAS í•™ìŠµìš© ì§ˆë¬¸.docx', 'version': 'v1...  \n",
       "1  {'source': 'RAGAS í•™ìŠµìš© ì§ˆë¬¸.docx', 'version': 'v1...  \n",
       "2  {'source': 'RAGAS í•™ìŠµìš© ì§ˆë¬¸.docx', 'version': 'v1...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TESTSET_JSONL = PROJECT_ROOT / \"ragas_testset_10_selected.jsonl\"  # change if needed\n",
    "assert TESTSET_JSONL.exists(), f\"âŒ JSONL not found: {TESTSET_JSONL}\"\n",
    "\n",
    "rows = []\n",
    "with open(TESTSET_JSONL, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        rows.append(json.loads(line))\n",
    "\n",
    "print(\"âœ… rows:\", len(rows))\n",
    "print(\"âœ… keys example:\", rows[0].keys())\n",
    "pd.DataFrame(rows[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347b7dac-4985-472c-a539-581bb0105eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fd5607-f5ef-4c8c-a324-21e45c1831e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec1529b4",
   "metadata": {},
   "source": [
    "## 2) Define baseline & experiment configs\n",
    "\n",
    "- Keep **base_cfg** stable.\n",
    "- Only put **changed knobs** in `exp_cfg = replace(base_cfg, ...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69c6ca41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RAGConfig(normalize_model='solar-pro2', generation_model='solar-pro2', temperature=0.1, normalize_temperature=0.0, embedding_backend='upstage', embedding_model='solar-embedding-1-large-passage', k_law=7, k_rule=7, k_case=3, search_multiplier=4, enable_bm25=True, sparse_mode='auto', sparse_k_law=None, sparse_k_rule=None, sparse_k_case=None, bm25_algorithm='okapi', bm25_k1=1.5, bm25_b=0.85, bm25_use_kiwi=True, bm25_max_doc_chars=3000, enable_bm25_title=True, bm25_title_field='title', bm25_title_max_chars=512, hybrid_sparse_title_ratio=0.35, hybrid_fusion='rrf', hybrid_dense_weight=0.5, hybrid_sparse_weight=0.5, rrf_k=60, enable_rerank=True, rerank_threshold=0.22, rerank_model='rerank-multilingual-v3.0', rerank_max_documents=18, rerank_doc_max_chars=3000, case_candidate_k=40, case_expand_top_n=None, case_context_top_k=50, dedupe_key_fields=['chunk_id', 'id']),\n",
       " RAGConfig(normalize_model='solar-pro2', generation_model='solar-pro2', temperature=0.1, normalize_temperature=0.0, embedding_backend='upstage', embedding_model='solar-embedding-1-large-passage', k_law=7, k_rule=7, k_case=3, search_multiplier=4, enable_bm25=True, sparse_mode='auto', sparse_k_law=None, sparse_k_rule=None, sparse_k_case=None, bm25_algorithm='okapi', bm25_k1=1.5, bm25_b=0.85, bm25_use_kiwi=True, bm25_max_doc_chars=2200, enable_bm25_title=True, bm25_title_field='title', bm25_title_max_chars=512, hybrid_sparse_title_ratio=0.35, hybrid_fusion='rrf', hybrid_dense_weight=0.5, hybrid_sparse_weight=0.5, rrf_k=60, enable_rerank=True, rerank_threshold=0.26, rerank_model='rerank-multilingual-v3.0', rerank_max_documents=14, rerank_doc_max_chars=2200, case_candidate_k=40, case_expand_top_n=None, case_context_top_k=50, dedupe_key_fields=['chunk_id', 'id']))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import replace\n",
    "from rag_module import RAGConfig\n",
    "\n",
    "# =========================\n",
    "# Base config (edit as needed)\n",
    "# =========================\n",
    "base_cfg = RAGConfig(\n",
    "    # ---- LLM ----\n",
    "    normalize_model=\"solar-pro2\",\n",
    "    generation_model=\"solar-pro2\",\n",
    "    temperature=0.1,\n",
    "    normalize_temperature=0.0,\n",
    "\n",
    "    # ---- Embedding ----\n",
    "    embedding_backend=\"upstage\",\n",
    "    embedding_model=\"solar-embedding-1-large-passage\",\n",
    "\n",
    "    # ---- Dense Retrieval ----\n",
    "    k_law=7,\n",
    "    k_rule=7,\n",
    "    k_case=3,\n",
    "    search_multiplier=4,\n",
    "\n",
    "    # ---- Hybrid Fusion ----\n",
    "    hybrid_dense_weight=0.5,\n",
    "    hybrid_sparse_weight=0.5,\n",
    "\n",
    "    # ---- BM25 / Sparse ----\n",
    "    enable_bm25=True,\n",
    "    sparse_mode=\"auto\",\n",
    "    bm25_algorithm=\"okapi\",\n",
    "    bm25_k1=1.5,\n",
    "    bm25_b=0.85,\n",
    "    bm25_use_kiwi=True,\n",
    "\n",
    "    # ---- BM25-title ----\n",
    "    enable_bm25_title=True,\n",
    "    bm25_title_field=\"title\",\n",
    "    hybrid_sparse_title_ratio=0.35,\n",
    "\n",
    "    # ---- Rerank ----\n",
    "    enable_rerank=True,\n",
    "    rerank_model=\"rerank-multilingual-v3.0\",\n",
    "    rerank_threshold=0.22,\n",
    "    rerank_max_documents=18,\n",
    "\n",
    "    # ---- Output trimming ----\n",
    "    bm25_max_doc_chars=3000,\n",
    "    rerank_doc_max_chars=3000,\n",
    "\n",
    "    # ---- Dedupe ----\n",
    "    dedupe_key_fields=[\"chunk_id\", \"id\"],\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Experiment config (only diffs here)\n",
    "# =========================\n",
    "exp_cfg = replace(\n",
    "    base_cfg,\n",
    "    rerank_threshold=0.26,\n",
    "    rerank_max_documents=14,\n",
    "    bm25_max_doc_chars=2200,\n",
    "    rerank_doc_max_chars=2200,\n",
    ")\n",
    "base_cfg, exp_cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b0bfd",
   "metadata": {},
   "source": [
    "## (ì¶”ê°€) SYSTEM PROMPT ì‹¤í—˜\n",
    "\n",
    "- ì—¬ê¸°ì„œ **í”„ë¡¬í”„íŠ¸ë§Œ** ë°”ê¿”ë„ BASE vs EXP ë¹„êµê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "- íŒŒì´í”„ë¼ì¸ì´ `answer_with_trace(question, system_prompt=...)`ë¥¼ ì§€ì›í•˜ì§€ ì•Šë”ë¼ë„,\n",
    "  ì•„ë˜ `run_pipe_to_samples()`ê°€ ê°€ëŠ¥í•œ ë°©ì‹ìœ¼ë¡œ ìš°íšŒí•´ì„œ ì£¼ì…ì„ ì‹œë„í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27e40aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE prompt chars: 454\n",
      "EXP  prompt chars: 759\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# SYSTEM PROMPT (BASE vs EXP)\n",
    "# =========================\n",
    "SYSTEM_PROMPT_BASE = \"\"\"\n",
    "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì£¼íƒ ì„ëŒ€ì°¨(ì „ì›”ì„¸) ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë²•ë¥ ì •ë³´ AIì…ë‹ˆë‹¤.\n",
    "ì•„ë˜ [ì°¸ê³  ë¬¸ì„œ]ë¥¼ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì§ì ‘ ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "[ìµœìš°ì„  ê·œì¹™]\n",
    "- ì§ˆë¬¸ì— ëŒ€í•œ ê²°ë¡ ì„ ê°€ì¥ ë¨¼ì € ì œì‹œí•˜ì„¸ìš”.\n",
    "- ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ ì—†ëŠ” ë‚´ìš©ì€ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "- ì°¸ê³  ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ë¡ í•˜ê±°ë‚˜ ì¼ë°˜í™”í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "- íŒë‹¨ì´ ì–´ë ¤ìš´ ê²½ìš°, ê·¼ê±° ë¶€ì¡±ì„ ëª…í™•íˆ ë°íˆì„¸ìš”.\n",
    "\n",
    "[ë‹µë³€ í˜•ì‹ â€” ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”]\n",
    "1. ê²°ë¡   \n",
    "   - ì§ˆë¬¸ì— ëŒ€í•´ ê°€ëŠ¥í•œì§€ / ë¶ˆê°€ëŠ¥í•œì§€ / í•´ì•¼ í•˜ëŠ”ì§€ë¥¼\n",
    "     ë‹¨ì •ì ì¸ ë¬¸ì¥ìœ¼ë¡œ ë¨¼ì € ì œì‹œí•˜ì„¸ìš”.\n",
    "\n",
    "2. ì´ìœ   \n",
    "   - ìœ„ ê²°ë¡ ì´ ë‚˜ì˜¤ëŠ” ì´ìœ ë¥¼\n",
    "     ì°¸ê³  ë¬¸ì„œì˜ ë‚´ìš©ì— ê·¼ê±°í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "   - ë¬¸ì„œì˜ ì·¨ì§€Â·ë‚´ìš©ê³¼ ì§ì ‘ ì—°ê²°ë˜ë„ë¡ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "3. í•œê³„ ëª…ì‹œ  \n",
    "   - ì°¸ê³  ë¬¸ì„œë§Œìœ¼ë¡œ íŒë‹¨ì´ ì™„ì „íˆ í™•ì •ë˜ì§€ ì•ŠëŠ” ê²½ìš°,\n",
    "     ê·¸ í•œê³„ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œë§Œ ë°íˆì„¸ìš”.\n",
    "\"\"\".strip()\n",
    "\n",
    "# âœ… EXP í”„ë¡¬í”„íŠ¸ë¥¼ ì—¬ê¸°ì„œë§Œ ìˆ˜ì •í•´ì„œ ë¹„êµ\n",
    "SYSTEM_PROMPT_EXP =\"\"\"\n",
    "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì£¼íƒ ì„ëŒ€ì°¨(ì „ì›”ì„¸) ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë²•ë¥ ì •ë³´ AIì…ë‹ˆë‹¤.\n",
    "ì•„ë˜ [ì°¸ê³  ë¬¸ì„œ]ë¥¼ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì§ì ‘ ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "[ìµœìš°ì„  ê·œì¹™]\n",
    "- ì§ˆë¬¸ì— ëŒ€í•œ ê²°ë¡ ì„ ê°€ì¥ ë¨¼ì € ì œì‹œí•˜ì„¸ìš”.\n",
    "- ì§ˆë¬¸ì— ì—†ëŠ” ìŸì (ì¼ë°˜ë¡ /ë°°ê²½ì„¤ëª…/ì œë„ ì†Œê°œ)ì€ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "- ì°¸ê³  ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ë¡ í•˜ê±°ë‚˜ ì¼ë°˜í™”í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "- íŒë‹¨ì´ ì–´ë ¤ìš´ ê²½ìš°, ê·¼ê±° ë¶€ì¡±ì„ ëª…í™•íˆ ë°íˆì„¸ìš”.\n",
    "\n",
    "[ì§ˆë¬¸-ì •í•©(AnswerRelevancy) ê°•í™” ê·œì¹™]\n",
    "- ë‹µë³€ì€ ë°˜ë“œì‹œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— â€˜ì •ë©´ìœ¼ë¡œâ€™ ëŒ€ì‘í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "- ì§ˆë¬¸ í˜•ì‹ì— ë§ì¶° ê²°ë¡  ë¬¸ì¥ì„ ì‘ì„±í•˜ì„¸ìš”.\n",
    "  - â€œê°€ëŠ¥í•œê°€?â€ â†’ â€œê°€ëŠ¥í•©ë‹ˆë‹¤ / ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤â€\n",
    "  - â€œí•´ì•¼ í•˜ë‚˜?â€ â†’ â€œí•´ì•¼ í•©ë‹ˆë‹¤ / í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤â€\n",
    "  - â€œì–´ë–»ê²Œ í•˜ë‚˜?â€ â†’ â€œAâ†’Bâ†’C ìˆœì„œë¡œ í•˜ì„¸ìš”â€\n",
    "- ì§ˆë¬¸ ìš”ì§€ë¥¼ ë²—ì–´ë‚˜ëŠ” ë¶€ê°€ ì„¤ëª…ì„ ê¸ˆì§€í•©ë‹ˆë‹¤.\n",
    "- (ë‚´ë¶€ ì ê²€) ì‘ì„± ì „, â€˜ì´ ë‹µì´ ì§ˆë¬¸ì— ì§ì ‘ ë‹µí•˜ëŠ”ê°€?â€™ë¥¼ 1íšŒ í™•ì¸í•˜ì„¸ìš”.\n",
    "\n",
    "[ë‹µë³€ í˜•ì‹ â€” ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”]\n",
    "1. ê²°ë¡   \n",
    "   - ì§ˆë¬¸ì— ëŒ€í•´ ê°€ëŠ¥í•œì§€ / ë¶ˆê°€ëŠ¥í•œì§€ / í•´ì•¼ í•˜ëŠ”ì§€ë¥¼\n",
    "     ë‹¨ì •ì ì¸ ë¬¸ì¥ìœ¼ë¡œ ë¨¼ì € ì œì‹œí•˜ì„¸ìš”.\n",
    "\n",
    "2. ì´ìœ   \n",
    "   - ìœ„ ê²°ë¡ ì´ ë‚˜ì˜¤ëŠ” ì´ìœ ë¥¼\n",
    "     ì°¸ê³  ë¬¸ì„œì˜ ë‚´ìš©ì— ê·¼ê±°í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "   - ë¬¸ì„œì˜ ì·¨ì§€Â·ë‚´ìš©ê³¼ ì§ì ‘ ì—°ê²°ë˜ë„ë¡ ì‘ì„±í•˜ì„¸ìš”.\n",
    "   - í•„ìš”í•œ ê·¼ê±°ë§Œ ìµœì†Œí•œìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "3. í•œê³„ ëª…ì‹œ  \n",
    "   - ì°¸ê³  ë¬¸ì„œë§Œìœ¼ë¡œ íŒë‹¨ì´ ì™„ì „íˆ í™•ì •ë˜ì§€ ì•ŠëŠ” ê²½ìš°,\n",
    "     ê·¸ í•œê³„ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œë§Œ ë°íˆì„¸ìš”.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"BASE prompt chars:\", len(SYSTEM_PROMPT_BASE))\n",
    "print(\"EXP  prompt chars:\", len(SYSTEM_PROMPT_EXP))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fbbb5",
   "metadata": {},
   "source": [
    "## 3) Build pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba0f69f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 17:28:14,941 - rag_module - INFO - ğŸ”— Pinecone 3ì¤‘ ì¸ë±ìŠ¤ ì—°ê²° ì¤‘...\n",
      "2026-02-06 17:28:14,955 - rag_module - INFO - âœ… [Law / Rule / Case] 3ê°œ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ!\n",
      "2026-02-06 17:28:15,594 - rag_module - INFO - âœ… Kiwi í† í¬ë‚˜ì´ì € ì‚¬ìš© (BM25)\n",
      "2026-02-06 17:28:17,738 - rag_module - INFO - ğŸ”— Pinecone 3ì¤‘ ì¸ë±ìŠ¤ ì—°ê²° ì¤‘...\n",
      "2026-02-06 17:28:17,740 - rag_module - INFO - âœ… [Law / Rule / Case] 3ê°œ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ!\n",
      "2026-02-06 17:28:18,389 - rag_module - INFO - âœ… Kiwi í† í¬ë‚˜ì´ì € ì‚¬ìš© (BM25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… pipelines ready\n"
     ]
    }
   ],
   "source": [
    "from rag_module import create_pipeline\n",
    "\n",
    "base_pipe = create_pipeline(config=base_cfg)\n",
    "exp_pipe  = create_pipeline(config=exp_cfg)\n",
    "\n",
    "print(\"âœ… pipelines ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6959059d-0ad1-4770-a338-6be9623871f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8fd6fa-516a-44f7-aa82-3095b2320555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e6dfb91",
   "metadata": {},
   "source": [
    "## 4) (Optional) Quick trace sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85371f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„¹ï¸ Skip or customize depending on your pipeline API.\n"
     ]
    }
   ],
   "source": [
    "# If your rag_module exposes a trace / debug method, call it here.\n",
    "# Otherwise you can skip this cell.\n",
    "\n",
    "# Example (adjust to your actual API):\n",
    "# ans, trace = base_pipe.answer_with_trace(\"í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ...\")\n",
    "# display(trace)\n",
    "\n",
    "print(\"â„¹ï¸ Skip or customize depending on your pipeline API.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16739f05",
   "metadata": {},
   "source": [
    "## 5) Build RAGAS samples from your pipeline outputs\n",
    "\n",
    "This converts each testset row into the RAGAS format:\n",
    "- `question`\n",
    "- `answer`\n",
    "- `contexts` (list[str])\n",
    "- `ground_truth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a8d6173",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 17:28:21,111 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:21,115 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸: ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "\n",
      "â€» [ìš©ì–´ ì‚¬ì „]ì— 'ì¡°ì •'ì´ ëª…ì‹œë˜ì–´ ìˆì§€ ì•Šì•„ ì›ë¬¸ì„ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤. í•„ìš” ì‹œ ì¶”ê°€ ë§¤í•‘ ìš”ì²­ ë°”ëë‹ˆë‹¤.\n",
      "2026-02-06 17:28:21,116 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸: ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "\n",
      "â€» [ìš©ì–´ ì‚¬ì „]ì— 'ì¡°ì •'ì´ ëª…ì‹œë˜ì–´ ìˆì§€ ì•Šì•„ ì›ë¬¸ì„ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤. í•„ìš” ì‹œ ì¶”ê°€ ë§¤í•‘ ìš”ì²­ ë°”ëë‹ˆë‹¤.'\n",
      "2026-02-06 17:28:21,617 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:24,514 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:26,872 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:33,776 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:33,782 - rag_module - INFO - ğŸ“Œ Rerank selected=18 (threshold=0.22)\n",
      "2026-02-06 17:28:33,782 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:28:34,645 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:28:34,648 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:28:35,415 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:35,415 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ë³´ì¦ê¸ˆ)ì„ ë³´ì¦ê¸ˆë¯¸ë°˜í™˜(ì•ˆ ëŒë ¤ì¤˜ì„œ)í•´ì„œ ì œê°€ ì¼ë¶€ëŸ¬ ì£¼ë¯¼ë“±ë¡(ì „ì…ì‹ ê³ )ì„ ìœ ì§€í•˜ê³  ìˆëŠ”ë°, ë‹¤ë¥¸ ì„ì°¨ì£¼íƒ(ë‹¤ë¥¸ ì§‘)ìœ¼ë¡œ ì£¼ë¯¼ë“±ë¡(ì „ì…ì‹ ê³ )ì„ í•˜ë©´ ì œ ì„ì°¨ì¸ ê¶Œë¦¬ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n",
      "2026-02-06 17:28:35,415 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ë³´ì¦ê¸ˆ)ì„ ë³´ì¦ê¸ˆë¯¸ë°˜í™˜(ì•ˆ ëŒë ¤ì¤˜ì„œ)í•´ì„œ ì œê°€ ì¼ë¶€ëŸ¬ ì£¼ë¯¼ë“±ë¡(ì „ì…ì‹ ê³ )ì„ ìœ ì§€í•˜ê³  ìˆëŠ”ë°, ë‹¤ë¥¸ ì„ì°¨ì£¼íƒ(ë‹¤ë¥¸ ì§‘)ìœ¼ë¡œ ì£¼ë¯¼ë“±ë¡(ì „ì…ì‹ ê³ )ì„ í•˜ë©´ ì œ ì„ì°¨ì¸ ê¶Œë¦¬ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?'\n",
      "2026-02-06 17:28:35,905 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:36,815 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:37,992 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:40,615 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:40,615 - rag_module - INFO - ğŸ“Œ Rerank selected=18 (threshold=0.22)\n",
      "2026-02-06 17:28:40,615 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:28:41,523 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:28:41,525 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:28:41,976 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:41,979 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ì–´ ìˆìœ¼ë©´, 1ë…„ ê²½ê³¼í•˜ë©´ ë¬´ì¡°ê±´ ì£¼íƒì˜ì¸ë„ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”?\n",
      "2026-02-06 17:28:41,980 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ì–´ ìˆìœ¼ë©´, 1ë…„ ê²½ê³¼í•˜ë©´ ë¬´ì¡°ê±´ ì£¼íƒì˜ì¸ë„ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”?'\n",
      "2026-02-06 17:28:42,433 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:43,199 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:43,948 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:46,939 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:46,946 - rag_module - INFO - ğŸ“Œ Rerank selected=2 (threshold=0.22)\n",
      "2026-02-06 17:28:46,947 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:28:47,735 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:28:47,737 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:28:48,477 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:48,480 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ â€œì£¼ë¯¼ë“±ë¡(ì£¼ë¯¼ë“±ë¡) í•˜ì§€ ë§ì•„ë‹¬ë¼â€ê³  íŠ¹ì•½ì‚¬í•­(íŠ¹ì•½ì‚¬í•­)ì„ ë„£ìê³  í•©ë‹ˆë‹¤. ì´ íŠ¹ì•½ì‚¬í•­(íŠ¹ì•½ì‚¬í•­)ì„ ì§€í‚¤ë©´ ì •ë§ ë¬¸ì œê°€ ìƒê¸°ë‚˜ìš”?\n",
      "2026-02-06 17:28:48,482 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ â€œì£¼ë¯¼ë“±ë¡(ì£¼ë¯¼ë“±ë¡) í•˜ì§€ ë§ì•„ë‹¬ë¼â€ê³  íŠ¹ì•½ì‚¬í•­(íŠ¹ì•½ì‚¬í•­)ì„ ë„£ìê³  í•©ë‹ˆë‹¤. ì´ íŠ¹ì•½ì‚¬í•­(íŠ¹ì•½ì‚¬í•­)ì„ ì§€í‚¤ë©´ ì •ë§ ë¬¸ì œê°€ ìƒê¸°ë‚˜ìš”?'\n",
      "2026-02-06 17:28:49,412 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:49,981 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:51,436 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:54,011 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:54,017 - rag_module - INFO - ğŸ“Œ Rerank selected=6 (threshold=0.22)\n",
      "2026-02-06 17:28:54,020 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:28:54,230 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:28:54,233 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:28:54,697 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:54,700 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ê²½ê¸°ë„ì— ì‚¬ëŠ”ë° ì„ì°¨ì£¼íƒì´ ê²½ë§¤ì ˆì°¨ë¡œ ë„˜ì–´ê°€ë©´, ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ì¼ë¶€ë¼ë„ ìš°ì„ ë³€ì œê¶Œìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\n",
      "2026-02-06 17:28:54,701 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ê²½ê¸°ë„ì— ì‚¬ëŠ”ë° ì„ì°¨ì£¼íƒì´ ê²½ë§¤ì ˆì°¨ë¡œ ë„˜ì–´ê°€ë©´, ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ì¼ë¶€ë¼ë„ ìš°ì„ ë³€ì œê¶Œìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?'\n",
      "2026-02-06 17:28:55,309 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:56,016 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:56,766 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:59,569 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:28:59,574 - rag_module - INFO - ğŸ“Œ Rerank selected=7 (threshold=0.22)\n",
      "2026-02-06 17:28:59,576 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:28:59,789 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:28:59,791 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:29:00,480 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:00,497 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ê³„ì•½ê¸°ê°„ ì¤‘ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ë°”ë€Œì—ˆê³ , ìƒˆ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ë‚˜ê°€ë¼ê³  í•´ìš”. ì €ëŠ” ëˆ„êµ¬ì—ê²Œ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)ì„ ì²­êµ¬í•´ì•¼ í•˜ë‚˜ìš”?\n",
      "2026-02-06 17:29:00,498 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ê³„ì•½ê¸°ê°„ ì¤‘ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ë°”ë€Œì—ˆê³ , ìƒˆ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ë‚˜ê°€ë¼ê³  í•´ìš”. ì €ëŠ” ëˆ„êµ¬ì—ê²Œ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)ì„ ì²­êµ¬í•´ì•¼ í•˜ë‚˜ìš”?'\n",
      "2026-02-06 17:29:01,446 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:02,314 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:03,073 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:06,092 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:06,097 - rag_module - INFO - ğŸ“Œ Rerank selected=5 (threshold=0.22)\n",
      "2026-02-06 17:29:06,097 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:29:06,697 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:29:06,697 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:29:07,822 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:07,825 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ë¬µì‹œì ê°±ì‹ (ë¬µì‹œì ê°±ì‹ )ìœ¼ë¡œ ì—°ì¥ëœ ì¤„ ëª¨ë¥´ê³  ì‚´ì•˜ëŠ”ë°, ì£¼íƒì˜ì¸ë„(ì£¼íƒì˜ì¸ë„) ê°€ë ¤ë©´ ì–¸ì œê¹Œì§€ ì‚´ì•„ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : ì‚¬ìš©ì ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ëŠ” \"ë¬µì‹œì  ê°±ì‹  ìƒíƒœì—ì„œ ê³„ì•½ í•´ì§€ ì‹œ í†µì§€ ê¸°ê°„\"ì— ê´€í•œ ê²ƒìœ¼ë¡œ ì¶”ì •ë˜ë‚˜, [ìš©ì–´ ì‚¬ì „]ì— ëª…ì‹œëœ ë§¤í•‘ ê·œì¹™ë§Œ ì ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. \"ì´ì‚¬ ê°€ë ¤ë©´ ì–¸ì œê¹Œì§€ ì‚´ì•„ì•¼ í•˜ë‚˜ìš”\"ëŠ” \"ê³„ì•½í•´ì§€ í†µì§€ ê¸°ê°„\" ê´€ë ¨ ì¶”ê°€ ë³€í™˜ì´ í•„ìš”í•˜ë‚˜, ì‚¬ì „ì— í•´ë‹¹ ìš©ì–´ê°€ ì—†ì–´ ì›ë¬¸ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
      "2026-02-06 17:29:07,826 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ë¬µì‹œì ê°±ì‹ (ë¬µì‹œì ê°±ì‹ )ìœ¼ë¡œ ì—°ì¥ëœ ì¤„ ëª¨ë¥´ê³  ì‚´ì•˜ëŠ”ë°, ì£¼íƒì˜ì¸ë„(ì£¼íƒì˜ì¸ë„) ê°€ë ¤ë©´ ì–¸ì œê¹Œì§€ ì‚´ì•„ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : ì‚¬ìš©ì ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ëŠ” \"ë¬µì‹œì  ê°±ì‹  ìƒíƒœì—ì„œ ê³„ì•½ í•´ì§€ ì‹œ í†µì§€ ê¸°ê°„\"ì— ê´€í•œ ê²ƒìœ¼ë¡œ ì¶”ì •ë˜ë‚˜, [ìš©ì–´ ì‚¬ì „]ì— ëª…ì‹œëœ ë§¤í•‘ ê·œì¹™ë§Œ ì ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. \"ì´ì‚¬ ê°€ë ¤ë©´ ì–¸ì œê¹Œì§€ ì‚´ì•„ì•¼ í•˜ë‚˜ìš”\"ëŠ” \"ê³„ì•½í•´ì§€ í†µì§€ ê¸°ê°„\" ê´€ë ¨ ì¶”ê°€ ë³€í™˜ì´ í•„ìš”í•˜ë‚˜, ì‚¬ì „ì— í•´ë‹¹ ìš©ì–´ê°€ ì—†ì–´ ì›ë¬¸ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤.'\n",
      "2026-02-06 17:29:08,130 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:10,624 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:11,158 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:13,684 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:13,689 - rag_module - INFO - ğŸ“Œ Rerank selected=4 (threshold=0.22)\n",
      "2026-02-06 17:29:13,691 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:29:13,902 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:29:13,903 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:29:14,640 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:14,648 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì‹ ì¶• ì„ì°¨ì£¼íƒì¸ë° ì„ëŒ€ì°¨ë³´ì¦ê¸ˆì´ ë„ˆë¬´ ë†’ì•„ì„œ ë¶ˆì•ˆí•©ë‹ˆë‹¤. ì‹¤ê±°ë˜ê°€ë³´ë‹¤ í›¨ì”¬ ë¹„ì‹¼ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ê³„ì•½ë„ ë²•ì ìœ¼ë¡œ ë¬¸ì œë  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "(ë¹Œë¼â†’ì„ì°¨ì£¼íƒ, ì „ì„¸ê°€â†’ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)\n",
      "2026-02-06 17:29:14,650 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì‹ ì¶• ì„ì°¨ì£¼íƒì¸ë° ì„ëŒ€ì°¨ë³´ì¦ê¸ˆì´ ë„ˆë¬´ ë†’ì•„ì„œ ë¶ˆì•ˆí•©ë‹ˆë‹¤. ì‹¤ê±°ë˜ê°€ë³´ë‹¤ í›¨ì”¬ ë¹„ì‹¼ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ê³„ì•½ë„ ë²•ì ìœ¼ë¡œ ë¬¸ì œë  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "(ë¹Œë¼â†’ì„ì°¨ì£¼íƒ, ì „ì„¸ê°€â†’ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)'\n",
      "2026-02-06 17:29:15,063 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:15,796 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:16,722 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:19,921 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:19,927 - rag_module - INFO - ğŸ“Œ Rerank selected=17 (threshold=0.22)\n",
      "2026-02-06 17:29:19,931 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:29:20,131 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:29:20,131 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:29:21,162 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:21,165 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì£¼ë¯¼ë“±ë¡Â·í™•ì •ì¼ì í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©(í™•ì •ì¼ìë¶€ ë‚´ìš©)ì´ ì¤‘ìš”í•œê°€ìš”?  \n",
      "\n",
      "[ë³€ê²½ëœ ì§ˆë¬¸]  \n",
      "ì£¼ë¯¼ë“±ë¡(ì£¼ë¯¼ë“±ë¡)Â·í™•ì •ì¼ì(í™•ì •ì¼ì) í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©(í™•ì •ì¼ìë¶€ ë‚´ìš©)ì´ ì¤‘ìš”í•œê°€ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : 'í™•ì •ì¼ìë¶€ ë‚´ìš©'ì€ ìš©ì–´ ì‚¬ì „ì— ì—†ëŠ” í‘œí˜„ì´ë¯€ë¡œ ì›ë¬¸ì„ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤. í•„ìš” ì‹œ ì¶”ê°€ ë§¤í•‘ ìš”ì²­ ë°”ëë‹ˆë‹¤.\n",
      "2026-02-06 17:29:21,167 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì£¼ë¯¼ë“±ë¡Â·í™•ì •ì¼ì í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©(í™•ì •ì¼ìë¶€ ë‚´ìš©)ì´ ì¤‘ìš”í•œê°€ìš”?  \n",
      "\n",
      "[ë³€ê²½ëœ ì§ˆë¬¸]  \n",
      "ì£¼ë¯¼ë“±ë¡(ì£¼ë¯¼ë“±ë¡)Â·í™•ì •ì¼ì(í™•ì •ì¼ì) í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©(í™•ì •ì¼ìë¶€ ë‚´ìš©)ì´ ì¤‘ìš”í•œê°€ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : 'í™•ì •ì¼ìë¶€ ë‚´ìš©'ì€ ìš©ì–´ ì‚¬ì „ì— ì—†ëŠ” í‘œí˜„ì´ë¯€ë¡œ ì›ë¬¸ì„ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤. í•„ìš” ì‹œ ì¶”ê°€ ë§¤í•‘ ìš”ì²­ ë°”ëë‹ˆë‹¤.'\n",
      "2026-02-06 17:29:21,744 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:24,146 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:24,857 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:27,513 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:27,513 - rag_module - INFO - ğŸ“Œ Rerank selected=18 (threshold=0.22)\n",
      "2026-02-06 17:29:27,513 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:29:28,159 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:29:28,162 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:29:29,730 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:29,732 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬) í”¼í•´ìë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨ ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬) í”¼í•´ìë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨ ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : ì‚¬ìš©ì ì§ˆë¬¸ì˜ \"ì „ì„¸ì‚¬ê¸°\"ëŠ” ìš©ì–´ ì‚¬ì „ì— 'ì „ì„¸í”¼í•´'ë¡œ ì§ì ‘ ë§¤í•‘ë˜ì§€ ì•Šìœ¼ë‚˜, ê°€ì¥ ê·¼ì ‘í•œ ì˜ë¯¸ì¸ 'ê¶Œë¦¬ë¦¬ìŠ¤í¬'ë¡œ ë³€í™˜í•˜ì˜€ìŠµë‹ˆë‹¤. ë‹¤ë§Œ, 'ì „ì„¸í”¼í•´'ê°€ ì‚¬ì „ì— ì¡´ì¬í•˜ë¯€ë¡œ ì •í™•í•œ ë³€í™˜ì„ ìœ„í•´ ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "\n",
      "(ìµœì¢… ì¶œë ¥ ì‹œ ìœ„ ì„¤ëª… ì œì™¸)  \n",
      "\n",
      "**ìµœì¢… ì¶œë ¥:**  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬) í”¼í•´ìë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨ ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?\n",
      "2026-02-06 17:29:29,734 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬) í”¼í•´ìë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨ ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬) í”¼í•´ìë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨ ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : ì‚¬ìš©ì ì§ˆë¬¸ì˜ \"ì „ì„¸ì‚¬ê¸°\"ëŠ” ìš©ì–´ ì‚¬ì „ì— 'ì „ì„¸í”¼í•´'ë¡œ ì§ì ‘ ë§¤í•‘ë˜ì§€ ì•Šìœ¼ë‚˜, ê°€ì¥ ê·¼ì ‘í•œ ì˜ë¯¸ì¸ 'ê¶Œë¦¬ë¦¬ìŠ¤í¬'ë¡œ ë³€í™˜í•˜ì˜€ìŠµë‹ˆë‹¤. ë‹¤ë§Œ, 'ì „ì„¸í”¼í•´'ê°€ ì‚¬ì „ì— ì¡´ì¬í•˜ë¯€ë¡œ ì •í™•í•œ ë³€í™˜ì„ ìœ„í•´ ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "\n",
      "(ìµœì¢… ì¶œë ¥ ì‹œ ìœ„ ì„¤ëª… ì œì™¸)  \n",
      "\n",
      "**ìµœì¢… ì¶œë ¥:**  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬) í”¼í•´ìë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨ ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?'\n",
      "2026-02-06 17:29:30,250 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:31,256 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:32,134 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:34,947 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:34,963 - rag_module - INFO - ğŸ“Œ Rerank selected=18 (threshold=0.22)\n",
      "2026-02-06 17:29:34,963 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:29:35,146 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:29:35,146 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:29:35,759 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:35,763 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?\n",
      "2026-02-06 17:29:35,763 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?'\n",
      "2026-02-06 17:29:36,395 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:38,879 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:41,495 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:48,754 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:48,759 - rag_module - INFO - ğŸ“Œ Rerank selected=14 (threshold=0.26)\n",
      "2026-02-06 17:29:48,761 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:29:49,628 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:29:49,628 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:29:50,345 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:50,345 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ë³´ì¦ê¸ˆ)ì„ ë³´ì¦ê¸ˆë¯¸ë°˜í™˜(ì•ˆëŒë ¤ì¤Œ)í•´ì„œ ì œê°€ ì¼ë¶€ëŸ¬ ì£¼ë¯¼ë“±ë¡(ì „ì…ì‹ ê³ )ì„ ìœ ì§€í•˜ê³  ìˆëŠ”ë°, ë‹¤ë¥¸ ì„ì°¨ì£¼íƒ(ë‹¤ë¥¸ ì§‘)ìœ¼ë¡œ ì£¼ë¯¼ë“±ë¡(ì „ì…ì‹ ê³ )ì„ í•˜ë©´ ì œ ì„ì°¨ì¸(ì„ì°¨ì¸) ê¶Œë¦¬ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n",
      "2026-02-06 17:29:50,352 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ë³´ì¦ê¸ˆ)ì„ ë³´ì¦ê¸ˆë¯¸ë°˜í™˜(ì•ˆëŒë ¤ì¤Œ)í•´ì„œ ì œê°€ ì¼ë¶€ëŸ¬ ì£¼ë¯¼ë“±ë¡(ì „ì…ì‹ ê³ )ì„ ìœ ì§€í•˜ê³  ìˆëŠ”ë°, ë‹¤ë¥¸ ì„ì°¨ì£¼íƒ(ë‹¤ë¥¸ ì§‘)ìœ¼ë¡œ ì£¼ë¯¼ë“±ë¡(ì „ì…ì‹ ê³ )ì„ í•˜ë©´ ì œ ì„ì°¨ì¸(ì„ì°¨ì¸) ê¶Œë¦¬ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?'\n",
      "2026-02-06 17:29:51,268 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:52,005 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:52,678 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:55,267 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:55,272 - rag_module - INFO - ğŸ“Œ Rerank selected=13 (threshold=0.26)\n",
      "2026-02-06 17:29:55,274 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:29:56,035 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:29:56,038 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:29:56,497 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:56,497 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ì–´ ìˆìœ¼ë©´, 1ë…„ ê²½ê³¼í•˜ë©´ ë¬´ì¡°ê±´ ì£¼íƒì˜ì¸ë„ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”?\n",
      "2026-02-06 17:29:56,497 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ì–´ ìˆìœ¼ë©´, 1ë…„ ê²½ê³¼í•˜ë©´ ë¬´ì¡°ê±´ ì£¼íƒì˜ì¸ë„ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”?'\n",
      "2026-02-06 17:29:56,744 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:57,235 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:29:58,341 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:00,989 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:00,994 - rag_module - INFO - ğŸ“Œ Rerank selected=1 (threshold=0.26)\n",
      "2026-02-06 17:30:00,994 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:30:02,027 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:30:02,027 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:30:03,110 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:03,113 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ â€œì£¼ë¯¼ë“±ë¡(ì£¼ë¯¼ë“±ë¡) í•˜ì§€ ë§ì•„ë‹¬ë¼â€ê³  íŠ¹ì•½ì‚¬í•­(íŠ¹ì•½ì‚¬í•­)ì„ ë„£ìê³  í•©ë‹ˆë‹¤. ì´ íŠ¹ì•½ì‚¬í•­(íŠ¹ì•½ì‚¬í•­)ì„ ì§€í‚¤ë©´ ì •ë§ ë¬¸ì œ(ë¬¸ì œ)ê°€ ìƒê¸°ë‚˜ìš”?\n",
      "2026-02-06 17:30:03,114 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ â€œì£¼ë¯¼ë“±ë¡(ì£¼ë¯¼ë“±ë¡) í•˜ì§€ ë§ì•„ë‹¬ë¼â€ê³  íŠ¹ì•½ì‚¬í•­(íŠ¹ì•½ì‚¬í•­)ì„ ë„£ìê³  í•©ë‹ˆë‹¤. ì´ íŠ¹ì•½ì‚¬í•­(íŠ¹ì•½ì‚¬í•­)ì„ ì§€í‚¤ë©´ ì •ë§ ë¬¸ì œ(ë¬¸ì œ)ê°€ ìƒê¸°ë‚˜ìš”?'\n",
      "2026-02-06 17:30:03,877 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:04,589 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:05,562 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:08,260 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:08,268 - rag_module - INFO - ğŸ“Œ Rerank selected=5 (threshold=0.26)\n",
      "2026-02-06 17:30:08,268 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:30:08,486 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:30:08,489 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:30:09,144 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:09,159 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ê²½ê¸°ë„ì— ì‚¬ëŠ”ë° ì„ì°¨ì£¼íƒì´ ê²½ë§¤ì ˆì°¨ë¡œ ë„˜ì–´ê°€ë©´, ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ì¼ë¶€ë¼ë„ ìš°ì„ ë³€ì œê¶Œìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\n",
      "2026-02-06 17:30:09,161 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ê²½ê¸°ë„ì— ì‚¬ëŠ”ë° ì„ì°¨ì£¼íƒì´ ê²½ë§¤ì ˆì°¨ë¡œ ë„˜ì–´ê°€ë©´, ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ì¼ë¶€ë¼ë„ ìš°ì„ ë³€ì œê¶Œìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?'\n",
      "2026-02-06 17:30:09,606 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:10,429 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:10,914 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:13,967 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:13,972 - rag_module - INFO - ğŸ“Œ Rerank selected=6 (threshold=0.26)\n",
      "2026-02-06 17:30:13,974 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:30:14,159 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:30:14,159 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:30:16,191 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:16,194 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ê³„ì•½ê¸°ê°„ ì¤‘ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ë°”ë€Œì—ˆê³ , ìƒˆ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ë‚˜ê°€ë¼ê³  í•´ìš”. ì €ëŠ” ëˆ„êµ¬ì—ê²Œ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)ì„ ì²­êµ¬í•´ì•¼ í•˜ë‚˜ìš”?\n",
      "2026-02-06 17:30:16,195 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ê³„ì•½ê¸°ê°„ ì¤‘ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ë°”ë€Œì—ˆê³ , ìƒˆ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ ë‚˜ê°€ë¼ê³  í•´ìš”. ì €ëŠ” ëˆ„êµ¬ì—ê²Œ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)ì„ ì²­êµ¬í•´ì•¼ í•˜ë‚˜ìš”?'\n",
      "2026-02-06 17:30:16,643 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:17,576 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:18,276 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:21,219 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:21,225 - rag_module - INFO - ğŸ“Œ Rerank selected=4 (threshold=0.26)\n",
      "2026-02-06 17:30:21,227 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:30:21,473 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:30:21,476 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:30:22,082 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:22,086 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ë¬µì‹œì ê°±ì‹ (ë¬µì‹œì ê°±ì‹ )ìœ¼ë¡œ ì—°ì¥ëœ ì¤„ ëª¨ë¥´ê³  ì‚´ì•˜ëŠ”ë°, ì£¼íƒì˜ì¸ë„(ì£¼íƒì˜ì¸ë„) ê°€ë ¤ë©´ ì–¸ì œê¹Œì§€ ì‚´ì•„ì•¼ í•˜ë‚˜ìš”?\n",
      "2026-02-06 17:30:22,087 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ë¬µì‹œì ê°±ì‹ (ë¬µì‹œì ê°±ì‹ )ìœ¼ë¡œ ì—°ì¥ëœ ì¤„ ëª¨ë¥´ê³  ì‚´ì•˜ëŠ”ë°, ì£¼íƒì˜ì¸ë„(ì£¼íƒì˜ì¸ë„) ê°€ë ¤ë©´ ì–¸ì œê¹Œì§€ ì‚´ì•„ì•¼ í•˜ë‚˜ìš”?'\n",
      "2026-02-06 17:30:22,526 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:23,371 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:24,085 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:27,108 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:27,109 - rag_module - INFO - ğŸ“Œ Rerank selected=14 (threshold=0.26)\n",
      "2026-02-06 17:30:27,109 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:30:27,330 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:30:27,332 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:30:28,185 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:28,189 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì‹ ì¶• ì„ì°¨ì£¼íƒì¸ë° ì„ëŒ€ì°¨ë³´ì¦ê¸ˆì´ ë„ˆë¬´ ë†’ì•„ì„œ ë¶ˆì•ˆí•©ë‹ˆë‹¤. ì‹¤ê±°ë˜ê°€ë³´ë‹¤ í›¨ì”¬ ë¹„ì‹¼ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ê³„ì•½ë„ ë²•ì ìœ¼ë¡œ ë¬¸ì œë  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì‹ ì¶• ì„ì°¨ì£¼íƒ(ì„ì°¨ì£¼íƒ)ì¸ë° ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)ì´ ë„ˆë¬´ ë†’ì•„ì„œ ë¶ˆì•ˆí•©ë‹ˆë‹¤. ì‹¤ê±°ë˜ê°€ë³´ë‹¤ í›¨ì”¬ ë¹„ì‹¼ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ) ê³„ì•½ë„ ë²•ì ìœ¼ë¡œ ë¬¸ì œë  ìˆ˜ ìˆë‚˜ìš”?\n",
      "2026-02-06 17:30:28,192 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì‹ ì¶• ì„ì°¨ì£¼íƒì¸ë° ì„ëŒ€ì°¨ë³´ì¦ê¸ˆì´ ë„ˆë¬´ ë†’ì•„ì„œ ë¶ˆì•ˆí•©ë‹ˆë‹¤. ì‹¤ê±°ë˜ê°€ë³´ë‹¤ í›¨ì”¬ ë¹„ì‹¼ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ê³„ì•½ë„ ë²•ì ìœ¼ë¡œ ë¬¸ì œë  ìˆ˜ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì‹ ì¶• ì„ì°¨ì£¼íƒ(ì„ì°¨ì£¼íƒ)ì¸ë° ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)ì´ ë„ˆë¬´ ë†’ì•„ì„œ ë¶ˆì•ˆí•©ë‹ˆë‹¤. ì‹¤ê±°ë˜ê°€ë³´ë‹¤ í›¨ì”¬ ë¹„ì‹¼ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ) ê³„ì•½ë„ ë²•ì ìœ¼ë¡œ ë¬¸ì œë  ìˆ˜ ìˆë‚˜ìš”?'\n",
      "2026-02-06 17:30:28,643 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:29,309 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:29,992 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:32,937 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:32,942 - rag_module - INFO - ğŸ“Œ Rerank selected=14 (threshold=0.26)\n",
      "2026-02-06 17:30:32,942 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:30:33,138 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:30:33,138 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:30:33,581 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:33,584 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì£¼ë¯¼ë“±ë¡Â·í™•ì •ì¼ì(í™•ì •ì¼ì) í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€(í™•ì •ì¼ìë¶€) ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”?\n",
      "2026-02-06 17:30:33,585 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì£¼ë¯¼ë“±ë¡Â·í™•ì •ì¼ì(í™•ì •ì¼ì) í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€(í™•ì •ì¼ìë¶€) ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”?'\n",
      "2026-02-06 17:30:34,159 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:35,335 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:36,174 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:39,026 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:39,026 - rag_module - INFO - ğŸ“Œ Rerank selected=2 (threshold=0.26)\n",
      "2026-02-06 17:30:39,026 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:30:39,226 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:30:39,229 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "2026-02-06 17:30:40,427 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:40,443 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : 'ì „ì„¸ì‚¬ê¸°'ëŠ” ìš©ì–´ ì‚¬ì „ì— ëª…ì‹œë˜ì§€ ì•Šì•„ ì›ë¬¸ì„ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤. í•„ìš” ì‹œ ì¶”ê°€ ë§¤í•‘ ìš”ì²­ ë°”ëë‹ˆë‹¤.\n",
      "2026-02-06 17:30:40,444 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : 'ì „ì„¸ì‚¬ê¸°'ëŠ” ìš©ì–´ ì‚¬ì „ì— ëª…ì‹œë˜ì§€ ì•Šì•„ ì›ë¬¸ì„ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤. í•„ìš” ì‹œ ì¶”ê°€ ë§¤í•‘ ìš”ì²­ ë°”ëë‹ˆë‹¤.'\n",
      "2026-02-06 17:30:40,872 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:41,741 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:42,442 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:45,492 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:45,492 - rag_module - INFO - ğŸ“Œ Rerank selected=14 (threshold=0.26)\n",
      "2026-02-06 17:30:45,492 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 17:30:45,715 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-06 17:30:45,719 - rag_module - WARNING - âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: Error code: 404 - {'error': {'message': 'The model `solar-pro2` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BASE_SAMPLES: 10\n",
      "âœ… EXP_SAMPLES : 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì§‘ì£¼ì¸ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?</td>\n",
       "      <td>ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.</td>\n",
       "      <td>[page_content='â‘  ì¡°ì •ìœ„ì›íšŒëŠ” í•´ë‹¹ ë¶„ìŸì´ ê·¸ ì„±ì§ˆìƒ ì¡°ì •ì„ í•˜ê¸°ì— ì ...</td>\n",
       "      <td>ë„¤, ê°•ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ27ì¡°ì— ë”°ë¥´ë©´,\\n ì œ26ì¡°ì œ4í•­ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               question                      answer  \\\n",
       "0  ì¡°ì •ì—ì„œ í•©ì˜í–ˆëŠ”ë° ì§‘ì£¼ì¸ì´ ì•ˆ ì§€ì¼œìš”. ì´ê±° ê°•ì œí•  ìˆ˜ ìˆë‚˜ìš”?  ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [page_content='â‘  ì¡°ì •ìœ„ì›íšŒëŠ” í•´ë‹¹ ë¶„ìŸì´ ê·¸ ì„±ì§ˆìƒ ì¡°ì •ì„ í•˜ê¸°ì— ì ...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  ë„¤, ê°•ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ27ì¡°ì— ë”°ë¥´ë©´,\\n ì œ26ì¡°ì œ4í•­ ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shrink_contexts(ctxs, max_chars=2400, max_contexts=30):\n",
    "    out = []\n",
    "    for c in (ctxs or []):\n",
    "        if c is None:\n",
    "            continue\n",
    "        s = str(c).strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        out.append(s[:max_chars])\n",
    "        if len(out) >= max_contexts:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "def row_get_ground_truth(r: dict):\n",
    "    return r.get(\"ground_truth\") or r.get(\"reference\") or r.get(\"gt\") or r.get(\"answer\")\n",
    "\n",
    "def run_pipe_to_samples(pipe, rows, system_prompt=None, max_chars=2400, max_contexts=30, limit=None):\n",
    "    samples = []\n",
    "    n = len(rows) if limit is None else min(limit, len(rows))\n",
    "\n",
    "    for i in range(n):\n",
    "        r = rows[i]\n",
    "        q = r.get(\"question\") or r.get(\"query\")\n",
    "        if not q:\n",
    "            continue\n",
    "\n",
    "        # âœ… íŒŒì´í”„ í˜¸ì¶œ + í”„ë¡¬í”„íŠ¸ ì£¼ì…(ê°€ëŠ¥í•œ ë°©ì‹ìœ¼ë¡œ ì‹œë„)\n",
    "        try:\n",
    "            out = pipe.answer_with_trace(q, system_prompt=system_prompt) if system_prompt else pipe.answer_with_trace(q)\n",
    "        except TypeError:\n",
    "            # íŒŒì´í”„ë¼ì¸ì´ system_prompt ì¸ìë¥¼ ë°›ì§€ ì•ŠëŠ” ê²½ìš°: ì†ì„±/ì„¸í„°ë¡œ ìš°íšŒ ì‹œë„\n",
    "            if system_prompt:\n",
    "                if hasattr(pipe, \"set_system_prompt\") and callable(getattr(pipe, \"set_system_prompt\")):\n",
    "                    pipe.set_system_prompt(system_prompt)\n",
    "                elif hasattr(pipe, \"system_prompt\"):\n",
    "                    try:\n",
    "                        setattr(pipe, \"system_prompt\", system_prompt)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                elif hasattr(pipe, \"prompt\"):\n",
    "                    try:\n",
    "                        setattr(pipe, \"prompt\", system_prompt)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            out = pipe.answer_with_trace(q)\n",
    "\n",
    "        # outì´ dictì¼ ìˆ˜ë„ ìˆê³ , (answer, ctxs, trace) íŠœí”Œì¼ ìˆ˜ë„ ìˆì–´ì„œ ì•ˆì „ ì²˜ë¦¬\n",
    "        ans, ctxs, trace = \"\", [], None\n",
    "\n",
    "        if isinstance(out, dict):\n",
    "            ans = out.get(\"answer\") or out.get(\"result\") or out.get(\"output\") or out.get(\"text\") or \"\"\n",
    "            ctxs = out.get(\"contexts\") or out.get(\"context\") or out.get(\"docs\") or []\n",
    "            trace = out.get(\"trace\") or out.get(\"debug\") or out.get(\"meta\")\n",
    "        elif isinstance(out, tuple):\n",
    "            # í”í•œ íŒ¨í„´ë“¤ ëŒ€ì‘\n",
    "            if len(out) == 3:\n",
    "                ans, ctxs, trace = out\n",
    "            elif len(out) == 2:\n",
    "                ans, ctxs = out\n",
    "            elif len(out) == 1:\n",
    "                ans = out[0]\n",
    "        else:\n",
    "            ans = str(out)\n",
    "\n",
    "        samples.append({\n",
    "            \"question\": q,\n",
    "            \"answer\": ans or \"\",\n",
    "            \"contexts\": shrink_contexts(ctxs, max_chars=max_chars, max_contexts=max_contexts),\n",
    "            \"ground_truth\": row_get_ground_truth(r) or \"\",\n",
    "            \"_trace\": trace,  # âœ… traceë„ ê°™ì´ ë³´ê´€(ì›í•˜ë©´ ì €ì¥ ê°€ëŠ¥)\n",
    "        })\n",
    "\n",
    "    return samples\n",
    "\n",
    "# âœ… ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸: 1ë¬¸ì œë§Œ (ì›í•˜ë©´ limit=1 ì¶”ì²œ)\n",
    "BASE_SAMPLES = run_pipe_to_samples(base_pipe, rows, system_prompt=SYSTEM_PROMPT_BASE, limit=None)\n",
    "EXP_SAMPLES  = run_pipe_to_samples(exp_pipe,  rows, system_prompt=SYSTEM_PROMPT_EXP,  limit=None)\n",
    "\n",
    "print(\"âœ… BASE_SAMPLES:\", len(BASE_SAMPLES))\n",
    "print(\"âœ… EXP_SAMPLES :\", len(EXP_SAMPLES))\n",
    "\n",
    "pd.DataFrame([{k: v for k, v in BASE_SAMPLES[0].items() if k != \"_trace\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286a3c26",
   "metadata": {},
   "source": [
    "## 6) RAGAS evaluation (prepared cell)\n",
    "\n",
    "- Creates per-sample detail dataframe (when supported by your RAGAS version)\n",
    "- Creates summary dataframe (mean over samples)\n",
    "- Keeps timing metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10a15582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… METRICS: ['ContextPrecision', 'ContextRecall', 'Faithfulness', 'AnswerRelevancy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7124\\1108317652.py:35: DeprecationWarning: Importing context_precision from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_precision\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7124\\1108317652.py:35: DeprecationWarning: Importing context_recall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_recall\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7124\\1108317652.py:35: DeprecationWarning: Importing faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import faithfulness\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7124\\1108317652.py:39: DeprecationWarning: Importing answer_relevancy from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import answer_relevancy\n",
      "  from ragas.metrics import answer_relevancy\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# RAGAS compare + clean saving (ragas==0.3.2 compatible)\n",
    "# FIXES:\n",
    "#  1) detail.csvì—ì„œ _trace ì œê±° (traceëŠ” trace.jsonlë¡œë§Œ)\n",
    "#  2) samplesì— run_tagë¥¼ ë¯¸ë¦¬ ì£¼ì…í•´ì„œ trace.jsonlì— íƒœê·¸ê°€ ë‚¨ë„ë¡\n",
    "#  3) ground_truths=[...] ì•ˆì „ì¥ì¹˜ ì¶”ê°€ (ë²„ì „/í™˜ê²½ í˜¸í™˜ì„±â†‘)\n",
    "#  4) samples/detail ì»¬ëŸ¼ ì¶©ëŒ ë°©ì§€(ê°€ëŠ¥í•œ í•œ ì•ˆì „í•˜ê²Œ merge)\n",
    "# ============================================================\n",
    "\n",
    "import time, json, re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.llms import llm_factory\n",
    "\n",
    "# ----------------------------\n",
    "# LLM + METRICS (ragas 0.3.2)\n",
    "# ----------------------------\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"UPSTAGE_API_KEY\"),\n",
    "    base_url=os.environ.get(\"UPSTAGE_BASE_URL\", \"https://api.upstage.ai/v1\"),\n",
    ")\n",
    "if not os.environ.get(\"UPSTAGE_API_KEY\"):\n",
    "    raise EnvironmentError(\"UPSTAGE_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆ: setx UPSTAGE_API_KEY \\\"...\\\"\")\n",
    "llm = llm_factory(\"solar-pro2\", client=client)\n",
    "def build_metrics_032():\n",
    "    from ragas.metrics import context_precision, context_recall, faithfulness\n",
    "    metrics = [context_precision, context_recall, faithfulness]\n",
    "    # answer_relevancyëŠ” í™˜ê²½ì— ë”°ë¼ ì—†ì„ ìˆ˜ ìˆì–´ optional\n",
    "    try:\n",
    "        from ragas.metrics import answer_relevancy\n",
    "        metrics.append(answer_relevancy)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    return metrics\n",
    "\n",
    "METRICS = build_metrics_032()\n",
    "print(\"âœ… METRICS:\", [getattr(m, \"__name__\", m.__class__.__name__) for m in METRICS])\n",
    "\n",
    "# ----------------------------\n",
    "# utils\n",
    "# ----------------------------\n",
    "def _json_safe(obj):\n",
    "    \"\"\"Make config/meta safe to dump to json.\"\"\"\n",
    "    try:\n",
    "        json.dumps(obj, ensure_ascii=False)\n",
    "        return obj\n",
    "    except TypeError:\n",
    "        if hasattr(obj, \"model_dump\"):\n",
    "            return obj.model_dump()\n",
    "        if hasattr(obj, \"dict\"):\n",
    "            return obj.dict()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            return obj.__dict__\n",
    "        return str(obj)\n",
    "\n",
    "def _write_json(path: Path, data):\n",
    "    path.write_text(json.dumps(_json_safe(data), ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "def _write_jsonl(path: Path, rows):\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(_json_safe(r), ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def _next_run_dir(project_root: Path, prefix: str):\n",
    "    runs_root = Path(project_root) / \"results\" / \"ragas_runs\"\n",
    "    runs_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pat = re.compile(rf\"^{re.escape(prefix)}_(\\d{{4}})_\")\n",
    "    nums = []\n",
    "    for p in runs_root.iterdir():\n",
    "        if p.is_dir():\n",
    "            m = pat.match(p.name)\n",
    "            if m:\n",
    "                nums.append(int(m.group(1)))\n",
    "    next_idx = (max(nums) + 1) if nums else 1\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = runs_root / f\"{prefix}_{next_idx:04d}_{ts}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=False)\n",
    "    return run_dir, next_idx, ts\n",
    "\n",
    "def _strip_trace(samples):\n",
    "    \"\"\"detail.csvì—ëŠ” _traceë¥¼ ë„£ì§€ ì•Šê¸°(íŒŒì¼ í­ë°œ ë°©ì§€).\"\"\"\n",
    "    out = []\n",
    "    for s in samples:\n",
    "        if isinstance(s, dict):\n",
    "            out.append({k: v for k, v in s.items() if k != \"_trace\"})\n",
    "        else:\n",
    "            out.append(s)\n",
    "    return out\n",
    "\n",
    "# ----------------------------\n",
    "# core eval\n",
    "# ----------------------------\n",
    "def eval_ragas_with_details(samples, run_tag: str):\n",
    "    # âœ… samplesì— run_tagë¥¼ ë¯¸ë¦¬ ì£¼ì… (trace.jsonlì—ì„œ íƒœê·¸ ìœ ì§€)\n",
    "    for s in samples:\n",
    "        if isinstance(s, dict):\n",
    "            s[\"run_tag\"] = run_tag\n",
    "            # âœ… ì•ˆì „ì¥ì¹˜: ground_truthsë„ í•¨ê»˜\n",
    "            if \"ground_truths\" not in s:\n",
    "                gt = s.get(\"ground_truth\") or \"\"\n",
    "                s[\"ground_truths\"] = [gt] if isinstance(gt, str) else (gt or [])\n",
    "\n",
    "    ds = Dataset.from_list(samples)\n",
    "\n",
    "    t0 = time.time()\n",
    "    res = evaluate(dataset=ds, metrics=METRICS, llm=llm)  # âœ… 0.3.2 ì•ˆì „ íŒ¨í„´\n",
    "    eval_sec = time.time() - t0\n",
    "\n",
    "    t1 = time.time()\n",
    "    detail_df = res.to_pandas() if hasattr(res, \"to_pandas\") else pd.DataFrame()\n",
    "    to_pandas_sec = time.time() - t1\n",
    "\n",
    "    # âœ… detailì—ëŠ” _trace ì œì™¸\n",
    "    samples_df = pd.DataFrame(_strip_trace(samples))\n",
    "\n",
    "    # merge per-sample metrics back onto samples (ê¸¸ì´ ë™ì¼í•  ë•Œë§Œ)\n",
    "    if len(detail_df) == len(samples_df) and len(detail_df) > 0:\n",
    "        # ì¶©ëŒ ì»¬ëŸ¼ ë°©ì§€: detail_dfì˜ ì»¬ëŸ¼ì´ samples_dfì— ì´ë¯¸ ìˆìœ¼ë©´ prefix\n",
    "        overlap = set(samples_df.columns) & set(detail_df.columns)\n",
    "        if overlap:\n",
    "            detail_df = detail_df.rename(columns={c: f\"metric__{c}\" for c in overlap})\n",
    "\n",
    "        out_detail = pd.concat(\n",
    "            [samples_df.reset_index(drop=True), detail_df.reset_index(drop=True)],\n",
    "            axis=1\n",
    "        )\n",
    "    else:\n",
    "        out_detail = samples_df.copy()\n",
    "\n",
    "    out_detail[\"eval_seconds\"] = round(eval_sec, 3)\n",
    "    out_detail[\"to_pandas_seconds\"] = round(to_pandas_sec, 3)\n",
    "\n",
    "    # summary (mean of numeric metric columns if available)\n",
    "    summary = {}\n",
    "    if len(detail_df) > 0:\n",
    "        summary = detail_df.mean(numeric_only=True).to_dict()\n",
    "    elif isinstance(res, dict):\n",
    "        summary = {k: float(v) for k, v in res.items() if isinstance(v, (int, float))}\n",
    "\n",
    "    summary[\"run_tag\"] = run_tag\n",
    "    summary[\"eval_seconds\"] = round(eval_sec, 3)\n",
    "    summary[\"to_pandas_seconds\"] = round(to_pandas_sec, 3)\n",
    "\n",
    "    return res, out_detail, pd.DataFrame([summary])\n",
    "\n",
    "# ----------------------------\n",
    "# compare + save (clean)\n",
    "# ----------------------------\n",
    "def run_compare_and_save(\n",
    "    base_samples,\n",
    "    exp_samples,\n",
    "    project_root: Path,\n",
    "    prefix=\"ragas_compare\",\n",
    "    base_cfg=None,\n",
    "    exp_cfg=None,\n",
    "):\n",
    "    # --- sanity ---\n",
    "    print(f\"âœ… base_samples: {len(base_samples)} | exp_samples: {len(exp_samples)}\")\n",
    "\n",
    "    base_res, base_detail_df, base_summary_df = eval_ragas_with_details(base_samples, \"baseline\")\n",
    "    exp_res,  exp_detail_df,  exp_summary_df  = eval_ragas_with_details(exp_samples,  \"experiment\")\n",
    "\n",
    "    summary_df = pd.concat([base_summary_df, exp_summary_df], ignore_index=True)\n",
    "    detail_df  = pd.concat([base_detail_df,  exp_detail_df],  ignore_index=True)\n",
    "\n",
    "    run_dir, run_id, ts = _next_run_dir(project_root, prefix)\n",
    "\n",
    "    out_summary = run_dir / \"summary.csv\"\n",
    "    out_detail  = run_dir / \"detail.csv\"\n",
    "    out_meta    = run_dir / \"meta.json\"\n",
    "    out_config  = run_dir / \"config.json\"\n",
    "    out_base_in = run_dir / \"samples_base.jsonl\"\n",
    "    out_exp_in  = run_dir / \"samples_exp.jsonl\"\n",
    "    out_trace   = run_dir / \"trace.jsonl\"\n",
    "\n",
    "    summary_df.to_csv(out_summary, index=False, encoding=\"utf-8-sig\")\n",
    "    detail_df.to_csv(out_detail, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # config snapshot (best-effort)\n",
    "    cfg_payload = {\n",
    "        \"base_cfg\": _json_safe(base_cfg) if base_cfg is not None else None,\n",
    "        \"exp_cfg\":  _json_safe(exp_cfg)  if exp_cfg  is not None else None,\n",
    "        \"llm\": {\"model\": \"solar-pro2\"},\n",
    "        \"metrics\": [getattr(m, \"__name__\", m.__class__.__name__) for m in METRICS],\n",
    "        \"created_at\": datetime.now().isoformat(),\n",
    "    }\n",
    "    _write_json(out_config, cfg_payload)\n",
    "\n",
    "    # input snapshots (ì›ë³¸ ìœ ì§€: _trace í¬í•¨)\n",
    "    _write_jsonl(out_base_in, base_samples)\n",
    "    _write_jsonl(out_exp_in,  exp_samples)\n",
    "\n",
    "    # trace snapshot (best-effort) - samplesì˜ _traceë§Œ ëª¨ì•„ì„œ ì €ì¥\n",
    "    trace_rows = []\n",
    "    for s in list(base_samples) + list(exp_samples):\n",
    "        if isinstance(s, dict) and (\"_trace\" in s) and (s.get(\"_trace\") is not None):\n",
    "            trace_rows.append({\n",
    "                \"run_tag\": s.get(\"run_tag\"),\n",
    "                \"question\": s.get(\"question\"),\n",
    "                \"_trace\": s.get(\"_trace\"),\n",
    "            })\n",
    "\n",
    "    # traceê°€ ì•„ì˜ˆ ì—†ìœ¼ë©´ ìµœì†Œ ì •ë³´ë¼ë„ ë‚¨ê¹€\n",
    "    if not trace_rows:\n",
    "        cols = [c for c in [\"run_tag\", \"question\", \"eval_seconds\"] if c in detail_df.columns]\n",
    "        trace_rows = detail_df[cols].to_dict(orient=\"records\") if cols else []\n",
    "\n",
    "    _write_jsonl(out_trace, trace_rows)\n",
    "\n",
    "    meta = {\n",
    "        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"ragas_version\": \"0.3.2\",\n",
    "        \"run_id\": run_id,\n",
    "        \"timestamp\": ts,\n",
    "        \"run_dir\": str(run_dir),\n",
    "        \"prefix\": prefix,\n",
    "        \"n_base_samples\": len(base_samples),\n",
    "        \"n_exp_samples\": len(exp_samples),\n",
    "        \"saved\": {\n",
    "            \"summary\": str(out_summary),\n",
    "            \"detail\": str(out_detail),\n",
    "            \"meta\": str(out_meta),\n",
    "            \"config\": str(out_config),\n",
    "            \"samples_base\": str(out_base_in),\n",
    "            \"samples_exp\": str(out_exp_in),\n",
    "            \"trace\": str(out_trace),\n",
    "        },\n",
    "    }\n",
    "    _write_json(out_meta, meta)\n",
    "\n",
    "    print(f\"âœ… Saved to: {run_dir}\")\n",
    "    print(f\"   - summary: {out_summary.name}\")\n",
    "    print(f\"   - detail : {out_detail.name}\")\n",
    "    print(f\"   - meta   : {out_meta.name}\")\n",
    "    print(f\"   - config : {out_config.name}\")\n",
    "    print(f\"   - inputs : {out_base_in.name}, {out_exp_in.name}\")\n",
    "    print(f\"   - trace  : {out_trace.name}\")\n",
    "\n",
    "    return {\n",
    "        \"base_res\": base_res,\n",
    "        \"exp_res\": exp_res,\n",
    "        \"summary_df\": summary_df,\n",
    "        \"detail_df\": detail_df,\n",
    "        \"run_dir\": run_dir,\n",
    "        \"out_summary\": out_summary,\n",
    "        \"out_detail\": out_detail,\n",
    "        \"out_meta\": out_meta,\n",
    "        \"out_config\": out_config,\n",
    "        \"out_samples_base\": out_base_in,\n",
    "        \"out_samples_exp\": out_exp_in,\n",
    "        \"out_trace\": out_trace,\n",
    "        \"run_id\": run_id,\n",
    "    }\n",
    "\n",
    "# ============================\n",
    "# USAGE (ì˜ˆì‹œ)\n",
    "# ============================\n",
    "# result = run_compare_and_save(\n",
    "#     base_samples=BASE_SAMPLES,\n",
    "#     exp_samples=EXP_SAMPLES,\n",
    "#     project_root=PROJECT_ROOT,\n",
    "#     prefix=\"ragas_compare\",\n",
    "#     base_cfg=base_cfg,\n",
    "#     exp_cfg=exp_cfg,\n",
    "# )\n",
    "# display(result[\"summary_df\"])\n",
    "# display(result[\"detail_df\"].head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee50b62",
   "metadata": {},
   "source": [
    "## 7) Run + compare + save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f39454-f368-4272-a7ed-116ed98f2ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29525fd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7124\\133348344.py:40: DeprecationWarning: Importing context_precision from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_precision\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7124\\133348344.py:40: DeprecationWarning: Importing context_recall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_recall\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7124\\133348344.py:40: DeprecationWarning: Importing faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import faithfulness\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7124\\133348344.py:43: DeprecationWarning: Importing answer_relevancy from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import answer_relevancy\n",
      "  from ragas.metrics import answer_relevancy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… METRICS: ['ContextPrecision', 'ContextRecall', 'Faithfulness', 'AnswerRelevancy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|                                                                               | 0/40 [00:00<?, ?it/s]2026-02-06 17:30:50,408 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:53,191 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:55,791 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:30:58,772 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:01,460 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:03,723 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:06,372 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:12,575 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:14,556 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:17,939 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:20,104 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:20,758 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:31:21,408 - ragas.executor - ERROR - Exception raised in Job[3]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:31:22,572 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:25,179 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:27,897 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:30,819 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:33,693 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:36,506 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:39,747 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:45,324 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:47,604 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:51,570 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:53,935 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:54,576 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:31:55,226 - ragas.executor - ERROR - Exception raised in Job[7]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:31:56,434 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:31:59,417 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:04,071 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:05,986 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:08,436 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:10,263 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:10,889 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:32:11,520 - ragas.executor - ERROR - Exception raised in Job[11]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:32:13,060 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:15,997 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:18,819 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:21,585 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:24,218 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:26,769 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:33,907 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:36,086 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:39,686 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:41,540 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:42,202 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:32:42,801 - ragas.executor - ERROR - Exception raised in Job[15]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:32:44,809 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:47,318 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:50,070 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:52,483 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:55,000 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:32:57,419 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:00,192 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:05,900 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:08,251 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:12,493 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:14,208 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:14,794 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:33:15,400 - ragas.executor - ERROR - Exception raised in Job[19]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:33:16,667 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:19,230 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:21,668 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:24,049 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:26,520 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:34,391 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:36,794 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:41,148 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:43,240 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:43,878 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:33:44,465 - ragas.executor - ERROR - Exception raised in Job[23]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:33:45,632 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:48,256 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:50,818 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:33:53,347 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:02,194 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:04,066 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:06,930 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:08,731 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:09,403 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:34:10,003 - ragas.executor - ERROR - Exception raised in Job[27]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:34:11,560 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:13,959 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:16,787 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:19,496 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:22,122 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:24,555 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:27,205 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:34,841 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:36,727 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:40,077 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:42,199 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:42,774 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:34:43,378 - ragas.executor - ERROR - Exception raised in Job[31]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:34:45,019 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:47,661 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:50,579 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:53,225 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:55,907 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:34:59,224 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:35:02,196 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:35:08,246 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:35:10,314 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:35:13,476 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:35:15,638 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:35:16,257 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:35:16,891 - ragas.executor - ERROR - Exception raised in Job[35]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:35:18,762 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:35:21,362 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:35:24,232 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:35:26,830 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:35:29,674 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:35:32,266 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:35:35,092 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:35:44,187 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:35:46,526 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:35:51,873 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:35:53,710 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:35:54,405 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:35:55,019 - ragas.executor - ERROR - Exception raised in Job[39]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [05:05<00:00,  7.65s/it]\n",
      "Evaluating:   0%|                                                                               | 0/40 [00:00<?, ?it/s]2026-02-06 17:35:59,024 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:01,545 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:04,190 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:06,623 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:09,099 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:11,853 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:14,172 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:19,891 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:21,855 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:25,494 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:27,437 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:28,215 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:36:28,889 - ragas.executor - ERROR - Exception raised in Job[3]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:36:30,511 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:33,409 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:35,704 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:38,476 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:40,975 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:43,972 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:46,569 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:52,619 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:55,001 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:36:59,381 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:01,219 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:01,836 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:37:02,533 - ragas.executor - ERROR - Exception raised in Job[7]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:37:03,668 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:08,662 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:10,685 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:15,035 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:16,949 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:17,610 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:37:18,252 - ragas.executor - ERROR - Exception raised in Job[11]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:37:19,559 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:22,492 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:24,958 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:27,498 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:30,068 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:36,442 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:38,593 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:42,666 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:44,560 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:45,179 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:37:45,806 - ragas.executor - ERROR - Exception raised in Job[15]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:37:47,609 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:49,976 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:52,566 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:55,482 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:37:58,199 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:00,807 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:06,876 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:09,315 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:13,831 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:16,131 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:16,783 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:38:17,406 - ragas.executor - ERROR - Exception raised in Job[19]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:38:18,603 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:21,578 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:24,089 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:26,731 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:36,663 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:39,199 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:43,394 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:45,398 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:46,046 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:38:46,779 - ragas.executor - ERROR - Exception raised in Job[23]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:38:48,086 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:50,679 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:53,045 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:55,346 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:38:57,732 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:00,328 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:02,927 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:11,697 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:13,618 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:16,509 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:18,243 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:18,945 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:39:19,560 - ragas.executor - ERROR - Exception raised in Job[27]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:39:21,014 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:23,287 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:26,416 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:28,855 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:31,411 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:34,135 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:37,085 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:43,258 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:45,124 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:48,699 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:50,506 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:51,109 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:39:51,708 - ragas.executor - ERROR - Exception raised in Job[31]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:39:53,108 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:39:56,347 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:40:02,760 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:40:04,937 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:40:07,946 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:40:09,847 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:40:10,463 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:40:11,091 - ragas.executor - ERROR - Exception raised in Job[35]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "2026-02-06 17:40:12,874 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:40:15,539 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:40:17,985 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:40:20,664 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:40:23,324 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:40:25,932 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:40:28,405 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:40:38,271 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:40:40,420 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:40:44,273 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:40:45,923 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 17:40:46,540 - ragas.prompt.pydantic_prompt - WARNING - LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "2026-02-06 17:40:47,189 - ragas.executor - ERROR - Exception raised in Job[39]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [04:49<00:00,  7.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… run_dir: C:\\ai\\source\\chatbot_app\\results\\ragas_runs\\ragas_compare_0032_20260206_174048\n",
      "âœ… saved: C:\\ai\\source\\chatbot_app\\results\\ragas_runs\\ragas_compare_0032_20260206_174048\\summary.csv C:\\ai\\source\\chatbot_app\\results\\ragas_runs\\ragas_compare_0032_20260206_174048\\detail.csv C:\\ai\\source\\chatbot_app\\results\\ragas_runs\\ragas_compare_0032_20260206_174048\\meta.json\n",
      "âœ… delta saved: C:\\ai\\source\\chatbot_app\\results\\ragas_runs\\ragas_compare_0032_20260206_174048\\delta_summary.csv C:\\ai\\source\\chatbot_app\\results\\ragas_runs\\ragas_compare_0032_20260206_174048\\delta_detail.csv\n",
      "âœ… top changes metric: answer_relevancy_delta\n",
      "âœ… top regressions: C:\\ai\\source\\chatbot_app\\results\\ragas_runs\\ragas_compare_0032_20260206_174048\\top_regressions.csv\n",
      "âœ… top improvements: C:\\ai\\source\\chatbot_app\\results\\ragas_runs\\ragas_compare_0032_20260206_174048\\top_improvements.csv\n",
      "âœ… extra saved config : C:\\ai\\source\\chatbot_app\\results\\ragas_runs\\ragas_compare_0032_20260206_174048\\config.json\n",
      "âœ… extra saved samples: C:\\ai\\source\\chatbot_app\\results\\ragas_runs\\ragas_compare_0032_20260206_174048\\samples_base.jsonl and C:\\ai\\source\\chatbot_app\\results\\ragas_runs\\ragas_compare_0032_20260206_174048\\samples_exp.jsonl\n",
      "âœ… extra saved trace  : C:\\ai\\source\\chatbot_app\\results\\ragas_runs\\ragas_compare_0032_20260206_174048\\trace.jsonl\n",
      "âœ… trace columns used : ['question', 'answer', 'ground_truth', 'reference', 'contexts', '_trace', 'run_tag']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# One-cell: RAGAS compare + save (+ delta outputs + dataset fingerprint)\n",
    "# Adds:\n",
    "#  - delta_summary.csv\n",
    "#  - delta_detail.csv\n",
    "#  - top_regressions.csv\n",
    "#  - top_improvements.csv\n",
    "#  - meta.json: testset fingerprint (path/lines/sha1) if TESTSET_JSONL exists\n",
    "# ============================================================\n",
    "\n",
    "import time, re, json, hashlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "from openai import OpenAI\n",
    "from ragas import evaluate\n",
    "from ragas.llms import llm_factory\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# LLM (non-deprecated)\n",
    "# ----------------------------\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"UPSTAGE_API_KEY\"),\n",
    "    base_url=os.environ.get(\"UPSTAGE_BASE_URL\", \"https://api.upstage.ai/v1\"),\n",
    ")\n",
    "if not os.environ.get(\"UPSTAGE_API_KEY\"):\n",
    "    raise EnvironmentError(\"UPSTAGE_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆ: setx UPSTAGE_API_KEY \\\"...\\\"\")\n",
    "llm = llm_factory(\"solar-pro2\", client=client)  # âœ… Upstage Solar Pro2\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# METRICS (version-tolerant)\n",
    "# ----------------------------\n",
    "def build_metrics():\n",
    "    from ragas.metrics import context_precision, context_recall, faithfulness\n",
    "    metrics = [context_precision, context_recall, faithfulness]\n",
    "    try:\n",
    "        from ragas.metrics import answer_relevancy\n",
    "        metrics.append(answer_relevancy)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    return metrics\n",
    "\n",
    "METRICS = build_metrics()\n",
    "print(\"âœ… METRICS:\", [getattr(m, \"__name__\", m.__class__.__name__) for m in METRICS])\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# JSON helpers (safe)\n",
    "# ----------------------------\n",
    "def _json_safe(obj):\n",
    "    try:\n",
    "        json.dumps(obj, ensure_ascii=False)\n",
    "        return obj\n",
    "    except TypeError:\n",
    "        if hasattr(obj, \"model_dump\"):\n",
    "            return obj.model_dump()\n",
    "        if hasattr(obj, \"dict\"):\n",
    "            return obj.dict()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            return obj.__dict__\n",
    "        return str(obj)\n",
    "\n",
    "def _write_json(path: Path, data):\n",
    "    path.write_text(json.dumps(_json_safe(data), ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "def _write_jsonl(path: Path, rows):\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(_json_safe(r), ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def _df_to_jsonl_rows(df, prefer_cols):\n",
    "    cols = [c for c in prefer_cols if c in df.columns]\n",
    "    if cols:\n",
    "        df = df[cols].copy()\n",
    "    return df.to_dict(orient=\"records\"), cols\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# dataset fingerprint helpers\n",
    "# ----------------------------\n",
    "def _file_sha1(path: Path, chunk_size=1024 * 1024) -> str:\n",
    "    h = hashlib.sha1()\n",
    "    with path.open(\"rb\") as f:\n",
    "        while True:\n",
    "            b = f.read(chunk_size)\n",
    "            if not b:\n",
    "                break\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def _count_jsonl_lines(path: Path) -> int:\n",
    "    n = 0\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                n += 1\n",
    "    return n\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# core: eval + detail/summary frames\n",
    "# ----------------------------\n",
    "def eval_ragas_with_details(samples, run_tag: str):\n",
    "    ds = Dataset.from_list(samples)\n",
    "\n",
    "    t0 = time.time()\n",
    "    res = evaluate(dataset=ds, metrics=METRICS, llm=llm)  # âœ… llmì€ ì—¬ê¸°ë¡œ\n",
    "    eval_sec = time.time() - t0\n",
    "\n",
    "    t1 = time.time()\n",
    "    detail_df = res.to_pandas() if hasattr(res, \"to_pandas\") else pd.DataFrame()\n",
    "    to_pandas_sec = time.time() - t1\n",
    "\n",
    "    samples_df = pd.DataFrame(samples)\n",
    "\n",
    "    # merge\n",
    "    if len(detail_df) == len(samples_df) and len(detail_df) > 0:\n",
    "        out_detail = pd.concat(\n",
    "            [samples_df.reset_index(drop=True), detail_df.reset_index(drop=True)],\n",
    "            axis=1\n",
    "        )\n",
    "    else:\n",
    "        out_detail = samples_df.copy()\n",
    "\n",
    "    out_detail[\"run_tag\"] = run_tag\n",
    "    out_detail[\"eval_seconds\"] = round(eval_sec, 3)\n",
    "    out_detail[\"to_pandas_seconds\"] = round(to_pandas_sec, 3)\n",
    "\n",
    "    # summary\n",
    "    summary = {}\n",
    "    if len(detail_df) > 0:\n",
    "        summary = detail_df.mean(numeric_only=True).to_dict()\n",
    "    elif isinstance(res, dict):\n",
    "        summary = {k: float(v) for k, v in res.items() if isinstance(v, (int, float))}\n",
    "\n",
    "    summary[\"run_tag\"] = run_tag\n",
    "    summary[\"eval_seconds\"] = round(eval_sec, 3)\n",
    "    summary[\"to_pandas_seconds\"] = round(to_pandas_sec, 3)\n",
    "\n",
    "    return res, out_detail, pd.DataFrame([summary])\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# run dir allocator\n",
    "# ----------------------------\n",
    "def _next_run_dir(project_root: Path, prefix: str):\n",
    "    runs_root = Path(project_root) / \"results\" / \"ragas_runs\"\n",
    "    runs_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pat = re.compile(rf\"^{re.escape(prefix)}_(\\d{{4}})_\")\n",
    "    nums = []\n",
    "    for p in runs_root.iterdir():\n",
    "        if p.is_dir():\n",
    "            m = pat.match(p.name)\n",
    "            if m:\n",
    "                nums.append(int(m.group(1)))\n",
    "    next_id = (max(nums) + 1) if nums else 1\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = runs_root / f\"{prefix}_{next_id:04d}_{ts}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=False)\n",
    "    return run_dir, next_id, ts\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# delta builders\n",
    "# ----------------------------\n",
    "def _pick_question_col(df: pd.DataFrame) -> str:\n",
    "    for c in [\"question\", \"normalized_question\", \"normalized_query\", \"query\"]:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return \"\"\n",
    "\n",
    "def _ensure_question_id(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # prefer an existing stable id\n",
    "    for c in [\"question_id\", \"id\", \"sample_id\"]:\n",
    "        if c in df.columns:\n",
    "            df = df.copy()\n",
    "            df[\"__qid__\"] = df[c].astype(str)\n",
    "            return df\n",
    "    # fallback: hash question text\n",
    "    qcol = _pick_question_col(df)\n",
    "    df = df.copy()\n",
    "    if qcol:\n",
    "        def _h(x: str) -> str:\n",
    "            s = (x or \"\").strip().encode(\"utf-8\")\n",
    "            return hashlib.sha1(s).hexdigest()[:12]\n",
    "        df[\"__qid__\"] = df[qcol].astype(str).map(_h)\n",
    "    else:\n",
    "        df[\"__qid__\"] = [f\"row{i:04d}\" for i in range(len(df))]\n",
    "    return df\n",
    "\n",
    "def _metric_cols(df: pd.DataFrame) -> list:\n",
    "    # heuristic: numeric columns from ragas result + common metric names\n",
    "    prefer = [\n",
    "        \"context_precision\", \"context_recall\", \"faithfulness\", \"answer_relevancy\",\n",
    "        \"ContextPrecision\", \"ContextRecall\", \"Faithfulness\", \"AnswerRelevancy\",\n",
    "    ]\n",
    "    cols = [c for c in prefer if c in df.columns]\n",
    "    if cols:\n",
    "        return cols\n",
    "\n",
    "    # fallback: any numeric columns that are not obvious non-metrics\n",
    "    exclude = set([\"eval_seconds\", \"to_pandas_seconds\"])\n",
    "    num_cols = []\n",
    "    for c in df.columns:\n",
    "        if c in exclude:\n",
    "            continue\n",
    "        if pd.api.types.is_numeric_dtype(df[c]):\n",
    "            num_cols.append(c)\n",
    "    return num_cols\n",
    "\n",
    "\n",
    "def _make_delta_summary(summary_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # summary_df has rows: baseline/experiment\n",
    "    metric_cols = [c for c in summary_df.columns if c not in [\"run_tag\"]]\n",
    "    base = summary_df[summary_df[\"run_tag\"] == \"baseline\"].iloc[0].to_dict()\n",
    "    exp  = summary_df[summary_df[\"run_tag\"] == \"experiment\"].iloc[0].to_dict()\n",
    "\n",
    "    rows = []\n",
    "    for c in metric_cols:\n",
    "        if c == \"run_tag\":\n",
    "            continue\n",
    "        b = base.get(c)\n",
    "        e = exp.get(c)\n",
    "        if isinstance(b, (int, float)) and isinstance(e, (int, float)):\n",
    "            rows.append({\"metric\": c, \"baseline\": float(b), \"experiment\": float(e), \"delta\": float(e - b)})\n",
    "        else:\n",
    "            # keep non-numeric too\n",
    "            rows.append({\"metric\": c, \"baseline\": b, \"experiment\": e, \"delta\": None})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def _make_delta_detail(detail_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = _ensure_question_id(detail_df)\n",
    "\n",
    "    base = df[df[\"run_tag\"] == \"baseline\"].copy()\n",
    "    exp  = df[df[\"run_tag\"] == \"experiment\"].copy()\n",
    "\n",
    "    # --- choose question column ---\n",
    "    qcol = _pick_question_col(df)\n",
    "\n",
    "    # --- metric columns ---\n",
    "    mcols = _metric_cols(df)\n",
    "\n",
    "    # --- info columns to keep (these overlap across base/exp) ---\n",
    "    info_cols = [\"__qid__\"]\n",
    "    if qcol:\n",
    "        info_cols.append(qcol)\n",
    "    for c in [\"ground_truth\", \"reference\", \"answer\", \"contexts\"]:\n",
    "        if c in df.columns:\n",
    "            info_cols.append(c)\n",
    "\n",
    "    # --- select + rename (so no overlap) ---\n",
    "    base_small = base[info_cols + mcols].copy()\n",
    "    exp_small  = exp[info_cols + mcols].copy()\n",
    "\n",
    "    rename_base = {c: f\"{c}_base\" for c in info_cols if c != \"__qid__\"}\n",
    "    rename_exp  = {c: f\"{c}_exp\"  for c in info_cols if c != \"__qid__\"}\n",
    "    rename_base.update({c: f\"{c}_base\" for c in mcols})\n",
    "    rename_exp.update({c: f\"{c}_exp\"  for c in mcols})\n",
    "\n",
    "    base_small = base_small.rename(columns=rename_base)\n",
    "    exp_small  = exp_small.rename(columns=rename_exp)\n",
    "\n",
    "    # --- merge safely ---\n",
    "    merged = exp_small.merge(base_small, on=\"__qid__\", how=\"outer\")\n",
    "\n",
    "    # --- compute deltas ---\n",
    "    for c in mcols:\n",
    "        cb = f\"{c}_base\"\n",
    "        ce = f\"{c}_exp\"\n",
    "        if cb in merged.columns and ce in merged.columns:\n",
    "            merged[f\"{c}_delta\"] = merged[ce] - merged[cb]\n",
    "\n",
    "    # --- convenience: make a unified question column (prefer exp, fallback base) ---\n",
    "    if qcol:\n",
    "        qe = f\"{qcol}_exp\"\n",
    "        qb = f\"{qcol}_base\"\n",
    "        if qe in merged.columns or qb in merged.columns:\n",
    "            merged[qcol] = None\n",
    "            if qe in merged.columns:\n",
    "                merged[qcol] = merged[qe]\n",
    "            if qb in merged.columns:\n",
    "                merged[qcol] = merged[qcol].fillna(merged[qb])\n",
    "\n",
    "    # --- order columns nicely ---\n",
    "    ordered = [\"__qid__\"]\n",
    "    if qcol and qcol in merged.columns:\n",
    "        ordered.append(qcol)\n",
    "\n",
    "    # keep references (unified view is optional; we keep exp/base separately)\n",
    "    for c in [\"ground_truth\", \"reference\"]:\n",
    "        # add unified if you want; here we keep exp/base columns only\n",
    "        pass\n",
    "\n",
    "    # metrics grouped\n",
    "    for c in mcols:\n",
    "        for suf in [\"_base\", \"_exp\", \"_delta\"]:\n",
    "            col = f\"{c}{suf}\"\n",
    "            if col in merged.columns:\n",
    "                ordered.append(col)\n",
    "\n",
    "    # then common info columns (exp/base)\n",
    "    tail_info = []\n",
    "    for c in [\"ground_truth\", \"reference\", \"answer\", \"contexts\"]:\n",
    "        ce, cb = f\"{c}_exp\", f\"{c}_base\"\n",
    "        if ce in merged.columns:\n",
    "            tail_info.append(ce)\n",
    "        if cb in merged.columns:\n",
    "            tail_info.append(cb)\n",
    "\n",
    "    remaining = [c for c in merged.columns if c not in ordered and c not in tail_info]\n",
    "    return merged[ordered + remaining + tail_info].copy()\n",
    "\n",
    "\n",
    "\n",
    "def _make_top_changes(delta_detail_df: pd.DataFrame, top_k=10) -> tuple[pd.DataFrame, pd.DataFrame, str]:\n",
    "    # choose primary metric for sorting\n",
    "    candidates = [\n",
    "        \"answer_relevancy_delta\", \"AnswerRelevancy_delta\",\n",
    "        \"faithfulness_delta\", \"Faithfulness_delta\",\n",
    "        \"context_precision_delta\", \"ContextPrecision_delta\",\n",
    "        \"context_recall_delta\", \"ContextRecall_delta\",\n",
    "    ]\n",
    "    sort_col = next((c for c in candidates if c in delta_detail_df.columns), None)\n",
    "    if sort_col is None:\n",
    "        # fallback: first *_delta numeric column\n",
    "        delta_cols = [c for c in delta_detail_df.columns if c.endswith(\"_delta\") and pd.api.types.is_numeric_dtype(delta_detail_df[c])]\n",
    "        sort_col = delta_cols[0] if delta_cols else \"\"\n",
    "\n",
    "    if not sort_col:\n",
    "        # nothing to rank\n",
    "        return pd.DataFrame(), pd.DataFrame(), \"\"\n",
    "\n",
    "    # pick minimal view columns\n",
    "    qcol = _pick_question_col(delta_detail_df)\n",
    "    view_cols = [c for c in [\"__qid__\", qcol, sort_col] if c and c in delta_detail_df.columns]\n",
    "    # add also base/exp of that metric if present\n",
    "    base_col = sort_col.replace(\"_delta\", \"_base\")\n",
    "    exp_col  = sort_col.replace(\"_delta\", \"_exp\")\n",
    "    for c in [base_col, exp_col]:\n",
    "        if c in delta_detail_df.columns and c not in view_cols:\n",
    "            view_cols.append(c)\n",
    "\n",
    "    regress = delta_detail_df.sort_values(sort_col, ascending=True).head(top_k)[view_cols].copy()\n",
    "    improve = delta_detail_df.sort_values(sort_col, ascending=False).head(top_k)[view_cols].copy()\n",
    "    return regress, improve, sort_col\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# main: compare + save (csv/json + optional snapshots)\n",
    "# ----------------------------\n",
    "def run_compare_and_save_all(\n",
    "    base_samples,\n",
    "    exp_samples,\n",
    "    project_root: Path,\n",
    "    prefix=\"ragas_compare\",\n",
    "    save_snapshots=True,\n",
    "    save_config=True,\n",
    "    save_samples_jsonl=True,\n",
    "    save_trace_jsonl=True,\n",
    "    trace_cols_priority=None,\n",
    "    save_delta_outputs=True,\n",
    "    top_k=10,\n",
    "):\n",
    "    # 1) evaluate\n",
    "    base_res, base_detail_df, base_summary_df = eval_ragas_with_details(base_samples, \"baseline\")\n",
    "    exp_res,  exp_detail_df,  exp_summary_df  = eval_ragas_with_details(exp_samples,  \"experiment\")\n",
    "\n",
    "    summary_df = pd.concat([base_summary_df, exp_summary_df], ignore_index=True)\n",
    "    detail_df  = pd.concat([base_detail_df,  exp_detail_df],  ignore_index=True)\n",
    "\n",
    "    # 2) run dir\n",
    "    run_dir, run_id, ts = _next_run_dir(project_root, prefix)\n",
    "\n",
    "    # 3) basic outputs\n",
    "    out_summary = run_dir / \"summary.csv\"\n",
    "    out_detail  = run_dir / \"detail.csv\"\n",
    "    out_meta    = run_dir / \"meta.json\"\n",
    "\n",
    "    summary_df.to_csv(out_summary, index=False, encoding=\"utf-8-sig\")\n",
    "    detail_df.to_csv(out_detail, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # --- dataset fingerprint (optional) ---\n",
    "    testset_info = None\n",
    "    if \"TESTSET_JSONL\" in globals():\n",
    "        p = Path(globals()[\"TESTSET_JSONL\"])\n",
    "        if p.exists():\n",
    "            testset_info = {\n",
    "                \"testset_path\": str(p),\n",
    "                \"testset_lines\": _count_jsonl_lines(p),\n",
    "                \"testset_sha1\": _file_sha1(p),\n",
    "            }\n",
    "\n",
    "    meta = {\n",
    "        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"run_id\": run_id,\n",
    "        \"timestamp\": ts,\n",
    "        \"run_dir\": str(run_dir),\n",
    "        \"prefix\": prefix,\n",
    "        \"n_base_samples\": len(base_samples),\n",
    "        \"n_exp_samples\": len(exp_samples),\n",
    "        \"metrics\": [getattr(m, \"__name__\", m.__class__.__name__) for m in METRICS],\n",
    "        \"llm\": {\"model\": \"solar-pro2\"},\n",
    "        \"testset\": testset_info,\n",
    "    }\n",
    "    _write_json(out_meta, meta)\n",
    "\n",
    "    # 3-1) DELTA outputs (â­ï¸ NEW)\n",
    "    extra = {}\n",
    "    if save_delta_outputs:\n",
    "        # delta_summary\n",
    "        delta_summary_df = _make_delta_summary(summary_df)\n",
    "        out_delta_summary = run_dir / \"delta_summary.csv\"\n",
    "        delta_summary_df.to_csv(out_delta_summary, index=False, encoding=\"utf-8-sig\")\n",
    "        extra[\"out_delta_summary\"] = str(out_delta_summary)\n",
    "\n",
    "        # delta_detail\n",
    "        delta_detail_df = _make_delta_detail(detail_df)\n",
    "        out_delta_detail = run_dir / \"delta_detail.csv\"\n",
    "        delta_detail_df.to_csv(out_delta_detail, index=False, encoding=\"utf-8-sig\")\n",
    "        extra[\"out_delta_detail\"] = str(out_delta_detail)\n",
    "\n",
    "        # top changes (regressions/improvements)\n",
    "        top_regress, top_improve, sort_col = _make_top_changes(delta_detail_df, top_k=top_k)\n",
    "        out_top_regress = run_dir / \"top_regressions.csv\"\n",
    "        out_top_improve = run_dir / \"top_improvements.csv\"\n",
    "        top_regress.to_csv(out_top_regress, index=False, encoding=\"utf-8-sig\")\n",
    "        top_improve.to_csv(out_top_improve, index=False, encoding=\"utf-8-sig\")\n",
    "        extra[\"out_top_regressions\"] = str(out_top_regress)\n",
    "        extra[\"out_top_improvements\"] = str(out_top_improve)\n",
    "        extra[\"top_rank_metric\"] = sort_col\n",
    "\n",
    "    # 4) optional snapshots\n",
    "    if save_snapshots:\n",
    "        # 4-1) config.json\n",
    "        if save_config:\n",
    "            cfg_payload = {\n",
    "                \"created_at\": datetime.now().isoformat(),\n",
    "                \"llm\": {\"model\": \"solar-pro2\"},\n",
    "                \"metrics\": [getattr(m, \"__name__\", m.__class__.__name__) for m in METRICS],\n",
    "                \"base_cfg\": _json_safe(globals().get(\"base_cfg\")) if \"base_cfg\" in globals() else None,\n",
    "                \"exp_cfg\":  _json_safe(globals().get(\"exp_cfg\"))  if \"exp_cfg\"  in globals() else None,\n",
    "            }\n",
    "            out_config = run_dir / \"config.json\"\n",
    "            _write_json(out_config, cfg_payload)\n",
    "            extra[\"out_config\"] = str(out_config)\n",
    "\n",
    "        # 4-2) input samples jsonl\n",
    "        if save_samples_jsonl:\n",
    "            out_samples_base = run_dir / \"samples_base.jsonl\"\n",
    "            out_samples_exp  = run_dir / \"samples_exp.jsonl\"\n",
    "            _write_jsonl(out_samples_base, base_samples)\n",
    "            _write_jsonl(out_samples_exp,  exp_samples)\n",
    "            extra[\"out_samples_base\"] = str(out_samples_base)\n",
    "            extra[\"out_samples_exp\"]  = str(out_samples_exp)\n",
    "\n",
    "        # 4-3) trace jsonl (from detail_df)\n",
    "        if save_trace_jsonl:\n",
    "            if trace_cols_priority is None:\n",
    "                trace_cols_priority = [\n",
    "                    \"id\", \"sample_id\", \"__qid__\",\n",
    "                    \"question\", \"normalized_question\", \"normalized_query\", \"query\",\n",
    "                    \"answer\", \"ground_truth\", \"reference\",\n",
    "                    \"contexts\",\n",
    "                    \"_trace\",\n",
    "                    \"retrieved_doc_ids\", \"retrieved_docs\", \"retrieval_scores\",\n",
    "                    \"rerank_selected_ids\", \"rerank_scores\",\n",
    "                    \"final_context_ids\", \"final_contexts\",\n",
    "                    \"latency_ms\", \"latency_sec\",\n",
    "                    \"run_tag\",\n",
    "                ]\n",
    "            trace_rows, used_cols = _df_to_jsonl_rows(detail_df, trace_cols_priority)\n",
    "            out_trace = run_dir / \"trace.jsonl\"\n",
    "            _write_jsonl(out_trace, trace_rows)\n",
    "            extra[\"out_trace\"] = str(out_trace)\n",
    "            extra[\"trace_cols_used\"] = used_cols\n",
    "\n",
    "    return {\n",
    "        \"base_res\": base_res,\n",
    "        \"exp_res\": exp_res,\n",
    "        \"summary_df\": summary_df,\n",
    "        \"detail_df\": detail_df,\n",
    "        \"run_dir\": str(run_dir),\n",
    "        \"out_summary\": str(out_summary),\n",
    "        \"out_detail\": str(out_detail),\n",
    "        \"out_meta\": str(out_meta),\n",
    "        **extra,\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# RUN\n",
    "# ----------------------------\n",
    "result = run_compare_and_save_all(\n",
    "    base_samples=BASE_SAMPLES,\n",
    "    exp_samples=EXP_SAMPLES,\n",
    "    project_root=PROJECT_ROOT,\n",
    "    prefix=\"ragas_compare\",\n",
    "    save_snapshots=True,\n",
    "    save_config=True,\n",
    "    save_samples_jsonl=True,\n",
    "    save_trace_jsonl=True,\n",
    "    save_delta_outputs=True,  # âœ… NEW\n",
    "    top_k=10,                 # âœ… NEW\n",
    ")\n",
    "\n",
    "print(\"âœ… run_dir:\", result[\"run_dir\"])\n",
    "print(\"âœ… saved:\", result[\"out_summary\"], result[\"out_detail\"], result[\"out_meta\"])\n",
    "\n",
    "# NEW delta outputs\n",
    "if \"out_delta_summary\" in result:\n",
    "    print(\"âœ… delta saved:\", result[\"out_delta_summary\"], result.get(\"out_delta_detail\"))\n",
    "    print(\"âœ… top changes metric:\", result.get(\"top_rank_metric\"))\n",
    "    print(\"âœ… top regressions:\", result.get(\"out_top_regressions\"))\n",
    "    print(\"âœ… top improvements:\", result.get(\"out_top_improvements\"))\n",
    "\n",
    "# snapshots\n",
    "if \"out_config\" in result:\n",
    "    print(\"âœ… extra saved config :\", result[\"out_config\"])\n",
    "if \"out_samples_base\" in result:\n",
    "    print(\"âœ… extra saved samples:\", result[\"out_samples_base\"], \"and\", result.get(\"out_samples_exp\"))\n",
    "if \"out_trace\" in result:\n",
    "    print(\"âœ… extra saved trace  :\", result[\"out_trace\"])\n",
    "    print(\"âœ… trace columns used :\", result.get(\"trace_cols_used\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6845ece-5d8b-47af-8aaf-0a1dc5ef87c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa7f586-c190-4912-a1c7-b08b1f1703db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0e570-c6a8-44d7-8628-8f2fb44c5755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df58dc-5dbf-4542-945f-0cf156a581dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ccdd3-e88b-4212-b6a2-fe100c7f1cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860dd3a7-6a46-4477-84a4-ef2861fe6829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c068515-0f85-4ef4-84dd-c22ad87302dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e96bfa9-487a-49b6-b4b1-df555cf06ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3be758-526b-4c43-a796-c5036f476881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5335ed-f34b-4677-950b-bd10cb6a0cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c55f40-ddfa-4a3a-a7dc-abd143d6eda4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97946b48-b0d8-4dd8-9a89-f6a451d7e36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d03785-23ae-4846-9368-4a45eaf6d3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab5d29-e922-4a2c-a0c0-fcb337ae36ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv chatbot_app)",
   "language": "python",
   "name": "chatbot-app-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
