{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3082f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:90% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
       "div.text_cell_render.rendered_html{font-size:12pt;}\n",
       "div.output {font-size:12pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:12pt;}\n",
       "div.prompt {min-width:70px;}}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
       "table.dataframe{font-size:12px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:90% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
    "div.text_cell_render.rendered_html{font-size:12pt;}\n",
    "div.output {font-size:12pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:12pt;}\n",
    "div.prompt {min-width:70px;}}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
    "table.dataframe{font-size:12px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8454600f",
   "metadata": {},
   "source": [
    "# 1. ê³µí†µì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f43a7f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:65: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:65: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_16380\\525142971.py:65: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  OUT_DIR = \"C:\\ai\\source\\chatbot_app\"\n",
      "C:\\ai\\source\\chatbot_app\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_16380\\525142971.py:21: DeprecationWarning: Importing answer_relevancy from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import answer_relevancy\n",
      "  from ragas.metrics import answer_relevancy as AnswerRelevancy\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_16380\\525142971.py:65: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  OUT_DIR = \"C:\\ai\\source\\chatbot_app\"\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chatbot_app.modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mragas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m faithfulness \u001b[38;5;28;01mas\u001b[39;00m Faithfulness\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_upstage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatUpstage, UpstageEmbeddings\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchatbot_app\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrag_module\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_pipeline\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mragas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrun_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunConfig\n\u001b[32m     32\u001b[39m rc = RunConfig(max_workers=\u001b[32m1\u001b[39m, timeout=\u001b[32m180\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'chatbot_app.modules'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "import gc\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "from datasets import Dataset\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from ragas import evaluate\n",
    "\n",
    "# ---- AnswerRelevancy / Faithfulness import (ragas ë²„ì „ ì°¨ì´ ëŒ€ì‘) ----\n",
    "try:\n",
    "    from ragas.metrics._answer_relevancy import AnswerRelevancy\n",
    "except Exception:\n",
    "    from ragas.metrics import answer_relevancy as AnswerRelevancy\n",
    "\n",
    "try:\n",
    "    from ragas.metrics._faithfulness import Faithfulness\n",
    "except Exception:\n",
    "    from ragas.metrics import faithfulness as Faithfulness\n",
    "\n",
    "from langchain_upstage import ChatUpstage, UpstageEmbeddings\n",
    "from chatbot_app.modules.rag_module import create_pipeline\n",
    "\n",
    "from ragas.run_config import RunConfig\n",
    "rc = RunConfig(max_workers=1, timeout=180)\n",
    "\n",
    "# ì €ì¥ëª…\n",
    "# PROMPT_TAG = \"prompt_v01\"\n",
    "\n",
    "# -----------------------------\n",
    "# LLM / Embeddings (í‰ê°€ìš©)\n",
    "# -----------------------------\n",
    "# ragasê°€ LangChain LLM wrapperë¥¼ ìš”êµ¬í•˜ëŠ” ë²„ì „ì´ ìˆì–´ì„œ ì•ˆì „í•˜ê²Œ ë˜í•‘ ì‹œë„\n",
    "try:\n",
    "    from ragas.llms import LangchainLLMWrapper\n",
    "    ragas_llm = LangchainLLMWrapper(ChatUpstage(model=\"solar-pro2\", temperature=0))\n",
    "except Exception:\n",
    "    ragas_llm = ChatUpstage(model=\"solar-pro2\", temperature=0)\n",
    "\n",
    "ragas_embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "upstage_embedding = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "print(f\"ragas_llm={type(ragas_llm)}\")\n",
    "print(f\"ragas_embeddings={type(ragas_embeddings)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics\n",
    "# -----------------------------\n",
    "def _metric_instance(m):\n",
    "    # mì´ í´ë˜ìŠ¤ë©´ m()ë¡œ ì¸ìŠ¤í„´ìŠ¤ ë§Œë“¤ê³ ,\n",
    "    # ì´ë¯¸ ì¸ìŠ¤í„´ìŠ¤/ê°ì²´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜\n",
    "    return m() if callable(m) else m\n",
    "\n",
    "\n",
    "AR_METRIC = _metric_instance(AnswerRelevancy)\n",
    "F_METRIC = _metric_instance(Faithfulness)\n",
    "\n",
    "OUT_DIR = \"C:\\ai\\source\\chatbot_app\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# ëª½í‚¤íŒ¨ì¹˜: AnswerRelevancy ì»¤ë„ í¬ë˜ì‹œ(ì„¸ê·¸í´íŠ¸) íšŒí”¼ìš©\n",
    "# - AnswerRelevancy ë‚´ë¶€ cosine similarity ê³„ì‚°ì´ numpy/BLAS ê²½ë¡œë¥¼ íƒ€ë©´\n",
    "#   Windows í™˜ê²½ì—ì„œ ë“œë¬¼ê²Œ í•˜ë“œ í¬ë˜ì‹œê°€ ë°œìƒí•  ìˆ˜ ìˆì–´,\n",
    "#   similarity ê³„ì‚°ë§Œ \"ì™„ì „ íŒŒì´ì¬\" êµ¬í˜„ìœ¼ë¡œ ìš°íšŒí•©ë‹ˆë‹¤.\n",
    "# - ë˜í•œ providers ì œì•½(Upstage: n must be 1) ë•Œë¬¸ì— strictness=1ì„ ê°•ì œí•©ë‹ˆë‹¤.\n",
    "# -----------------------------\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import ragas.metrics._answer_relevance as ar\n",
    "\n",
    "def _cos_sim(u, v, eps=1e-8):\n",
    "    # numpy dot/BLAS ì•ˆ ì“°ëŠ” ìˆœìˆ˜ íŒŒì´ì¬ ì½”ì‚¬ì¸\n",
    "    su = 0.0\n",
    "    sv = 0.0\n",
    "    s  = 0.0\n",
    "    for a, b in zip(u, v):\n",
    "        af = float(a); bf = float(b)\n",
    "        s  += af * bf\n",
    "        su += af * af\n",
    "        sv += bf * bf\n",
    "    return s / (math.sqrt(su) * math.sqrt(sv) + eps)\n",
    "\n",
    "def safe_calculate_similarity(self, question: str, generated_questions: list[str]):\n",
    "    \"\"\"\n",
    "    ragas AnswerRelevancy/ResponseRelevancyê°€ ê¸°ëŒ€í•˜ëŠ” ì‹œê·¸ë‹ˆì²˜:\n",
    "      (self, question: str, generated_questions: list[str]) -> array-like with .mean()\n",
    "    \"\"\"\n",
    "    # 1) metricì´ ë“¤ê³  ìˆëŠ” embeddings ì¡ê¸°\n",
    "    emb = None\n",
    "    for name in [\"embeddings\", \"_embeddings\", \"embedding\", \"_embedding\"]:\n",
    "        if hasattr(self, name):\n",
    "            emb = getattr(self, name)\n",
    "            if emb is not None:\n",
    "                break\n",
    "\n",
    "    if emb is None:\n",
    "        raise RuntimeError(\"AnswerRelevancy metricì— embeddingsê°€ ì„¸íŒ…ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 2) ì„ë² ë”© í•¨ìˆ˜ ì„ íƒ (syncë§Œ)\n",
    "    def embed_one(text: str):\n",
    "        if hasattr(emb, \"embed_query\"):\n",
    "            return emb.embed_query(text)\n",
    "        if hasattr(emb, \"embed_documents\"):\n",
    "            return emb.embed_documents([text])[0]\n",
    "        raise RuntimeError(\"embeddings ê°ì²´ì— embed_query/embed_documentsê°€ ì—†ìŠµë‹ˆë‹¤(ë™ê¸° ë©”ì„œë“œ í•„ìš”).\")\n",
    "\n",
    "    def embed_many(texts: list[str]):\n",
    "        if len(texts) == 0:\n",
    "            return []\n",
    "        if hasattr(emb, \"embed_documents\"):\n",
    "            return emb.embed_documents(texts)\n",
    "        # embed_queryë§Œ ìˆìœ¼ë©´ ë£¨í”„\n",
    "        if hasattr(emb, \"embed_query\"):\n",
    "            return [emb.embed_query(t) for t in texts]\n",
    "        raise RuntimeError(\"embeddings ê°ì²´ì— embed_query/embed_documentsê°€ ì—†ìŠµë‹ˆë‹¤(ë™ê¸° ë©”ì„œë“œ í•„ìš”).\")\n",
    "\n",
    "    # 3) ë¬¸ìì—´ -> ë²¡í„°\n",
    "    qv = embed_one(question)\n",
    "    gvs = embed_many(generated_questions)\n",
    "\n",
    "    if not gvs:\n",
    "        return np.array([0.0], dtype=\"float32\")\n",
    "\n",
    "    # 4) ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (BLAS ì•ˆ íƒ)\n",
    "    sims = [_cos_sim(qv, gv) for gv in gvs]\n",
    "\n",
    "    # ragasëŠ” ë’¤ì—ì„œ cosine_sim.mean()ì„ í˜¸ì¶œí•˜ë¯€ë¡œ numpy arrayë¡œ ë°˜í™˜\n",
    "    return np.array(sims, dtype=\"float32\")\n",
    "\n",
    "# âœ… í´ë˜ìŠ¤ ë©”ì„œë“œë¥¼ ë®ì–´ì¨ì•¼ í•¨ (ëª¨ë“ˆ í•¨ìˆ˜ íŒ¨ì¹˜ê°€ ì•„ë‹˜)\n",
    "ar.ResponseRelevancy.calculate_similarity = safe_calculate_similarity\n",
    "ar.AnswerRelevancy.calculate_similarity = safe_calculate_similarity\n",
    "\n",
    "# 1) ëª¨ë“ˆ ë ˆë²¨ í•¨ìˆ˜ê°€ ìˆë‹¤ë©´ __code__ êµì²´\n",
    "if ar is not None and hasattr(ar, \"calculate_similarity\"):\n",
    "    ar.calculate_similarity.__code__ = _cos_sim.__code__\n",
    "    ar.calculate_similarity.__defaults__ = _cos_sim.__defaults__\n",
    "    print(\"âœ… patched ar.calculate_similarity (__code__)\")\n",
    "elif ar is not None:\n",
    "    # 2) ëª¨ë“ˆì— ì—†ìœ¼ë©´ ì´ë¦„ ì£¼ì…(lookup ê²½ë¡œì— ë”°ë¼ ë¨¹ì„ ìˆ˜ ìˆìŒ)\n",
    "    ar.__dict__[\"calculate_similarity\"] = _cos_sim\n",
    "    print(\"âœ… injected ar.calculate_similarity\")\n",
    "\n",
    "    # 3) í´ë˜ìŠ¤ ë©”ì„œë“œë¡œ ê³„ì‚°í•˜ëŠ” ë²„ì „ ëŒ€ë¹„: ResponseRelevancy.calculate_similarityë¥¼ ë®ì–´ì“°ê¸°\n",
    "    if hasattr(ar, \"ResponseRelevancy\"):\n",
    "        try:\n",
    "            ar.ResponseRelevancy.calculate_similarity = _cos_sim\n",
    "            print(\"âœ… patched ResponseRelevancy.calculate_similarity\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# Upstage ì œì•½: n=1 ê°•ì œ\n",
    "if hasattr(AR_METRIC, \"strictness\"):\n",
    "    AR_METRIC.strictness = 1\n",
    "    print(\"âœ… AR_METRIC.strictness fixed to 1\")\n",
    "\n",
    "# -----------------------------\n",
    "# ê³µí†µ ìœ í‹¸\n",
    "# -----------------------------\n",
    "def clip_rows(rows, *, max_ctx=4, max_chars=1200, clip_answer_chars=700):\n",
    "    \"\"\"ìš”êµ¬ì‚¬í•­ ë°˜ì˜: context clip 1200 chars\"\"\"\n",
    "    clipped = []\n",
    "    for r in rows:\n",
    "        rr = dict(r)\n",
    "        ctx = rr.get(\"contexts\", []) or []\n",
    "        ctx = [c for c in ctx if c is not None]\n",
    "        rr[\"contexts\"] = [str(c)[:max_chars] for c in ctx[:max_ctx]]\n",
    "        if rr.get(\"answer\"):\n",
    "            rr[\"answer\"] = str(rr[\"answer\"])[:clip_answer_chars]\n",
    "        clipped.append(rr)\n",
    "    return clipped\n",
    "\n",
    "def cleanup_memory():\n",
    "    gc.collect()\n",
    "    print(\"ğŸ§¹ Memory cleaned\")\n",
    "\n",
    "def save_df(df: pd.DataFrame, out_path: str):\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    df.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"âœ… saved: {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "# -----------------------------\n",
    "# ì •ì„± ì²´í¬(í‰ê°€í‘œ ì»¬ëŸ¼): ê·¼ê±°í‘œí˜„/ë¬¸ì¥êµ¬ì¡°/ì¶”ë¡ í™•ì¥/ë¶ˆí™•ì‹¤ì„±\n",
    "# - ì—„ë°€í•œ metricì´ ì•„ë‹ˆë¼ \"íŒ¨í„´ íƒì§€ìš©\" ë³´ì¡° ì»¬ëŸ¼\n",
    "# -----------------------------\n",
    "_KR_EVIDENCE_PHRASES = [\"ë”°ë¥´ë©´\", \"ê·¼ê±°\", \"ì°¸ê³ \", \"ì— ë”°ë¥´ë©´\", \"ì¡°í•­\", \"ê·œì •\", \"íŒë¡€\", \"ë²•ì›\", \"ì‚¬ê±´ë²ˆí˜¸\", \"ì œ\"]\n",
    "_KR_UNCERTAINTY_PHRASES = [\"í™•ì¸ í•„ìš”\", \"ì¶”ê°€ í™•ì¸\", \"ê°€ëŠ¥\", \"ì¼ ìˆ˜\", \"ìë£Œ ë²”ìœ„\", \"ì œê³µëœ ìë£Œ\", \"ë‹¨ì •\", \"ë¶ˆëª…í™•\"]\n",
    "\n",
    "# âœ… (ìˆ˜ì •) ì¶”ë¡  ì‹ í˜¸ë¥¼ ë” ë„“ê²Œ ì¡ê¸°\n",
    "# - ë„ˆë¬´ ì¼ë°˜ì ì¸ ì ‘ì†ì‚¬ëŠ” ê³¼ê²€ì¶œ ìœ„í—˜ì´ ìˆì–´, \"ë…¼ë¦¬ ì „ê°œ/ìš”ì•½/ì›ì¸/ì¡°ê±´\" ì¤‘ì‹¬ìœ¼ë¡œ í™•ì¥\n",
    "_KR_INFERENCE_PHRASES = [\n",
    "    \"ì¼ë°˜ì ìœ¼ë¡œ\", \"í†µìƒ\", \"ë³´í†µ\", \"ëŒ€ê°œ\", \"ì¶”ì •\", \"ì›ì¹™ì ìœ¼ë¡œ\", \"ì¶”ë¡ \", \"ìƒì‹ì ìœ¼ë¡œ\",\n",
    "    \"ë”°ë¼ì„œ\", \"ê·¸ëŸ¬ë¯€ë¡œ\", \"ê·¸ë˜ì„œ\", \"ì¦‰\", \"ì •ë¦¬í•˜ë©´\", \"ìš”ì•½í•˜ë©´\", \"ê²°ë¡ ì ìœ¼ë¡œ\",\n",
    "    \"ì™œëƒí•˜ë©´\", \"ë•Œë¬¸ì—\", \"ë°˜ëŒ€ë¡œ\", \"ë§Œì•½\", \"ê²½ìš°\", \"ì „ì œ\", \"ê°€ì •\",\n",
    "    \"â†’\", \"=>\", \"ê²°ê³¼ì ìœ¼ë¡œ\", \"ì¢…í•©í•˜ë©´\",\n",
    "]\n",
    "\n",
    "def _has_any(text: str, phrases: List[str]) -> int:\n",
    "    t = text or \"\"\n",
    "    return int(any(p in t for p in phrases))\n",
    "\n",
    "# -----------------------------\n",
    "# âœ… (ìˆ˜ì •) ì²« ë¬¸ì¥ ì¶”ì¶œ: í—¤ë”(###/** ë“±) ìŠ¤í‚µ\n",
    "# -----------------------------\n",
    "_MD_HEADING_RE = re.compile(r\"^\\s{0,3}#{1,6}\\s+\")\n",
    "_MD_BOLD_TITLE_RE = re.compile(r\"^\\s*\\*\\*.+\\*\\*\\s*$\")\n",
    "_MD_LIST_TITLE_RE = re.compile(r\"^\\s*[-*â€¢]\\s+\\S+\")\n",
    "_ONLY_PUNCT_RE = re.compile(r\"^[\\s\\-\\*\\#\\=\\_]+$\")\n",
    "\n",
    "def _strip_md_bold(s: str) -> str:\n",
    "    # ** ... ** ë°”ê¹¥ í‘œì‹œ ì œê±°\n",
    "    t = s.strip()\n",
    "    if t.startswith(\"**\") and t.endswith(\"**\") and len(t) >= 4:\n",
    "        t = t[2:-2].strip()\n",
    "    return t\n",
    "\n",
    "def _looks_like_sentence(s: str) -> bool:\n",
    "    # ë¬¸ì¥ì²˜ëŸ¼ ë³´ì´ëŠ” íŒíŠ¸: ì¢…ê²°/êµ¬ë‘ì /ê¸¸ì´\n",
    "    if not s:\n",
    "        return False\n",
    "    # ë”°ì˜´í‘œ ì œê±° í›„ ì²´í¬\n",
    "    t = s.strip().strip('\"').strip(\"'\").strip(\"â€œâ€\").strip()\n",
    "    if any(p in t for p in [\".\", \"?\", \"!\", \"â€¦\"]):\n",
    "        return True\n",
    "    if any(t.endswith(end) for end in [\"í•©ë‹ˆë‹¤\", \"ë©ë‹ˆë‹¤\", \"ìˆìŠµë‹ˆë‹¤\", \"ì—†ìŠµë‹ˆë‹¤\", \"í•˜ì„¸ìš”\", \"ê¶Œí•©ë‹ˆë‹¤\", \"ê°€ëŠ¥í•©ë‹ˆë‹¤\", \"ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤\", \"ì…ë‹ˆë‹¤\"]):\n",
    "        return True\n",
    "    # ë„ˆë¬´ ì§§ìœ¼ë©´ ì œëª©ì¼ í™•ë¥ ì´ ë†’ìŒ\n",
    "    return len(t) >= 18\n",
    "\n",
    "def _first_meaningful_line(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    lines = text.splitlines()\n",
    "    for line in lines:\n",
    "        s = (line or \"\").strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        if _ONLY_PUNCT_RE.match(s):\n",
    "            continue\n",
    "        if _MD_HEADING_RE.match(s):\n",
    "            continue\n",
    "\n",
    "        # âœ… (í•µì‹¬ ìˆ˜ì •) êµµì€ ê¸€ì”¨ ë¼ì¸ì€ ë¬´ì¡°ê±´ ìŠ¤í‚µí•˜ì§€ ì•ŠëŠ”ë‹¤\n",
    "        if _MD_BOLD_TITLE_RE.match(s):\n",
    "            inner = _strip_md_bold(s)\n",
    "            # innerê°€ ì‹¤ì œ ë¬¸ì¥(ê²°ë¡ )ì²˜ëŸ¼ ë³´ì´ë©´ ì±„íƒ\n",
    "            if _looks_like_sentence(inner):\n",
    "                return inner\n",
    "            # ì•„ë‹ˆë©´ ì„¹ì…˜ íƒ€ì´í‹€ë¡œ ë³´ê³  ìŠ¤í‚µ\n",
    "            continue\n",
    "\n",
    "        if _MD_LIST_TITLE_RE.match(s) and any(k in s for k in [\"ê²°ë¡ \", \"ìš”ì•½\", \"ì •ë¦¬\", \"ê·¼ê±°\", \"ì²´í¬ë¦¬ìŠ¤íŠ¸\", \"ì ˆì°¨\", \"ì¦ë¹™\", \"ì¶”ê°€ í™•ì¸\", \"í™•ì¸ ì§ˆë¬¸\"]):\n",
    "            continue\n",
    "\n",
    "        return s\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def _first_sentence(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    line = _first_meaningful_line(text)\n",
    "    if not line:\n",
    "        return \"\"\n",
    "    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°\n",
    "    for sep in [\".\", \"?\", \"!\"]:\n",
    "        if sep in line:\n",
    "            return line.split(sep, 1)[0].strip()\n",
    "    return line.strip()\n",
    "\n",
    "_CONCLUSION_HEADER_RE = re.compile(r\"(í•œ\\s*ì¤„\\s*ê²°ë¡ |^A\\.\\s*í•œ\\s*ì¤„\\s*ê²°ë¡ |^A\\.\\s*ê²°ë¡ |^ê²°ë¡ )\", re.IGNORECASE)\n",
    "\n",
    "def _extract_conclusion_line(answer: str) -> str:\n",
    "    if not answer:\n",
    "        return \"\"\n",
    "    lines = answer.splitlines()\n",
    "\n",
    "    # 1) \"í•œ ì¤„ ê²°ë¡ \" ì„¹ì…˜ì„ ì°¾ê³ , ê·¸ ì•„ë˜ì—ì„œ ì²« ë¬¸ì¥ í›„ë³´ë¥¼ ë½‘ê¸°\n",
    "    for i, line in enumerate(lines):\n",
    "        s = (line or \"\").strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        # í—¤ë” í‘œì‹ ì œê±° í›„ì—ë„ \"í•œ ì¤„ ê²°ë¡ \"ì¸ì§€ í™•ì¸\n",
    "        s2 = s.lstrip(\"#\").strip()\n",
    "        if _CONCLUSION_HEADER_RE.search(s2):\n",
    "            # ì•„ë˜ 1~4ì¤„ì—ì„œ ì˜ë¯¸ìˆëŠ” ë¬¸ì¥ ì°¾ê¸°\n",
    "            for j in range(i + 1, min(i + 6, len(lines))):\n",
    "                cand = (lines[j] or \"\").strip()\n",
    "                if not cand:\n",
    "                    continue\n",
    "                # êµµê²Œ ê°ì‹¸ì§„ ê²½ìš° ë‚´ë¶€ë§Œ\n",
    "                if cand.startswith(\"**\") and cand.endswith(\"**\") and len(cand) >= 4:\n",
    "                    cand = cand[2:-2].strip()\n",
    "                cand = cand.strip().strip('\"').strip(\"'\").strip(\"â€œâ€\").strip()\n",
    "                # ì œëª©/êµ¬ë¶„ì„ ë§Œ ìˆìœ¼ë©´ ìŠ¤í‚µ\n",
    "                if _MD_HEADING_RE.match(cand) or _ONLY_PUNCT_RE.match(cand):\n",
    "                    continue\n",
    "                return cand\n",
    "            break\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def _looks_conclusion_first(answer: str) -> int:\n",
    "    # 1ìˆœìœ„: í•œ ì¤„ ê²°ë¡  ì„¹ì…˜ ê¸°ë°˜\n",
    "    c = _extract_conclusion_line(answer)\n",
    "    if c:\n",
    "        # ê²°ë¡  ì¤„ì´ ë„ˆë¬´ ì§§ì€ ì œëª©ì´ë©´ ì œì™¸\n",
    "        if len(c) >= 8:\n",
    "            return 1\n",
    "\n",
    "    # 2ìˆœìœ„: ê¸°ì¡´ í´ë°±\n",
    "    s1 = _first_sentence(answer)\n",
    "    if not s1:\n",
    "        return 0\n",
    "\n",
    "    t = s1.strip().strip('\"').strip(\"'\").strip(\"â€œâ€\").strip()\n",
    "    # ë„ˆë¬´ ì§§ìœ¼ë©´ ì œëª© ê°€ëŠ¥ì„±\n",
    "    if len(t) < 8:\n",
    "        return 0\n",
    "\n",
    "    # ê°•í•œ ì¢…ê²°/ê¶Œê³  ì‹ í˜¸\n",
    "    if any(k in t for k in [\"ê°€ëŠ¥\", \"ë¶ˆê°€ëŠ¥\", \"í•„ìˆ˜\", \"ì¤‘ìš”\", \"ê¶Œì¥\", \"ì¶”ì²œ\", \"ìœ„í—˜\", \"ìœ ë¦¬\", \"ë¶ˆë¦¬\"]):\n",
    "        return 1\n",
    "    if any(t.endswith(e) for e in [\"í•©ë‹ˆë‹¤\", \"ë©ë‹ˆë‹¤\", \"ì…ë‹ˆë‹¤\", \"í•´ì•¼ í•©ë‹ˆë‹¤\", \"í•„ìš”í•©ë‹ˆë‹¤\", \"ì¤‘ìš”í•©ë‹ˆë‹¤\"]):\n",
    "        return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "def _norm_ws(s: str) -> str:\n",
    "    # ê³µë°±/ì¤„ë°”ê¿ˆ/ë”°ì˜´í‘œ ì •ë¦¬ + ë‹¤ì¤‘ ê³µë°± ì¶•ì†Œ\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    t = str(s)\n",
    "    t = t.replace(\"â€œ\", '\"').replace(\"â€\", '\"').replace(\"â€™\", \"'\")\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "def _norm_article(art: str) -> str:\n",
    "    # \"ì œ 30 ì¡°\", \"ì œ30ì¡°\", \"30ì¡°\" -> \"ì œ30ì¡°\" í˜•íƒœë¡œ í†µì¼\n",
    "    if not art:\n",
    "        return \"\"\n",
    "    t = re.sub(r\"\\s+\", \"\", str(art))\n",
    "    if re.match(r\"^\\d+ì¡°\", t):  # \"30ì¡°\" í˜•íƒœë©´\n",
    "        t = \"ì œ\" + t\n",
    "    # \"ì œ3ì¡°ì˜2\"ë„ ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "    return t\n",
    "\n",
    "def _hallucinated_citation_flag(answer: str, contexts: List[str]) -> int:\n",
    "    \"\"\"\n",
    "    âœ… ê°œì„ íŒ:\n",
    "    - ë‹µë³€ì—ì„œ ì¡°ë¬¸ í† í°(ì œNNì¡°/ì œNNì¡°ì˜M)ì„ ë½‘ê³ \n",
    "    - ì»¨í…ìŠ¤íŠ¸ì— ê°™ì€ ì¡°ë¬¸ í† í°ì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ 1(ì˜ì‹¬), ìˆìœ¼ë©´ 0\n",
    "    - ê³µë°± ì°¨ì´ ë•Œë¬¸ì— ì˜¤íƒ ë‚˜ëŠ” ê²ƒ ë°©ì§€\n",
    "    \"\"\"\n",
    "    if not answer:\n",
    "        return 0\n",
    "\n",
    "    ctx_all = _norm_ws(\"\\n\".join(contexts or []))\n",
    "    if not ctx_all:\n",
    "        # ì»¨í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ 'ì—†ëŠ” ì¡°ë¬¸'ì´ë¼ê¸°ë³´ë‹¤ 'ë¹„êµ ë¶ˆê°€'ì— ê°€ê¹ì§€ë§Œ,\n",
    "        # ê¸°ì¡´ ì˜ë¯¸ë¥¼ ìœ ì§€í•˜ë ¤ë©´ 1ë¡œ ë‘ëŠ” ê²Œ ì•ˆì „.\n",
    "        return 1\n",
    "\n",
    "    # ë‹µë³€ì—ì„œ ì¡°ë¬¸ë§Œ ì¶”ì¶œ (law nameê¹Œì§€ ë¬¶ì§€ ì•ŠìŒ)\n",
    "    arts = re.findall(r\"(ì œ?\\s*\\d+\\s*ì¡°(?:\\s*ì˜\\s*\\d+)?)\", answer)\n",
    "    if not arts:\n",
    "        return 0\n",
    "\n",
    "    arts_norm = {_norm_article(a) for a in arts if _norm_article(a)}\n",
    "    if not arts_norm:\n",
    "        return 0\n",
    "\n",
    "    ctx_nospace = _norm_article(ctx_all)  # ê³µë°± ì œê±°í•œ ë²„ì „ìœ¼ë¡œë„ ë¹„êµ\n",
    "    # í•˜ë‚˜ë¼ë„ ì»¨í…ìŠ¤íŠ¸ì— ìˆìœ¼ë©´ ì˜ì‹¬ ì•„ë‹˜\n",
    "    for a in arts_norm:\n",
    "        if a in ctx_all or a in ctx_nospace:\n",
    "            return 0\n",
    "    return 1\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# ì •ê·œí™” ê²°ê³¼ â€œ1ì¤„ ê°•ì œâ€ ìœ í‹¸\n",
    "# (ì£¼ì˜: ì§€ê¸ˆ íŒ¨ì¹˜ëŠ” trace ì €ì¥ê°’ë§Œ 1ì¤„ë¡œ ë§Œë“¤ê³ , pipeline ë‚´ë¶€ retrieval queryì—ëŠ” ì˜í–¥ì„ ì£¼ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "#        pipeline ë‚´ë¶€ì— ì ìš©í•˜ë ¤ë©´ rag_module.py ì¿¼ë¦¬ ìƒì„± ì§ì „ì— ë™ì¼ ë¡œì§ì„ ë„£ì–´ì•¼ í•©ë‹ˆë‹¤.)\n",
    "# -----------------------------\n",
    "def sanitize_normalized_query(text: str, max_chars: int = 400) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    first = text.strip().splitlines()[0].strip()\n",
    "    return first[:max_chars]\n",
    "\n",
    "# âœ… ë°ì´í„° ê²€ì¦ í•¨ìˆ˜ ì¶”ê°€\n",
    "def validate_data(rows, required_fields):\n",
    "    \"\"\"ë°ì´í„° ê²€ì¦ ë° ë¬¸ì œ ë¦¬í¬íŠ¸\"\"\"\n",
    "    issues = []\n",
    "    for i, r in enumerate(rows):\n",
    "        for field in required_fields:\n",
    "            if field not in r:\n",
    "                issues.append(f\"Row {i}: missing field '{field}'\")\n",
    "            elif r[field] is None:\n",
    "                issues.append(f\"Row {i}: field '{field}' is None\")\n",
    "            elif field in [\"question\", \"answer\"] and not str(r[field]).strip():\n",
    "                issues.append(f\"Row {i}: field '{field}' is empty\")\n",
    "\n",
    "    if issues:\n",
    "        print(\"âš ï¸ Data validation issues:\")\n",
    "        for issue in issues[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥\n",
    "            print(f\"  - {issue}\")\n",
    "        if len(issues) > 10:\n",
    "            print(f\"  ... and {len(issues) - 10} more issues\")\n",
    "    else:\n",
    "        print(\"âœ… Data validation passed\")\n",
    "\n",
    "    return len(issues) == 0\n",
    "\n",
    "# -----------------------------\n",
    "# ì¶”ê°€ ì»¬ëŸ¼ ê³„ì‚° í•¨ìˆ˜\n",
    "# - âœ… (ìš”êµ¬ ë°˜ì˜) í™•ì¸ì§ˆë¬¸ ë¡œì§ ì‚­ì œ: has_questions_2plus ê´€ë ¨ ëª¨ë‘ ì œê±°\n",
    "# -----------------------------\n",
    "_RE_ARTICLE = re.compile(r\"ì œ\\s*\\d+\\s*ì¡°(?:\\s*ì˜\\s*\\d+)?\")  # 'ì œ 30 ì¡°', 'ì œ3ì¡°ì˜2' ë³€í˜• ëŒ€ì‘\n",
    "_RE_BULLET = re.compile(r\"(^|\\n)\\s*[-*â€¢]\\s+\")\n",
    "\n",
    "def _to_context_list(x):\n",
    "    \"\"\"contextsë¥¼ list[str]ë¡œ ì •ê·œí™”.\"\"\"\n",
    "    if x is None:\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return [str(s) for s in x if s is not None and str(s).strip()]\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    parts = [p.strip() for p in re.split(r\"\\n\\s*\\n\", s) if p.strip()]\n",
    "    return parts if parts else [s]\n",
    "\n",
    "# -----------------------------\n",
    "# ì‹¤í–‰ íƒœê·¸ / ë””ë ‰í† ë¦¬\n",
    "# -----------------------------\n",
    "def make_run_tag_for_answer(model_name: str) -> str:\n",
    "    return f\"llmcmp_{model_name}\"\n",
    "\n",
    "RUNS_ROOT = os.path.join(OUT_DIR, \"runs_answer\")\n",
    "os.makedirs(RUNS_ROOT, exist_ok=True)\n",
    "\n",
    "def add_prompt_eval_columns(\n",
    "    df: pd.DataFrame,\n",
    "    answer_col: str = \"answer\",\n",
    "    contexts_col: str = \"contexts\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    dfì— ì•„ë˜ ì»¬ëŸ¼ ì¶”ê°€ (í™•ì¸ì§ˆë¬¸ ë¡œì§ ì‚­ì œ ë°˜ì˜):\n",
    "    - has_todo_checklist\n",
    "    - has_legal_basis\n",
    "    - citation_count_like\n",
    "    - n_contexts\n",
    "    - ctx_total_chars\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    answers = df[answer_col].fillna(\"\").astype(str) if answer_col in df.columns else pd.Series([\"\"] * len(df))\n",
    "    ctxs = df[contexts_col] if contexts_col in df.columns else pd.Series([[]] * len(df))\n",
    "\n",
    "    # 1) ì§€ê¸ˆ ë‹¹ì¥ í•  ì¼/ì²´í¬ë¦¬ìŠ¤íŠ¸ ì¡´ì¬ ì—¬ë¶€ (ì„¹ì…˜ í‚¤ì›Œë“œ OR ë¶ˆë¦¿ 2ê°œ ì´ìƒ)\n",
    "    def has_todo(a: str) -> int:\n",
    "        if not a:\n",
    "            return 0\n",
    "        key = (\"ì§€ê¸ˆ ë‹¹ì¥\" in a) or (\"í•  ì¼\" in a) or (\"ì²´í¬ë¦¬ìŠ¤íŠ¸\" in a)\n",
    "        bullets = len(_RE_BULLET.findall(a)) >= 2\n",
    "        return int(key or bullets)\n",
    "\n",
    "    # 2) ë²•ì  ê·¼ê±° ì„¹ì…˜ ì¡´ì¬ ì—¬ë¶€ (í‚¤ì›Œë“œ + ì¡°ë¬¸ íŒ¨í„´ 1ê°œ ì´ìƒ)\n",
    "    def has_basis(a: str) -> int:\n",
    "        if not a:\n",
    "            return 0\n",
    "        key = (\"ë²•ì  ê·¼ê±°\" in a) or (\"ê·¼ê±°\" in a) or (\"ì¡°ë¬¸\" in a)\n",
    "        art = len(_RE_ARTICLE.findall(a)) >= 1\n",
    "        return int(key and art)\n",
    "\n",
    "    # 3) ì¡°ë¬¸ ì¸ìš© íŒ¨í„´ ê°œìˆ˜(ìœ ì‚¬ ì¸ìš© ê°œìˆ˜)\n",
    "    def citation_like(a: str) -> int:\n",
    "        if not a:\n",
    "            return 0\n",
    "        return len(_RE_ARTICLE.findall(a))\n",
    "\n",
    "    # 4) ì»¨í…ìŠ¤íŠ¸ ê°œìˆ˜ / 5) ì»¨í…ìŠ¤íŠ¸ ì´ ê¸¸ì´\n",
    "    n_contexts = []\n",
    "    ctx_chars = []\n",
    "    for x in ctxs:\n",
    "        lst = _to_context_list(x)\n",
    "        n_contexts.append(len(lst))\n",
    "        ctx_chars.append(sum(len(s) for s in lst))\n",
    "\n",
    "    df[\"has_todo_checklist\"] = [has_todo(a) for a in answers]\n",
    "    df[\"has_legal_basis\"] = [has_basis(a) for a in answers]\n",
    "    df[\"citation_count_like\"] = [citation_like(a) for a in answers]\n",
    "    df[\"n_contexts\"] = n_contexts\n",
    "    df[\"ctx_total_chars\"] = ctx_chars\n",
    "\n",
    "    return df\n",
    "\n",
    "# -----------------------------\n",
    "# run_once_answer: AnswerRelevancy / Faithfulness 1íšŒ\n",
    "# -----------------------------\n",
    "def run_once_answer(\n",
    "    pipeline,\n",
    "    items: List[Dict[str, Any]],\n",
    "    run_idx: int,\n",
    "    llm_name: str = \"solar-pro2\",\n",
    ") -> Dict[str, Any]:\n",
    "    run_tag = make_run_tag_for_answer(llm_name)\n",
    "    run_dir = os.path.join(RUNS_ROOT, run_tag, f\"run_{run_idx:02d}\")\n",
    "\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "    # prompt_tag = PROMPT_TAG\n",
    "    # with open(os.path.join(run_dir, \"prompt_tag.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    #     f.write(prompt_tag + \"\\n\")\n",
    "\n",
    "    cache_jsonl = os.path.join(run_dir, \"rag_run_cache.jsonl\")\n",
    "    print(f\"--- run_once_answer START | run_idx={run_idx} | llm_name={llm_name} ---\")\n",
    "\n",
    "    # (1) íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼ ìºì‹œ ì €ì¥\n",
    "    with open(cache_jsonl, \"w\", encoding=\"utf-8\") as f:\n",
    "        print(f\"items={len(items)}\")\n",
    "        for i, ex in enumerate(items, start=1):\n",
    "            q = ex[\"question\"]\n",
    "            gt = ex.get(\"ground_truth\", \"\")\n",
    "\n",
    "            MAX_QUERY_CHARS = 2000\n",
    "            q_for_retrieval = q if len(q) <= MAX_QUERY_CHARS else q[:MAX_QUERY_CHARS]\n",
    "\n",
    "            try:\n",
    "                trace = pipeline.answer_with_trace(q_for_retrieval, skip_normalization=False)\n",
    "                if \"normalized_query\" in trace:\n",
    "                    trace[\"normalized_query\"] = sanitize_normalized_query(trace.get(\"normalized_query\", \"\"))\n",
    "            except Exception as e:\n",
    "                trace = {\"answer\": \"\", \"docs\": [], \"normalized_query\": \"\"}\n",
    "\n",
    "            answer = trace.get(\"answer\", \"\") or \"\"\n",
    "            docs = trace.get(\"docs\", []) or []\n",
    "\n",
    "            contexts = []\n",
    "            for d in docs:\n",
    "                try:\n",
    "                    contexts.append(d.page_content)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            row = {\n",
    "                \"id\": i,\n",
    "                \"question\": q,\n",
    "                \"answer\": answer,\n",
    "                \"contexts\": contexts,\n",
    "                \"reference\": gt,\n",
    "                \"ground_truths\": [gt],\n",
    "                \"normalized_query\": trace.get(\"normalized_query\", \"\"),\n",
    "            }\n",
    "            f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    # (2) rows ë¡œë“œ + ìµœì†Œ ì •ë¦¬\n",
    "    raw_rows = []\n",
    "    with open(cache_jsonl, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                raw_rows.append(json.loads(line))\n",
    "\n",
    "    rows_local = []\n",
    "    for r in raw_rows:\n",
    "        rr = dict(r)\n",
    "        if not rr.get(\"question\"):\n",
    "            continue\n",
    "        if not rr.get(\"answer\"):\n",
    "            rr[\"answer\"] = \"ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        if \"contexts\" not in rr or rr[\"contexts\"] is None:\n",
    "            rr[\"contexts\"] = []\n",
    "        if not isinstance(rr[\"contexts\"], list):\n",
    "            rr[\"contexts\"] = [str(rr[\"contexts\"])]\n",
    "        rows_local.append(rr)\n",
    "\n",
    "    validate_data(rows_local, required_fields=[\"question\", \"answer\", \"contexts\"])\n",
    "\n",
    "    # (3) clip (ìš”êµ¬ì‚¬í•­: max_chars=1200)\n",
    "    rows_eval = clip_rows(rows_local, max_ctx=4, max_chars=1200, clip_answer_chars=700)\n",
    "\n",
    "    ds = Dataset.from_list(\n",
    "        [\n",
    "            {\n",
    "                \"question\": r[\"question\"],\n",
    "                \"answer\": r[\"answer\"],\n",
    "                \"contexts\": r.get(\"contexts\", []),\n",
    "                \"reference\": r.get(\"reference\", \"\"),\n",
    "            }\n",
    "            for r in rows_eval\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # (4) RAGAS í‰ê°€\n",
    "    print(f\"evaluate START | run_idx={run_idx}\")\n",
    "    import sys, ragas.metrics._answer_relevance as ar\n",
    "\n",
    "    print(\"ar module id:\", id(ar))\n",
    "    print(\"calc filename:\", ar.calculate_similarity.__code__.co_filename)\n",
    "    print(\"in sys.modules:\", sys.modules.get(\"ragas.metrics._answer_relevance\") is ar)\n",
    "\n",
    "    AR_METRIC.strictness = 1\n",
    "    res = evaluate(\n",
    "        dataset=ds,\n",
    "        metrics=[AR_METRIC, F_METRIC],\n",
    "        llm=ragas_llm,\n",
    "        embeddings=ragas_embeddings,\n",
    "        run_config=rc,\n",
    "        show_progress=True,\n",
    "        raise_exceptions=True,\n",
    "        batch_size=1,\n",
    "    )\n",
    "\n",
    "    print(\"evaluate RETURNED\")\n",
    "    df = res.to_pandas()\n",
    "    print(\"to_pandas DONE\")\n",
    "\n",
    "    # id ì»¬ëŸ¼ ë³´ì •\n",
    "    if \"id\" not in df.columns:\n",
    "        df = df.copy()\n",
    "        df[\"id\"] = range(1, len(df) + 1)\n",
    "\n",
    "    # (5) ì •ì„± ì²´í¬ ì»¬ëŸ¼ ì¶”ê°€\n",
    "    id_to_ctx = {i + 1: rows_eval[i].get(\"contexts\", []) for i in range(len(rows_eval))}\n",
    "    id_to_ans = {i + 1: rows_eval[i].get(\"answer\", \"\") for i in range(len(rows_eval))}\n",
    "\n",
    "    # âœ… RAGAS ê²°ê³¼ dfì—ëŠ” answer/contextsê°€ ì—†ìœ¼ë¯€ë¡œ rows_evalì—ì„œ ë‹¤ì‹œ ë¶™ì„\n",
    "    df[\"answer\"] = df[\"id\"].map(lambda _id: id_to_ans.get(_id, \"\"))\n",
    "    df[\"contexts\"] = df[\"id\"].map(lambda _id: id_to_ctx.get(_id, []))\n",
    "\n",
    "    df[\"evidence_expression\"] = df[\"id\"].map(lambda _id: _has_any(id_to_ans.get(_id, \"\"), _KR_EVIDENCE_PHRASES))\n",
    "    df[\"structure_conclusion_first\"] = df[\"id\"].map(lambda _id: _looks_conclusion_first(id_to_ans.get(_id, \"\")))\n",
    "    df[\"inference_expansion_signal\"] = df[\"id\"].map(lambda _id: _has_any(id_to_ans.get(_id, \"\"), _KR_INFERENCE_PHRASES))\n",
    "    df[\"uncertainty_signal\"] = df[\"id\"].map(lambda _id: _has_any(id_to_ans.get(_id, \"\"), _KR_UNCERTAINTY_PHRASES))\n",
    "    df[\"hallucinated_citation_suspect\"] = df[\"id\"].map(\n",
    "        lambda _id: _hallucinated_citation_flag(id_to_ans.get(_id, \"\"), id_to_ctx.get(_id, []))\n",
    "    )\n",
    "\n",
    "    df = add_prompt_eval_columns(df, answer_col=\"answer\", contexts_col=\"contexts\")\n",
    "\n",
    "    # ì»¬ëŸ¼ëª… í•œê¸€ë¡œ ë³€ê²½ (ë³´ê¸° í¸í•˜ê²Œ)\n",
    "    RENAME_COLS_KR = {\n",
    "        \"evidence_expression\": \"ê·¼ê±°í‘œí˜„ìœ ë¬´\",\n",
    "        \"structure_conclusion_first\": \"ë‘ê´„ì‹\",\n",
    "        \"inference_expansion_signal\": \"ì¶”ê°€ì¶”ë¡ ìœ ë¬´\",\n",
    "        \"uncertainty_signal\": \"ì•ˆì „í‘œí˜„ìœ ë¬´\",\n",
    "        \"hallucinated_citation_suspect\": \"ì—†ëŠ”ì¡°ë¬¸ì˜ì‹¬\",\n",
    "        \"has_todo_checklist\": \"ì²´í¬ë¦¬ìŠ¤íŠ¸\",\n",
    "        \"has_legal_basis\": \"ë²•ì ê·¼ê±°ì„¹ì…˜\",\n",
    "        \"citation_count_like\": \"ë‹µë³€ë‚´ì¡°ë¬¸ê°¯ìˆ˜\",\n",
    "        \"n_contexts\": \"ì»¨í…ìŠ¤íŠ¸ê°œìˆ˜\",\n",
    "        \"ctx_total_chars\": \"ì»¨í…ìŠ¤íŠ¸ê¸¸ì´\",\n",
    "    }\n",
    "    df = df.rename(columns=RENAME_COLS_KR)\n",
    "\n",
    "    # (ì €ì¥1) ragas raw\n",
    "    out_raw = os.path.join(run_dir, \"ragas_result_answer_faith.csv\")\n",
    "    save_df(df, out_raw)\n",
    "\n",
    "    # (ì €ì¥2) per_question (ë³´ê¸° ì¢‹ì€ í‰ê°€í‘œ)\n",
    "    perq_cols = [\n",
    "        \"id\",\n",
    "        \"answer\",\n",
    "        \"contexts\",\n",
    "        \"answer_relevancy\",\n",
    "        \"faithfulness\",\n",
    "        \"ê·¼ê±°í‘œí˜„ìœ ë¬´\",\n",
    "        \"ë‘ê´„ì‹\",\n",
    "        \"ì¶”ê°€ì¶”ë¡ ìœ ë¬´\",\n",
    "        \"ì•ˆì „í‘œí˜„ìœ ë¬´\",\n",
    "        \"ì—†ëŠ”ì¡°ë¬¸ì˜ì‹¬\",\n",
    "        \"ì²´í¬ë¦¬ìŠ¤íŠ¸\",\n",
    "        \"ë²•ì ê·¼ê±°ì„¹ì…˜\",\n",
    "        \"ë‹µë³€ë‚´ì¡°ë¬¸ê°¯ìˆ˜\",\n",
    "        \"ì»¨í…ìŠ¤íŠ¸ê°œìˆ˜\",\n",
    "        \"ì»¨í…ìŠ¤íŠ¸ê¸¸ì´\",\n",
    "    ]\n",
    "\n",
    "    # âœ… ì‹¤ì œ dfì— ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ (metricsë¥¼ ë°”ê¿”ë„ KeyError ë°©ì§€)\n",
    "    _cols_exist = [c for c in perq_cols if c in df.columns]\n",
    "    perq = df[_cols_exist].copy()\n",
    "\n",
    "    for c in [\"answer_relevancy\", \"faithfulness\"]:\n",
    "        if c in perq.columns:\n",
    "            perq[c] = perq[c].astype(float).round(3)\n",
    "\n",
    "    # ë§ˆì§€ë§‰ í–‰ì— ì „ì²´ í‰ê· (ìˆ«ì ì»¬ëŸ¼ë§Œ í‰ê· )\n",
    "    numeric_cols = perq.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    mean_row = {c: perq[c].mean() for c in numeric_cols}\n",
    "    mean_row[\"id\"] = \"mean\"\n",
    "    perq = pd.concat([perq, pd.DataFrame([mean_row])], ignore_index=True)\n",
    "\n",
    "    perq_csv = os.path.join(run_dir, \"per_question.csv\")\n",
    "    save_df(perq, perq_csv)\n",
    "\n",
    "    print(f\"saved per_question_csv={perq_csv}\")\n",
    "    print(f\"--- run_once_answer DONE | run_idx={run_idx} ---\")\n",
    "    cleanup_memory()\n",
    "\n",
    "    # mean í–‰ ì œì™¸í•œ í†µê³„\n",
    "    perq_metrics_only = perq[perq[\"id\"] != \"mean\"].copy()\n",
    "\n",
    "    return {\n",
    "        \"run_tag\": run_tag,\n",
    "        \"run_idx\": run_idx,\n",
    "        \"run_dir\": run_dir,\n",
    "        \"cache_jsonl\": cache_jsonl,\n",
    "        \"raw_csv\": out_raw,\n",
    "        \"per_question_csv\": perq_csv,\n",
    "        \"AR_mean\": float(perq_metrics_only[\"answer_relevancy\"].mean()),\n",
    "        \"AR_std\": float(perq_metrics_only[\"answer_relevancy\"].std(ddof=1)) if len(perq_metrics_only) > 1 else 0.0,\n",
    "        \"F_mean\": float(perq_metrics_only[\"faithfulness\"].mean()),\n",
    "        \"F_std\": float(perq_metrics_only[\"faithfulness\"].std(ddof=1)) if len(perq_metrics_only) > 1 else 0.0,\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# ë°˜ë³µ ì‹¤í–‰(run_repeat_answer) + wide CSV\n",
    "# -----------------------------\n",
    "def run_repeat_answer(pipeline, items: List[Dict[str, Any]], n: int = 3, llm_name: str = \"solar-pro2\") -> List[Dict[str, Any]]:\n",
    "    results = []\n",
    "    for run_idx in range(1, n + 1):\n",
    "        print(\"\\n==============================\")\n",
    "        print(f\"RUN {run_idx:02d}/{n} | {make_run_tag_for_answer(llm_name)}\")\n",
    "        print(\"==============================\")\n",
    "        results.append(run_once_answer(pipeline, items, run_idx, llm_name=llm_name))\n",
    "    return results\n",
    "\n",
    "def build_wide_csv_answer(run_tag: str, results: List[Dict[str, Any]], n_questions: int) -> str:\n",
    "    \"\"\"\n",
    "    ë©”ëª¨ë¦¬ ì•ˆì •ì„±ì„ ìœ„í•´ ê²°ê³¼ dictì— df_perqë¥¼ ì €ì¥í•˜ì§€ ì•Šê³ ,\n",
    "    per_question_csvë¥¼ ë‹¤ì‹œ ì½ì–´ì„œ wideë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    base_dir = os.path.join(RUNS_ROOT, run_tag)\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    ids = pd.DataFrame({\"id\": range(1, n_questions + 1)})\n",
    "    wide = ids.copy()\n",
    "\n",
    "    for res in results:\n",
    "        ridx = res[\"run_idx\"]\n",
    "        dfm = pd.read_csv(res[\"per_question_csv\"])[[\n",
    "            \"id\",\n",
    "            \"answer_relevancy\",\n",
    "            \"faithfulness\",\n",
    "            \"ì—†ëŠ”ì¡°ë¬¸ì˜ì‹¬\",  # âœ… í•œê¸€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€ê²½ ë°˜ì˜\n",
    "        ]].copy()\n",
    "\n",
    "        dfm = dfm.rename(columns={\n",
    "            \"answer_relevancy\": f\"r{ridx}-answer_relevancy\",\n",
    "            \"faithfulness\": f\"r{ridx}-faithfulness\",\n",
    "            \"ì—†ëŠ”ì¡°ë¬¸ì˜ì‹¬\": f\"r{ridx}-ì—†ëŠ”ì¡°ë¬¸ì˜ì‹¬\",\n",
    "        })\n",
    "        wide = pd.merge(wide, dfm, on=\"id\", how=\"left\")\n",
    "\n",
    "    wide = wide.set_index(\"id\").sort_index()\n",
    "\n",
    "    ar_cols = [c for c in wide.columns if c.endswith(\"-answer_relevancy\")]\n",
    "    f_cols = [c for c in wide.columns if c.endswith(\"-faithfulness\")]\n",
    "\n",
    "    wide[\"answer_relevancy-mean\"] = wide[ar_cols].mean(axis=1, skipna=True)\n",
    "    wide[\"faithfulness-mean\"] = wide[f_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "    mean_row = wide.mean(axis=0, skipna=True).to_frame().T\n",
    "    mean_row.index = [\"mean\"]\n",
    "    wide2 = pd.concat([wide, mean_row], axis=0)\n",
    "\n",
    "    out_csv = os.path.join(base_dir, \"runs_wide_3repeats.csv\")\n",
    "    wide2.to_csv(out_csv, encoding=\"utf-8\")\n",
    "    print(\"âœ… saved:\", out_csv)\n",
    "    return out_csv\n",
    "\n",
    "# -----------------------------\n",
    "# DOCX ì§ˆë¬¸ ë¡œë”©\n",
    "# -----------------------------\n",
    "from docx import Document\n",
    "\n",
    "DOCX_PATH = \"C:\\ai\\source\\chatbot_app\\ragas_testset_10_selected.jsonl\"\n",
    "\n",
    "def load_items_from_docx(docx_path: str, max_q: int = 10):\n",
    "    doc = Document(docx_path)\n",
    "    paras = [p.text.strip() for p in doc.paragraphs if p.text and p.text.strip()]\n",
    "\n",
    "    items = []\n",
    "    i = 0\n",
    "    while i < len(paras) and len(items) < max_q:\n",
    "        line = paras[i]\n",
    "        m = re.match(r\"^(\\d+)\\.\\s*(.+)$\", line)\n",
    "        if not m:\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        question = m.group(2).strip()\n",
    "\n",
    "        i += 1\n",
    "        answer_lines = []\n",
    "        while i < len(paras):\n",
    "            if re.match(r\"^\\d+\\.\\s*.+$\", paras[i]):\n",
    "                break\n",
    "            answer_lines.append(paras[i])\n",
    "            i += 1\n",
    "\n",
    "        gt = \"\\n\".join([x for x in answer_lines if x not in [\"âœ”ï¸ ëª¨ë²”ë‹µì•ˆ\"]]).strip()\n",
    "        items.append({\"question\": question, \"ground_truth\": gt})\n",
    "\n",
    "    return items\n",
    "\n",
    "items = load_items_from_docx(DOCX_PATH, max_q=10)\n",
    "print(\"âœ… items loaded:\", len(items))\n",
    "print(\"sample Q1:\", items[0][\"question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d10f8",
   "metadata": {},
   "source": [
    "# 2. ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e20d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 15:00:11,679 - chatbot_app.modules.rag_module - INFO - ğŸ”— Pinecone 3ì¤‘ ì¸ë±ìŠ¤ ì—°ê²° ì¤‘...\n",
      "2026-02-05 15:00:14,761 - chatbot_app.modules.rag_module - INFO - âœ… [Law / Rule / Case] 3ê°œ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ!\n",
      "2026-02-05 15:00:14,791 - chatbot_app.modules.rag_module - INFO - â„¹ï¸ SimpleTokenizer ì‚¬ìš© (BM25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- run_once_answer START | run_idx=1 | llm_name=solar-pro2 ---\n",
      "items=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 15:00:15,727 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:15,727 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì „ì…ì‹ ê³ (ì£¼ë¯¼ë“±ë¡)Â·í™•ì •ì¼ì(í™•ì •ì¼ì) í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€(í™•ì •ì¼ì) ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”?\n",
      "2026-02-05 15:00:15,727 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì „ì…ì‹ ê³ (ì£¼ë¯¼ë“±ë¡)Â·í™•ì •ì¼ì(í™•ì •ì¼ì) í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€(í™•ì •ì¼ì) ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”?'\n",
      "2026-02-05 15:00:16,053 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:18,075 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:20,163 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:22,269 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:22,285 - chatbot_app.modules.rag_module - INFO - ğŸ“Œ Rerank selected=2 (threshold=0.2)\n",
      "2026-02-05 15:00:22,286 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-05 15:00:25,186 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:25,844 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:25,844 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ê³„ì•½ì¦ì„œ(ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ)ì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ì–´ ìˆìœ¼ë©´, 1ë…„ ê²½ê³¼í•˜ë©´ ë¬´ì¡°ê±´ ì£¼íƒì˜ì¸ë„(í‡´ê±°)ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”?\n",
      "2026-02-05 15:00:25,844 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ê³„ì•½ì¦ì„œ(ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ)ì— 1ë…„ì´ë¼ê³  ê¸°ì¬ë˜ì–´ ìˆìœ¼ë©´, 1ë…„ ê²½ê³¼í•˜ë©´ ë¬´ì¡°ê±´ ì£¼íƒì˜ì¸ë„(í‡´ê±°)ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”?'\n",
      "2026-02-05 15:00:26,552 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:27,219 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:27,932 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:28,684 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:28,693 - chatbot_app.modules.rag_module - INFO - ğŸ“Œ Rerank selected=5 (threshold=0.2)\n",
      "2026-02-05 15:00:28,695 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-05 15:00:31,028 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:31,621 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:31,624 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì„ëŒ€ì¸(ì§‘ì£¼ì¸)ê°€ ì•„ë¬´ ë§ ì•ˆ í–ˆëŠ”ë°, ê³„ì•½ì´ ë¬µì‹œì ê°±ì‹ (ìë™ì—°ì¥)ëœ ê±´ê°€ìš”?\n",
      "2026-02-05 15:00:31,625 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì„ëŒ€ì¸(ì§‘ì£¼ì¸)ê°€ ì•„ë¬´ ë§ ì•ˆ í–ˆëŠ”ë°, ê³„ì•½ì´ ë¬µì‹œì ê°±ì‹ (ìë™ì—°ì¥)ëœ ê±´ê°€ìš”?'\n",
      "2026-02-05 15:00:32,316 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:32,958 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:33,650 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:34,398 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:34,408 - chatbot_app.modules.rag_module - INFO - ğŸ“Œ Rerank selected=1 (threshold=0.2)\n",
      "2026-02-05 15:00:34,410 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-05 15:00:36,528 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:37,597 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:37,601 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ë¬µì‹œì ê°±ì‹ (ë¬µì‹œì ê°±ì‹ )ìœ¼ë¡œ ì—°ì¥ëœ ì¤„ ëª¨ë¥´ê³  ì‚´ì•˜ëŠ”ë°, ì£¼íƒì˜ì¸ë„(ì£¼íƒì˜ì¸ë„) ê°€ë ¤ë©´ ì–¸ì œê¹Œì§€ ì‚´ì•„ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : ì‚¬ìš©ì ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ëŠ” \"ë¬µì‹œì  ê°±ì‹  ìƒíƒœì—ì„œ ê³„ì•½ í•´ì§€ ì‹œ í†µì§€ ê¸°ê°„\"ì— ê´€í•œ ê²ƒìœ¼ë¡œ ì¶”ì •ë˜ë‚˜, [ìš©ì–´ ì‚¬ì „]ì— ëª…ì‹œëœ ë§¤í•‘ ê·œì¹™ë§Œ ì ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. \"ì´ì‚¬ ê°€ë ¤ë©´ ì–¸ì œê¹Œì§€ ì‚´ì•„ì•¼ í•˜ë‚˜ìš”\"ëŠ” \"ê³„ì•½í•´ì§€ í†µì§€ ê¸°ê°„\" ê´€ë ¨ ì¶”ê°€ ë³€í™˜ì´ í•„ìš”í•˜ë‚˜, ì‚¬ì „ì— í•´ë‹¹ ìš©ì–´ê°€ ì—†ì–´ ì›ë¬¸ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
      "2026-02-05 15:00:37,603 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ë¬µì‹œì ê°±ì‹ (ë¬µì‹œì ê°±ì‹ )ìœ¼ë¡œ ì—°ì¥ëœ ì¤„ ëª¨ë¥´ê³  ì‚´ì•˜ëŠ”ë°, ì£¼íƒì˜ì¸ë„(ì£¼íƒì˜ì¸ë„) ê°€ë ¤ë©´ ì–¸ì œê¹Œì§€ ì‚´ì•„ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : ì‚¬ìš©ì ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ëŠ” \"ë¬µì‹œì  ê°±ì‹  ìƒíƒœì—ì„œ ê³„ì•½ í•´ì§€ ì‹œ í†µì§€ ê¸°ê°„\"ì— ê´€í•œ ê²ƒìœ¼ë¡œ ì¶”ì •ë˜ë‚˜, [ìš©ì–´ ì‚¬ì „]ì— ëª…ì‹œëœ ë§¤í•‘ ê·œì¹™ë§Œ ì ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. \"ì´ì‚¬ ê°€ë ¤ë©´ ì–¸ì œê¹Œì§€ ì‚´ì•„ì•¼ í•˜ë‚˜ìš”\"ëŠ” \"ê³„ì•½í•´ì§€ í†µì§€ ê¸°ê°„\" ê´€ë ¨ ì¶”ê°€ ë³€í™˜ì´ í•„ìš”í•˜ë‚˜, ì‚¬ì „ì— í•´ë‹¹ ìš©ì–´ê°€ ì—†ì–´ ì›ë¬¸ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤.'\n",
      "2026-02-05 15:00:38,034 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:38,687 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:39,353 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:40,107 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:40,113 - chatbot_app.modules.rag_module - INFO - ğŸ“Œ Rerank selected=6 (threshold=0.2)\n",
      "2026-02-05 15:00:40,114 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-05 15:00:42,476 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:43,547 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:43,552 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì°¨ì„(ì¦ì•¡)ì„ 6ê°œì›” ì „ì— í–ˆëŠ”ë° ë˜ ì°¨ì„ì¦ì•¡(ì¦ì•¡)ì„ ìš”êµ¬í•´ìš”. ë”°ë¼ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸: ì°¨ì„(ì¦ì•¡)ì„ 6ê°œì›” ì „ì— í–ˆëŠ”ë° ë˜ ì°¨ì„ì¦ì•¡(ì¦ì•¡)ì„ ìš”êµ¬í•´ìš”. ë”°ë¼ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : ì‹¤ì œ ë²•ë¥  ì ìš© ì‹œ ì°¨ì„ì¦ì•¡ ìš”ê±´(ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ7ì¡° ë“±) ë° ì¦ì•¡ ìƒí•œë¥ (5% ì´ë‚´) ë“±ì„ ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë§Œ, ë³¸ ì‘ì—…ì€ ìš©ì–´ ë³€í™˜ë§Œ ìˆ˜í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
      "2026-02-05 15:00:43,554 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì°¨ì„(ì¦ì•¡)ì„ 6ê°œì›” ì „ì— í–ˆëŠ”ë° ë˜ ì°¨ì„ì¦ì•¡(ì¦ì•¡)ì„ ìš”êµ¬í•´ìš”. ë”°ë¼ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸: ì°¨ì„(ì¦ì•¡)ì„ 6ê°œì›” ì „ì— í–ˆëŠ”ë° ë˜ ì°¨ì„ì¦ì•¡(ì¦ì•¡)ì„ ìš”êµ¬í•´ìš”. ë”°ë¼ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : ì‹¤ì œ ë²•ë¥  ì ìš© ì‹œ ì°¨ì„ì¦ì•¡ ìš”ê±´(ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ7ì¡° ë“±) ë° ì¦ì•¡ ìƒí•œë¥ (5% ì´ë‚´) ë“±ì„ ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë§Œ, ë³¸ ì‘ì—…ì€ ìš©ì–´ ë³€í™˜ë§Œ ìˆ˜í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.'\n",
      "2026-02-05 15:00:44,238 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:45,762 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:46,285 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:47,130 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:47,139 - chatbot_app.modules.rag_module - INFO - ğŸ“Œ Rerank selected=22 (threshold=0.2)\n",
      "2026-02-05 15:00:47,140 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-05 15:00:49,864 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:50,307 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:50,309 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ê²½ê¸°ë„ì— ì‚¬ëŠ”ë° ì„ì°¨ì£¼íƒì´ ê²½ë§¤ì ˆì°¨ë¡œ ë„˜ì–´ê°€ë©´, ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ì¼ë¶€ë¼ë„ ìš°ì„ ë³€ì œê¶Œìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\n",
      "2026-02-05 15:00:50,310 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ê²½ê¸°ë„ì— ì‚¬ëŠ”ë° ì„ì°¨ì£¼íƒì´ ê²½ë§¤ì ˆì°¨ë¡œ ë„˜ì–´ê°€ë©´, ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ì¼ë¶€ë¼ë„ ìš°ì„ ë³€ì œê¶Œìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?'\n",
      "2026-02-05 15:00:50,740 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:51,735 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:52,336 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:53,090 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:53,095 - chatbot_app.modules.rag_module - INFO - ğŸ“Œ Rerank selected=9 (threshold=0.2)\n",
      "2026-02-05 15:00:53,096 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-05 15:00:56,804 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:57,771 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:57,789 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì¡°ì • ì‹ ì²­ì€ ì–´ë””ì— í•˜ë‚˜ìš”? (ë¶„ìŸì¡°ì •) ë§ë¡œ í•´ë„ ë˜ë‚˜ìš”? (ë¶„ìŸì¡°ì •) ëˆì€ ê¼­ ë‚´ì•¼ í•˜ë‚˜ìš”? (ë¶„ìŸì¡°ì •)  \n",
      "\n",
      "â€» ì°¸ê³ : ìš©ì–´ ì‚¬ì „ ë‚´ \"ì¡°ì •ìœ„\" â†’ \"ì£¼íƒì„ëŒ€ì°¨ë¶„ìŸì¡°ì •ìœ„ì›íšŒ\" ë§¤í•‘ì´ ì¡´ì¬í•˜ë‚˜, ì‚¬ìš©ì ì§ˆë¬¸ì— í•´ë‹¹ ë‹¨ì–´ê°€ ì—†ì–´ ì ìš©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. \"ë¶„ìŸì¡°ì •\"ì€ ì‚¬ì „ ë¯¸ë“±ì¬ ë‹¨ì–´ë¡œ ì›ì•ˆ ìœ ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 15:00:57,789 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì¡°ì • ì‹ ì²­ì€ ì–´ë””ì— í•˜ë‚˜ìš”? (ë¶„ìŸì¡°ì •) ë§ë¡œ í•´ë„ ë˜ë‚˜ìš”? (ë¶„ìŸì¡°ì •) ëˆì€ ê¼­ ë‚´ì•¼ í•˜ë‚˜ìš”? (ë¶„ìŸì¡°ì •)  \n",
      "\n",
      "â€» ì°¸ê³ : ìš©ì–´ ì‚¬ì „ ë‚´ \"ì¡°ì •ìœ„\" â†’ \"ì£¼íƒì„ëŒ€ì°¨ë¶„ìŸì¡°ì •ìœ„ì›íšŒ\" ë§¤í•‘ì´ ì¡´ì¬í•˜ë‚˜, ì‚¬ìš©ì ì§ˆë¬¸ì— í•´ë‹¹ ë‹¨ì–´ê°€ ì—†ì–´ ì ìš©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. \"ë¶„ìŸì¡°ì •\"ì€ ì‚¬ì „ ë¯¸ë“±ì¬ ë‹¨ì–´ë¡œ ì›ì•ˆ ìœ ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.'\n",
      "2026-02-05 15:00:58,494 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:00:59,220 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:00,128 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:00,707 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:00,707 - chatbot_app.modules.rag_module - INFO - ğŸ“Œ Rerank selected=7 (threshold=0.2)\n",
      "2026-02-05 15:01:00,723 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-05 15:01:03,951 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:04,868 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:04,868 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ê²½ë§¤ì ˆì°¨(ê²½ë§¤ì ˆì°¨)ë¡œ ê¶Œë¦¬ë¦¬ìŠ¤í¬(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ê°€ ë°œìƒí–ˆìœ¼ë©°, êµ­ì„¸ ì²´ë‚©ìœ¼ë¡œ ì¸í•œ ì••ë¥˜ê°€ ìš°ì„ ë³€ì œê¶Œ(ìš°ì„ ë³€ì œê¶Œ)ë³´ë‹¤ ì„ í–‰ë˜ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤. êµ­ì„¸ ì²´ë‚©ê¸ˆê³¼ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ) ì¤‘ ìµœìš°ì„ (ìµœìš°ì„ ë³€ì œê¶Œ) ë³€ì œìˆœìœ„ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n",
      "2026-02-05 15:01:04,868 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ê²½ë§¤ì ˆì°¨(ê²½ë§¤ì ˆì°¨)ë¡œ ê¶Œë¦¬ë¦¬ìŠ¤í¬(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ê°€ ë°œìƒí–ˆìœ¼ë©°, êµ­ì„¸ ì²´ë‚©ìœ¼ë¡œ ì¸í•œ ì••ë¥˜ê°€ ìš°ì„ ë³€ì œê¶Œ(ìš°ì„ ë³€ì œê¶Œ)ë³´ë‹¤ ì„ í–‰ë˜ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤. êµ­ì„¸ ì²´ë‚©ê¸ˆê³¼ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ) ì¤‘ ìµœìš°ì„ (ìµœìš°ì„ ë³€ì œê¶Œ) ë³€ì œìˆœìœ„ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?'\n",
      "2026-02-05 15:01:05,586 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:06,330 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:07,037 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:07,804 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:07,823 - chatbot_app.modules.rag_module - INFO - ğŸ“Œ Rerank selected=20 (threshold=0.2)\n",
      "2026-02-05 15:01:07,825 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-05 15:01:10,999 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:11,873 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:11,873 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì „ì„¸(ì „ì„¸) ê³„ì•½í•˜ë ¤ëŠ” ì„ì°¨ì£¼íƒ(ì„ì°¨ì£¼íƒ)ì— ì„ ìˆœìœ„ ê·¼ì €ë‹¹ê¶Œ(ê·¼ì €ë‹¹ê¶Œ)ì€ ì—†ëŠ”ë°, ë‚˜ì¤‘ì— ë³´ë‹ˆ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ êµ­ì„¸(êµ­ì„¸)ë¥¼ ì²´ë‚©í•œ ìƒíƒœì˜€ìŠµë‹ˆë‹¤. ì•„ì§ ì••ë¥˜ë“±ê¸°(ì••ë¥˜ë“±ê¸°)ëŠ” ì—†ì—ˆëŠ”ë°, ì´ ê²½ìš°ì—ë„ ì œ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)ì´ ìœ„í—˜í•œê°€ìš”?\n",
      "2026-02-05 15:01:11,888 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì „ì„¸(ì „ì„¸) ê³„ì•½í•˜ë ¤ëŠ” ì„ì°¨ì£¼íƒ(ì„ì°¨ì£¼íƒ)ì— ì„ ìˆœìœ„ ê·¼ì €ë‹¹ê¶Œ(ê·¼ì €ë‹¹ê¶Œ)ì€ ì—†ëŠ”ë°, ë‚˜ì¤‘ì— ë³´ë‹ˆ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ êµ­ì„¸(êµ­ì„¸)ë¥¼ ì²´ë‚©í•œ ìƒíƒœì˜€ìŠµë‹ˆë‹¤. ì•„ì§ ì••ë¥˜ë“±ê¸°(ì••ë¥˜ë“±ê¸°)ëŠ” ì—†ì—ˆëŠ”ë°, ì´ ê²½ìš°ì—ë„ ì œ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)ì´ ìœ„í—˜í•œê°€ìš”?'\n",
      "2026-02-05 15:01:12,310 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:13,364 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:13,860 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:14,664 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:14,674 - chatbot_app.modules.rag_module - INFO - ğŸ“Œ Rerank selected=22 (threshold=0.2)\n",
      "2026-02-05 15:01:14,674 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-05 15:01:18,465 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:20,298 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:20,301 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : 'ì „ì„¸ì‚¬ê¸°'ëŠ” ìš©ì–´ ì‚¬ì „ì— 'ì „ì„¸í”¼í•´'ë¡œ ì§ì ‘ ë§¤í•‘ë˜ì§€ ì•Šì•˜ìœ¼ë‚˜, ë¬¸ë§¥ìƒ 'ê¶Œë¦¬ë¦¬ìŠ¤í¬'ë¡œ ëŒ€ì²´ ê°€ëŠ¥í•œ ê²ƒìœ¼ë¡œ íŒë‹¨í•˜ì˜€ìŠµë‹ˆë‹¤. ì •í™•í•œ ë²•ë¥  ìš©ì–´ ì ìš©ì„ ìœ„í•´ ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "\n",
      "(ìµœì¢… ì¶œë ¥ ì‹œ ìœ„ ì°¸ê³  ë¬¸êµ¬ ì œì™¸)  \n",
      "\n",
      "**ìµœì¢… ì¶œë ¥:**  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?\n",
      "2026-02-05 15:01:20,301 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : 'ì „ì„¸ì‚¬ê¸°'ëŠ” ìš©ì–´ ì‚¬ì „ì— 'ì „ì„¸í”¼í•´'ë¡œ ì§ì ‘ ë§¤í•‘ë˜ì§€ ì•Šì•˜ìœ¼ë‚˜, ë¬¸ë§¥ìƒ 'ê¶Œë¦¬ë¦¬ìŠ¤í¬'ë¡œ ëŒ€ì²´ ê°€ëŠ¥í•œ ê²ƒìœ¼ë¡œ íŒë‹¨í•˜ì˜€ìŠµë‹ˆë‹¤. ì •í™•í•œ ë²•ë¥  ìš©ì–´ ì ìš©ì„ ìœ„í•´ ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "\n",
      "(ìµœì¢… ì¶œë ¥ ì‹œ ìœ„ ì°¸ê³  ë¬¸êµ¬ ì œì™¸)  \n",
      "\n",
      "**ìµœì¢… ì¶œë ¥:**  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?'\n",
      "2026-02-05 15:01:20,761 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:21,484 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:22,451 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:23,047 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:23,064 - chatbot_app.modules.rag_module - INFO - ğŸ“Œ Rerank selected=22 (threshold=0.2)\n",
      "2026-02-05 15:01:23,065 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-05 15:01:26,066 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data validation passed\n",
      "evaluate START | run_idx=1\n",
      "ar module id: 1732619184992\n",
      "calc filename: C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_19848\\2654277498.py\n",
      "in sys.modules: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6eb7cc777d849138d36db813155684e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43aed36a9d84a71bd4d2ae28adfb6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch 1/20:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 15:01:27,351 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:28,620 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:29,324 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:32,400 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:43,980 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:45,512 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:46,771 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:47,485 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:50,285 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:58,368 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:01:59,982 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:01,473 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:02,797 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:05,281 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:11,850 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:13,301 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:14,530 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:15,253 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:17,750 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:26,165 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:27,562 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:28,804 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:29,615 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:32,201 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:40,413 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:41,787 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:43,142 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:44,558 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-05 15:02:47,506 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "gpt_llm = ChatOpenAI(\n",
    "    # model=\"gpt-4o-mini\",\n",
    "    model=\"gpt-5-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "upstage_llm = ChatUpstage(\n",
    "    model=\"solar-pro2\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "pipeline = create_pipeline(\n",
    "    # generation_llm=gpt_llm,\n",
    "    generation_llm=upstage_llm,\n",
    "    embedding=upstage_embedding,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 1íšŒ ì‹¤í–‰\n",
    "# -----------------------------\n",
    "result = run_once_answer(pipeline, items, run_idx=1, llm_name=\"solar-pro2\")\n",
    "\n",
    "# ì €ì¥ íŒŒì¼ë“¤ ê²½ë¡œ ì¶œë ¥\n",
    "print(\"âœ… DONE. run_tag =\", result.get(\"run_tag\"))\n",
    "print(\" - raw_csv:\", result.get(\"raw_csv\"))\n",
    "print(\" - run_dir:\", result.get(\"run_dir\"))\n",
    "print(\" - per_question_csv:\", result.get(\"per_question_csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fd61e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/RAGAS/runs_answer/llmcmp_solar-pro2/run_01/per_question.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab09fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv chatbot_app)",
   "language": "python",
   "name": "chatbot-app-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "164.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
