{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3410cd46-8bde-4451-81ee-4c8494246cf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpinecone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pinecone\n\u001b[1;32m----> 5\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOPENAI_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m pc \u001b[38;5;241m=\u001b[39m Pinecone(api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPINECONE_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      7\u001b[0m index \u001b[38;5;241m=\u001b[39m pc\u001b[38;5;241m.\u001b[39mIndex(os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPINECONE_INDEX_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfenv\\lib\\site-packages\\openai\\_client.py:137\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    135\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m     )\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index = pc.Index(os.getenv(\"PINECONE_INDEX_NAME\"))\n",
    "\n",
    "EMBED_MODEL = \"text-embedding-3-large\"   # 3072\n",
    "CHAT_MODEL = \"gpt-4.1-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16989a7d-03ea-4417-878c-eb6e0a16258d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d04b75-981a-4dcc-b72e-f04d8893f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_query(text: str):\n",
    "    res = client.embeddings.create(\n",
    "        model=EMBED_MODEL,\n",
    "        input=text\n",
    "    )\n",
    "    return res.data[0].embedding\n",
    "\n",
    "\n",
    "def search_docs(query: str, top_k=8, min_score=0.45):\n",
    "    v = embed_query(query)\n",
    "    res = index.query(\n",
    "        vector=v,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    return [m for m in res[\"matches\"] if m[\"score\"] >= min_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a40c31-0d7c-4f87-9f0d-4e0929ffb4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5afa59f-c0be-4448-a1b5-503d28ccca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_RULES = \"\"\"\n",
    "너는 오직 제공된 [근거]만으로 답한다.\n",
    "- 근거에 없는 사실/법리/절차/판례/조문을 절대 추가하지 마라.\n",
    "- 결론은 근거 문장을 최대한 그대로 재구성해라(새 표현 최소화).\n",
    "- 반드시 근거 문장을 따옴표로 2~3개 인용해라.\n",
    "- 불확실하면 '근거 부족'이라고 말해라.\n",
    "\"\"\"\n",
    "\n",
    "def answer_with_rag(query: str, return_matches=False):\n",
    "    matches = search_docs(query)\n",
    "    if not matches:\n",
    "        return (\"근거 부족: 관련 문서를 찾지 못했습니다.\", matches) if return_matches else \"근거 부족: 관련 문서를 찾지 못했습니다.\"\n",
    "\n",
    "    context = \"\\n\\n\".join(\n",
    "        f\"[근거 {i+1} | score={m['score']:.3f}] {m['metadata'].get('text','')}\"\n",
    "        for i, m in enumerate(matches)\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"{RAG_RULES}\n",
    "\n",
    "\n",
    "\n",
    "[근거]\n",
    "{context}\n",
    "\n",
    "[질문]\n",
    "{query}\n",
    "\n",
    "[출력 형식]\n",
    "1) 결론\n",
    "2) 근거 인용(따옴표 2~3개)\n",
    "3) 요약(3줄 이내)\n",
    "4) 근거 부족한 부분(있으면)\n",
    "\"\"\"\n",
    "\n",
    "    res = client.chat.completions.create(\n",
    "        model=CHAT_MODEL,\n",
    "        temperature=0,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53f9cc-8c29-4a37-9d01-7c698949c56b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef818a0e-0abe-4fea-a6f9-e3ffd730e8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer_with_rag(\n",
    "    \"임대인이 전세사기 재판 중이거나 주택에 압류·가압류가 있거나 경매 진행 중이면 계약 해지가 가능한가?\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d473b9f-1d18-401f-896f-62d6bed6b96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c66182-2949-45e4-ba2b-5ee3ce28b353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81acf31c-c0e1-4ee7-a0fc-eb231fc1e022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d855c92-550b-4530-80f3-ffbd04c7bf7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96ed5e3b-78fe-4265-a9e9-2ad0c90736c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U python-dotenv openai pinecone langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "744404ea-8cd9-4e63-a8d7-9d969b474778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 업서트 중...\n",
      "{'doc_id': 'contract_v1', 'chunks': 1}\n",
      "\n",
      "2) RAG 답변:\n",
      "\n",
      "- 리스크 요약: 손해배상 한도가 연간 계약 금액의 100%로 제한되어 있어, 특정 상황에서 무한 책임이 발생할 수 있다.\n",
      "\n",
      "- 주요 리스크\n",
      "  - 근거: \"본 계약의 손해배상 한도는 연간 계약 금액의 100%로 한다.\"\n",
      "  - 영향: 계약 금액을 초과하는 손해가 발생할 경우, 추가적인 손해에 대한 보상이 이루어지지 않아 재정적 부담이 클 수 있다.\n",
      "  - 권고 조치: 손해배상 한도를 조정하거나, 특정 상황에서의 무한 책임을 명확히 규정하는 조항을 추가하는 것을 검토해야 한다.\n",
      "\n",
      "  - 근거: \"단, 고의 또는 중과실, 비밀유지 위반, 지식재산권 침해의 경우 손해배상 한도를 적용하지 않는다.\"\n",
      "  - 영향: 고의 또는 중과실로 인한 손해가 발생할 경우, 손해배상 한도가 적용되지 않아 무한 책임이 발생할 수 있다.\n",
      "  - 권고 조치: 고의 또는 중과실의 정의를 명확히 하고, 이에 대한 책임 범위를 구체적으로 규정하는 것이 필요하다.\n",
      "\n",
      "- 추가로 확인할 질문: 손해배상 한도를 조정할 수 있는 협상 가능성이 있는가?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 0) 환경 로드\n",
    "# ---------------------------\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "\n",
    "if not OPENAI_API_KEY or not PINECONE_API_KEY or not PINECONE_INDEX_NAME:\n",
    "    raise ValueError(\"OPENAI_API_KEY / PINECONE_API_KEY / PINECONE_INDEX_NAME 를 .env에 설정해줘.\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 1) 임베딩 유틸\n",
    "# ---------------------------\n",
    "def embed_text(text: str) -> list[float]:\n",
    "    resp = client.embeddings.create(\n",
    "        model=\"text-embedding-3-large\",  # ✅ 3072 dim\n",
    "        input=text\n",
    "    )\n",
    "    return resp.data[0].embedding\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 2) 문서 -> 청크 -> 업서트\n",
    "# ---------------------------\n",
    "def upsert_document(\n",
    "    doc_id: str,\n",
    "    text: str,\n",
    "    namespace: str = \"default\",\n",
    "    chunk_size: int = 800,\n",
    "    chunk_overlap: int = 120,\n",
    "):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    )\n",
    "    chunks = splitter.split_text(text)\n",
    "\n",
    "    vectors = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        vec = embed_text(chunk)\n",
    "        vectors.append({\n",
    "            \"id\": f\"{doc_id}::chunk{i}\",\n",
    "            \"values\": vec,\n",
    "            \"metadata\": {\n",
    "                \"doc_id\": doc_id,\n",
    "                \"chunk_id\": i,\n",
    "                \"text\": chunk,\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # 배치 업서트\n",
    "    index.upsert(vectors=vectors, namespace=namespace)\n",
    "    return {\"doc_id\": doc_id, \"chunks\": len(chunks)}\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 3) 검색\n",
    "# ---------------------------\n",
    "def retrieve(\n",
    "    query: str,\n",
    "    namespace: str = \"default\",\n",
    "    top_k: int = 5,\n",
    "):\n",
    "    qvec = embed_text(query)\n",
    "    res = index.query(\n",
    "        vector=qvec,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        namespace=namespace,\n",
    "    )\n",
    "\n",
    "    contexts = []\n",
    "    for m in res.matches or []:\n",
    "        md = m.metadata or {}\n",
    "        contexts.append({\n",
    "            \"score\": m.score,\n",
    "            \"doc_id\": md.get(\"doc_id\"),\n",
    "            \"chunk_id\": md.get(\"chunk_id\"),\n",
    "            \"text\": md.get(\"text\", \"\"),\n",
    "        })\n",
    "    return contexts\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 4) LLM 응답 (RAG)\n",
    "# ---------------------------\n",
    "SYSTEM = \"\"\"너는 계약서/정책 문서를 검토하는 실무형 어시스턴트다.\n",
    "주어진 근거(context) 안에서만 답하고, 근거가 부족하면 '근거 부족'이라고 말한다.\n",
    "출력은 한국어로, 핵심 리스크/근거/권고조치 형태로 정리한다.\n",
    "\"\"\"\n",
    "\n",
    "def answer_with_rag(\n",
    "    question: str,\n",
    "    namespace: str = \"default\",\n",
    "    top_k: int = 5,\n",
    "    model: str = \"gpt-4o-mini\",\n",
    "):\n",
    "    ctxs = retrieve(question, namespace=namespace, top_k=top_k)\n",
    "\n",
    "    context_block = \"\\n\\n\".join(\n",
    "        [f\"[doc={c['doc_id']} chunk={c['chunk_id']} score={c['score']:.3f}]\\n{c['text']}\"\n",
    "         for c in ctxs]\n",
    "    ) or \"(검색 결과 없음)\"\n",
    "\n",
    "    prompt = f\"\"\"아래 context를 근거로 질문에 답해줘.\n",
    "\n",
    "[context]\n",
    "{context_block}\n",
    "\n",
    "[question]\n",
    "{question}\n",
    "\n",
    "[output format]\n",
    "- 리스크 요약(한 줄)\n",
    "- 주요 리스크(불릿 3~7개)\n",
    "  - 근거: (doc/chunk 인용)\n",
    "  - 영향\n",
    "  - 권고 조치\n",
    "- 추가로 확인할 질문(있다면)\n",
    "\"\"\"\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"contexts\": ctxs,\n",
    "        \"answer\": resp.choices[0].message.content\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 5) 데모 실행\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    sample_doc = \"\"\"\n",
    "    본 계약의 손해배상 한도는 연간 계약 금액의 100%로 한다.\n",
    "    단, 고의 또는 중과실, 비밀유지 위반, 지식재산권 침해의 경우 손해배상 한도를 적용하지 않는다.\n",
    "    계약 해지는 30일 전 서면 통지로 가능하다.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"1) 업서트 중...\")\n",
    "    print(upsert_document(doc_id=\"contract_v1\", text=sample_doc, namespace=\"contracts\"))\n",
    "\n",
    "    q = \"손해배상 한도 조항에서 우리에게 불리한 리스크가 뭐야?\"\n",
    "    print(\"\\n2) RAG 답변:\\n\")\n",
    "    out = answer_with_rag(q, namespace=\"contracts\", top_k=5)\n",
    "    print(out[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0346f918-ed6f-4aac-94e1-94b8c8435ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a7e5cb-9d04-4a86-9b9e-2db7e31f1ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed0c9c3-f5d9-4bd9-be9d-ca0d0332a27c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd72b51-b93e-4b44-885e-c42b6fdf2221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfenv)",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
